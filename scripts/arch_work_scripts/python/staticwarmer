#!/usr/bin/env python
# -*- coding: utf-8 -*-

import urllib2
import sys
import os.path
import argparse

parser = argparse.ArgumentParser(description='Cache warming URL crawler from list.')
parser.add_argument('-f', '--file', help='file path', required=True)

# Display help by default
if len(sys.argv) == 1:
    sys.argv.append('-h')

# Parse command-line arguments
try:
    args = parser.parse_args()
except KeyboardInterrupt:
	pass

fhandle = open(args.file, 'r')
listing = fhandle.readlines()
fhandle.close()

o = urllib2.build_opener()

for url in listing:
    try:
        print ".. %s" % url.rstrip()
        o.open(url.rstrip())
    except (urllib2.HTTPError, urllib2.URLError):
        pass

# vim: ts=4 sw=4 et
