== monitoring proxmox server dans prometheus / grafana ==


https://blog.zwindler.fr/2020/01/06/proxmox-ve-prometheus/
https://github.com/znerol/prometheus-pve-exporter



= installation de l'exporteur prometheus sur les serveurs proxmox :

on creer un rep qui va contenir notre appli, on install virtualenv python pour ne pas parasiter notre os avec la / les lib installées avec notre binaire puis on install l'exporteur :

mkdir /opt/prometheus-pve-exporter
apt install virtualenv
virtualenv /opt/prometheus-pve-exporter
/opt/prometheus-pve-exporter/bin/pip install prometheus-pve-exporter
# on test c'est ok :
/opt/prometheus-pve-exporter/bin/pve_exporter --help
usage: pve_exporter [-h] [config] [port] [address]

positional arguments:
  config      Path to configuration file (pve.yml)
  port        Port on which the exporter is listening (9221)
  address     Address to which the exporter will bind

optional arguments:
  -h, --help  show this help message and exit


= on crée un groupe et un user dedié sur proxmox : 

ce user permettra l'acces aux metriques via l'api proxmox et c'est ce user que l'exporteur prometheus utilisera pour recuperer les metriques de proxmox et les exposer au format openmetrics que prometheus viendra scraper .

root@boogie-hypervisor:/opt# pveum groupadd monitoring -comment 'Monitoring group'
root@boogie-hypervisor:/opt# pveum aclmod / -group monitoring -role PVEAuditor
root@boogie-hypervisor:/opt# pveum useradd pve_exporter@pve
root@boogie-hypervisor:/opt# pveum usermod pve_exporter@pve -group monitoring
root@boogie-hypervisor:/opt# pveum passwd pve_exporter@pve
Enter new password: ************
Retype new password: ************

on cree le fichier de conf qu'on renseigne avec nos infos user :

mkdir -p /usr/share/pve_exporter/
cat > /opt/prometheus-pve-exporter/pve_exporter.yml << EOF
default:
    user: pve_exporter@pve
    password: monitoring#1
    verify_ssl: false
EOF

On test maintenant le demarrage de l'appli avec le fichier de conf en argument :
root@boogie-hypervisor:/opt/prometheus-pve-exporter# /opt/prometheus-pve-exporter/bin/pve_exporter /opt/prometheus-pve-exporter/pve_exporter.yml
 * Running on http://localhost:9221/ (Press CTRL+C to quit)

C'est ok : l'appli démarre: on va créer un service systemd pour le démarrage auto de l'exporteur : 

cat > /etc/systemd/system/pve_exporter.service << EOF
[Unit]
Description=Proxmox VE Prometheus Exporter
After=network.target
Wants=network.target
[Service]
Restart=on-failure
WorkingDirectory=/opt/prometheus-pve-exporter/
ExecStart=/opt/prometheus-pve-exporter/bin/pve_exporter /opt/prometheus-pve-exporter/pve_exporter.yml 9221 192.168.0.7  <<< on renseigne l'ip de notre serveur proxmox(aussi accessible par votre serveur Prometheus)
[Install]
WantedBy=multi-user.target
EOF


on peut tester depuis un navigateur ou en cli c'est ok notre exporteur fonctionne :

root@boogie-hypervisor:/opt/prometheus-pve-exporter# curl http://192.168.0.7:9221//pve?target=192.168.0.7 |head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5248  100  5248    0     0  30690      0 --:--:-- --:--:-- --:--:-- 30511
# HELP pve_node_info Node info
# TYPE pve_node_info gauge
pve_node_info{id="node/boogie-hypervisor",ip="192.168.0.7",level="",local="1",name="boogie-hypervisor",nodeid="0"} 1.0
# HELP pve_up Node/VM/CT-Status is online/running
# TYPE pve_up gauge
pve_up{id="node/boogie-hypervisor"} 1.0
pve_up{id="qemu/103"} 1.0
pve_up{id="qemu/102"} 1.0
pve_up{id="qemu/100"} 0.0
pve_up{id="qemu/101"} 1.0


===  containerisation de l'appli : 

on va containeriser le pve exporter de manière à pouvoir l'executer (comme c'est prévu depuis un autre serveur qu'un membre du cluster proxmox) 

cat Dockerfile
FROM python:3-alpine

RUN \
  pip install --no-cache-dir prometheus-pve-exporter && \
  mkdir /config

COPY ./pve.yml /config/pve.yml
WORKDIR /config
VOLUME /config

ENTRYPOINT ["/usr/local/bin/pve_exporter"]
CMD ["pve.yml"]


cat pve.yml
default:
  user: bob@pve
  password: blabla
  verify_ssl: false


docker build . -t prometheus-pve-exporter
docker tag prometheus-pve-exporter:latest bob/prometheus-pve-exporter:0.1
docker push bob/prometheus-pve-exporter:0.1

on peut tester en local sur un node proxmox :

docker pull bob/prometheus-pve-exporter:0.1
0.1: Pulling from bob/prometheus-pve-exporter
df20fa9351a1: Already exists
36b3adc4ff6f: Already exists
7031d6d6c7f1: Already exists
81b7f5a7444b: Already exists
0f8a54c5d7c7: Already exists
eb01c84c0422: Pull complete
e8ec9b2f3ba6: Pull complete

 docker run -v $(pwd)/pve.yml:/config/pve.yml -p 9221:9221 bob/prometheus-pve-exporter:0.1
 * Running on http://localhost:9221/ (Press CTRL+C to quit)
192.168.0.20 - - [27/Jun/2020 09:13:57] "GET /pve?target=192.168.0.7 HTTP/1.1" 200 -
192.168.0.20 - - [27/Jun/2020 09:17:32] "GET /pve?target=192.168.0.7 HTTP/1.1" 200 -

depuis un navigateur ou en curl on a les infos :
curl http://192.168.0.7:9221//pve?target=192.168.0.7 |head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5249  100  5249    0     0  40376      0 --:--:-- --:--:-- --:--:-- 40376
# HELP pve_up Node/VM/CT-Status is online/running
# TYPE pve_up gauge
pve_up{id="node/boogie-hypervisor"} 1.0
pve_up{id="qemu/103"} 1.0
pve_up{id="qemu/101"} 1.0
pve_up{id="qemu/100"} 0.0
pve_up{id="qemu/102"} 1.0


on est pas obligé d'avoir le fichier de conf contenant les credentials en local sur le node qu'on test ..si les infos correctes sont insérées au build dans l'image on peut lancer directement : 
docker run  -p 9221:9221 fredsobon/prometheus-pve-exporter:0.1
 * Running on http://localhost:9221/ (Press CTRL+C to quit)
192.168.0.7 - - [27/Jun/2020 09:27:28] "GET //pve?target=192.168.0.7 HTTP/1.1" 200 -

la réponse sera identique : 
curl http://192.168.0.7:9221//pve?target=192.168.0.7 |head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5247  100  5247    0     0  38866      0 --:--:-- --:--:-- --:--:-- 38866
# HELP pve_up Node/VM/CT-Status is online/running
# TYPE pve_up gauge
pve_up{id="node/boogie-hypervisor"} 1.0
pve_up{id="qemu/102"} 1.0
pve_up{id="qemu/100"} 0.0
pve_up{id="qemu/101"} 1.0
pve_up{id="qemu/103"} 1.0
# HELP pve_disk_size_bytes Size of storage device
# TYPE pve_disk_size_bytes gauge


== proxmox-prometheus-exporter kube : ==


1/ on va builder notre container :

On va utiliser un fichier fake pour ne pas biensur divulger les infos du compte permettant de se connecter en api proxmox :
cat pve.yml
default:
  user: pve_user@pve
  password: secretpass
  verify_ssl: false

cat Dockerfile 

# source de notre image 
FROM python:3-alpine
# install du module python prometheus-pve-exporter
RUN  pip install --no-cache-dir prometheus-pve-exporter 
# déplacement (et creation du rep /config) dans l'arbo de notre container :
WORKDIR /config
# copie de notre fichier de conf proxmox exporter contenant les infos de connexion à l'api proxmox ( compte à créer sur proxmox au préalable )
COPY ./pve.yml /config/pve.yml
# Commande exécutée au lancement de notre container
ENTRYPOINT ["/usr/local/bin/pve_exporter", "/config/pve.yml"]

Nb: de manière native le port 9221 est utilisé et configuré dans le code python 

On build notre image :
docker build . -t prometheus-pve-exporter

on tag et on pousse dans notre repo :
docker tag prometheus-pve-exporter:latest bob/prometheus-pve-exporter:0.1
docker push bob/prometheus-pve-exporter:0.1



2/ pod de test :

on crée maintenant un pod de test qui va nous permettre de tester notre appli.
Avant de faire notre conf on va déclarer notre fichier de conf permettant la connex à l'api proxmox en tant que secret kube :

#creation du secret  contenant les acces à l'api :
kubectl create secret generic proxmox-api --from-file=pve.yml

# creation de notre pod de test : 

cat proxmox-pve-exporter_pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: prometheus-pve-exporter
spec:
  containers:
  - name: prometheus-pve-exporter          <<< nom de notre pod
    image: bob/prometheus-pve-exporter:0.1 <<< nom de l'image que l'on va pull de notre registry
    ports:
    - name: pve-exporter                   <<< nom du port sur lequel ecoute notre container
      containerPort: 9221                  <<< num de port de notre container en ecoute 
    command: ["/usr/local/bin/pve_exporter", "/config/pve.yml"]   <<< commande executée depuis notre pod
    volumeMounts:                           <<< ici on va définir un point de montage 
    - name: proxmox-api-vol                 <<< on donne le nom à notre point de montage 
      mountPath: "/config"                  <<< on defini notre point de montage
      readOnly: true                        <<< on le défini en readonly 
  volumes:
  - name: proxmox-api-vol                   <<< on defini un nom à notre volume 
    secret:
      secretName: proxmox-api               <<< on fait matcher le nom de notre secret monter en volume avec le secret qu'on a poussé dnas kube auparavant 



kubectl create -f proxmox-pve-exporter_pod.yaml

kctl get secrets proxmox-api
NAME          TYPE     DATA   AGE
proxmox-api   Opaque   1      3h55m
 boogie@boogieland  ~/Documents/work/work_utils  kctl get pods prometheus-pve-exporter 
NAME                      READY   STATUS    RESTARTS   AGE
prometheus-pve-exporter   1/1     Running   0          3h54m


on va examiner notre pod et vérifier la conf de connex api :
on voit en nous connectant en shell qu'on arrive bien dans le rep /config comme défini dans notre Dockerfile. On voit aussi que le secret est bien récupérer et monter : le fichier et les informations de connections  sont les bonnes  

kubectl -it exec prometheus-pve-exporter -- sh
/config # ls
pve.yml
/config # cat pve.yml
default:
  user: blabla@pve
  password: blabla
  verify_ssl: false


on va récupérer l'ip de notre pod :
kctl get pod prometheus-pve-exporter  -o yaml |grep -A 1 " podIPs:"
  podIPs:
  - ip: 10.124.71.96


on lance un pod de test debian qui contient des utilitaires :
kubectl create -f debian-pod.yaml
On lance un shell du container et on test la connection à notre pod suivi du port du service puis de la target d'un hyperviseur proxmox .
On recupére  bien les infos de notre hyperviseur. Notre exporteur est fonctionnel.

 kctl exec -it debian-pod -- /bin/bash
root@debian-pod:/# curl 10.124.71.96:9221/pve?target=192.168.0.7 |head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0# HELP pve_up Node/VM/CT-Status is online/running
# TYPE pve_up gauge
pve_up{id="node/boogie-hypervisor"} 1.0
pve_up{id="qemu/100"} 0.0
pve_up{id="qemu/103"} 1.0
pve_up{id="qemu/101"} 1.0
pve_up{id="qemu/102"} 1.0
# HELP pve_disk_size_bytes Size of storage device
# TYPE pve_disk_size_bytes gauge
pve_disk_size_bytes{id="qemu/100"} 7.516192768e+010
100  5247  100  5247    0     0  14297      0 --:--:-- --:--:-- --:--:-- 14297
(23) Failed writing body

