=== notes prometheus (ud) ===


prometheus est fait en go
prom collecte les metrics des points de monitoring sur les endpoints via http. On dis que prometheus "scrap" les data.

== Set up :

cf files pour baremetal

une fois les applis ( prometheus / node-exporter et grafana installés ) ont peut y acceder :

- prometheus    http://localhost:9090
- node-exporter http://localhost:9100
- grafana       http://localhost:3000


- prometheus :

on peut browser les differentes métriques , executer la requete ( recupérer les valeurs ) ou ajouter un graph : qui va nous montrer physiquement le resulat de notre requete sous forme de graph

ex: on selectionne via le menu deroulant la metrique :
scrape_samples_scraped

on peut avoir le graph 

- grafana :
une fois installé on va definir une datasource : on va donc ajouter prometheus ( localhost:9090) 

on ajoute un dashboard > on ajoute une metrique : ex on recupere scrape_samples_scraped celle qu'on a tester dans prometheus , on ajoute un graph et on a la meme chose que dans prometheus mais avec un visuel plus clair.


== concepts :

toutes les donnees sont stockée en format time series.
chaque time-series est identifiée par un nom de métrique (metric name ) et un set de paires clés valeurs apellées "labels"

exemple : 
metric: go_memstats_alloc_bytes

et on aura plusieurs labels de cette métrique : 
    ✔
    go_memstats_alloc_bytes{endpoint="web",instance="172.17.0.4:9090",job="monitor-prometheus-operato-prometheus",namespace="prom",pod="prometheus-monitor-prometheus-operato-prometheus-0",service="monitor-prometheus-operato-prometheus"}
    ✔
    go_memstats_alloc_bytes{endpoint="service",instance="172.17.0.2:3000",job="monitor-grafana",namespace="prom",pod="monitor-grafana-857c4b68b4-sqwkm",service="monitor-grafana"}
    ✔
    go_memstats_alloc_bytes{endpoint="metrics",instance="192.168.39.114:9100",job="node-exporter",namespace="prom",pod="monitor-prometheus-node-exporter-mb87t",service="monitor-prometheus-node-exporter"}
    ✔

 On aura donc la même métrique mais dont les résultats seront issus de plusieurs soft dfférents .

les data time-series sont la representation des data actuelles et elles peuvent prendre un format  float64 ou un timestamp de précision milliseconds
la notation des time-series suit un standart du type :
<metric_name>{<label_name=label_value..}
ex: 
node_boot_time_seconds{endpoint="metrics",instance="192.168.39.114:9100",job="node-exporter",namespace="prom",pod="monitor-prometheus-node-exporter-mb87t",service="monitor-prometheus-node-exporter"}


== configuration prometheus : =

La conf de prometheus est stockée dans un format yaml et on peut modifier cette config sans avoir a redémarrer prometheus.
un reload peut être fait avec un sig hup linux kill -SIGHUP <pid>

on peut aussi démarrer prom avec des params en lui passant des arguments de type : --config.file
si on veut modifier un param on doit par contre redémarrer prom.

on peut dans un deployment helm du chart prometheus-operator examiner la conf prometheus en nous loggant en shell dans le container prometheus-config-reloader de notre pod  prometheus-monitor-prometheus-operato-prometheus-0
on peut voir en gros les params de base en début de fichier dans la section global 
puis on va definir les targets : les endpoints qui permettront a prometheus de recup la data.
Le label job_name est rajouté sur toutes les lignes d'ou on veut scrap la data 

/etc/prometheus/config_out $ cat prometheus.env.yaml
global:
  evaluation_interval: 30s  <<<<  delai d'evaluation des rules définies dans notre conf 
  scrape_interval: 30s  <<< delai de recup de métrique.
  external_labels:
    prometheus: prom/monitor-prometheus-operato-prometheus
    prometheus_replica: prometheus-monitor-prometheus-operato-prometheus-0
rule_files:
- /etc/prometheus/rules/prometheus-monitor-prometheus-operato-prometheus-rulefiles-0/*.yaml    <<< fichier de rules 
scrape_configs:   <<<<< c'est dans cette section qu'on va définir les endpoints dont prometheus viendra scrapper les data.
- job_name: prom/monitor-prometheus-operato-alertmanager/0   <<<< on commence toujours notre label par job_name suivi de notre target            
  honor_labels: false
  kubernetes_sd_configs:
  - role: endpoints
    namespaces:
      names:
      - prometheus
  metrics_path: /metrics    <<< on defini ici que notre points d'entrée pour recup les metrics sera /metrics
  ...

on peut examiner nos targets en selectionnant status > target dans l'interface de prometheus 
on voit notre target definie dans la conf :


prom/monitor-prometheus-operato-alertmanager/0 (1/1 up)
Endpoint 	State 	Labels 	Last Scrape 	Scrape Duration 	Error
http://172.17.0.3:9093/metrics
	up 	endpoint="web" instance="172.17.0.3:9093" job="monitor-prometheus-operato-alertmanager" namespace="prom" pod="alertmanager-monitor-prometheus-operato-alertmanager-0" service="monitor-prometheus-operato-alertmanager" 	18.967s ago 	8.43ms

= Monitoring des nodes :

pour monitorer un node on doit ajouter un node exporter : qui va exposer les métrics des serveurs linux/ unix ( cpu, mem ..)
on peut dans une install classique installer le binaire de la maniere suivante :

#!/bin/bash
NODE_EXPORTER_VERSION="0.16.0"
wget https://github.com/prometheus/node_exporter/releases/download/v${NODE_EXPORTER_VERSION}/node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz
tar -xzvf node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz
cd node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64
cp node_exporter /usr/local/bin

# create user
useradd --no-create-home --shell /bin/false node_exporter

chown node_exporter:node_exporter /usr/local/bin/node_exporter

# on créee un fichier de service : 
echo '[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/usr/local/bin/node_exporter

[Install]
WantedBy=multi-user.target' > /etc/systemd/system/node_exporter.service

# enable node_exporter in systemctl
systemctl daemon-reload
systemctl start node_exporter
systemctl enable node_exporter


On va ensuite alimenter notre fichier de conf prometheus pour qu'il prenne en compte notre exporter :
...
  - job_name: 'node_exporter'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:9100']

Dans une conf kube déployée avec le prometheus operator on aura classiquement un dameonset installé sur chaque noeud du cluster et on pourra retrouver cette conf par ex :

- job_name: monitoring/monitor-prometheus-operato-node-exporter/0
  honor_timestamps: true
  scrape_interval: 30s
  scrape_timeout: 10s
  metrics_path: /metrics
  scheme: http
  kubernetes_sd_configs:
  - role: endpoints
    namespaces:
      names:
      - monitoring
  relabel_configs:
  ....
  .......

on pourra examiner les métrics exposées par les membres de notre cluster en faisant un curl sur l'ip d'un node suivi du port 9100 (port de l'exporter) et de la route "/metrics" :
ex: 
curl http://192.168.0.81:9100/metrics |head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 1.1048e-05
go_gc_duration_seconds{quantile="0.25"} 4.9248e-05
go_gc_duration_seconds{quantile="0.5"} 9.0784e-05
go_gc_duration_seconds{quantile="0.75"} 0.00013272
go_gc_duration_seconds{quantile="1"} 0.008615343
go_gc_duration_seconds_sum 6.307212057
go_gc_duration_seconds_count 22903
# HELP go_goroutines Number of goroutines that currently exist.
100 14997    0 14997    0     0   523k      0 --:--:-- --:--:-- --:--:--  542k

== Monitoring : ==

= Clients librairies :

avant de monitorer notre code on doit instrumenter notre code.
on a à notre disposition des librairies pretes en python, scala, go ....Lua pour nginx, ruby, rust ...
On peut si on en a besoin créer les notres : il faut juste respecter le format d'exposition.

- exposition format :
le format a respecter est de forme : "simple text format" : un nom de metric , un label clé valeur et la metrique récupérée.
ex: 
node_uname_info{domainname="(none)",machine="x86_64",nodename="k-node01",release="4.9.0-12-amd64",sysname="Linux",version="#1 SMP Debian 4.9.210-1+deb9u1 (2020-06-07)"} 1
process_cpu_seconds_total 1477.77
process_resident_memory_bytes 2.0381696e+07

v2-1
