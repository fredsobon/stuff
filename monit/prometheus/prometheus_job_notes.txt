$
== notes : ===

= concepts prometheus : 

activation d'une metrique du node exporter desactivé par défaut

ajout d'une machine a monitorer :

on ajoute dans le fichier de conf prometheus.yml

- job_name: node_exporter
  static_configs:
  - targets:
    - 10.121.253.78:9100

de base prometheus ecrit ses data en local : il ne pousse pas dans s3 par exemple.
Il y a des projets tierce pour stocker ( ex thanos) .

La base est une resolution de 15s avec un max de 15jours de retention.

-service discovery :

prometheus va inerroger quelque chose pour recup la listes des objects qu'il va scraper .

dns_sd_configs

on va modifier nsd : serveur dns  local autoritaire ( pas de fwd) :w


cat /etc/resolv.conf
; Created by cloud-init on instance boot automatically, do not edit.
;
; generated by /usr/sbin/dhclient-script
search lapin.io
nameserver 127.0.0.1
#nameserver 10.101.1.227
#nameserver 10.101.101.49
#nameserver 10.120.1.227


on ajoute a la fin dans le fichier nsd.conf notre domaine de test :

zone:
  name: lab.lapin.io
  zonefile: lab.lapin.io.conf


on va ajouter le fichier de zone :

[root@poc-prometheus-server-fso prometheus-2.18.1.linux-amd64]# cat /etc/nsd/lab.lapin.io.conf
;## NSD authoritative only DNS

$ORIGIN lab.lapin.io.    ; default zone domain
$TTL 86400           ; default time to live

@ IN SOA ns1 admin@lab.lapin.io (
           2012082703  ; serial number
           28800       ; Refresh
           14400        ; Retry
           864000      ; Expire
           86400       ; Min TTL
           )

           NS      ns1.lab.lapin.io.
           NS      ns2.lab.lapin.io.

virt02u   	   IN     A    10.121.253.1
virt04u   	   IN     A    10.121.253.2
virt06u   	   IN     A    10.121.235.3


FSO-node       IN     A    10.121.253.78

_pve._tcp      SRV    0 0 8006 FSO-node

_node._tcp     SRV   0 0 9100 FSO-node
_pve._tcp      SRV    0 0 8006 virt02u.lab.lapin.io.
_pve._tcp      SRV    0 0 8006 virt04u.lab.lapin.io.
_pve._tcp      SRV    0 0 8006 virt06u.lab.lapin.io.

;## NSD authoritative only DNS

maintenant on modifie la conf prometheus en ajoutant le service discovery :

scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']

  - job_name: 'node_exporter'
    dns_sd_configs:
    - names :
      - _node._tcp.lab.lapin.io

>> on aura maintenant une decouverte des servers service entrés dans la conf dns :

_node._tcp     SRV   0 0 9100 bob-node

- prometheus evalue les rules : les seuils une fois que le seuil est dépassé il envoit a alerte manager qui lui va envoyé a slack etc ... : alerte manager ne sert juste qu'a l'aiguillage

- prometheus devient un standart : les applis exposent les metriques au format prometheus.
on peut creer un fichier text a plat qui recupére ls datas au format prometheus
text_file

les fichiers doivent finir par .prom



- notes helm chart maison : 

umbrella : notre module maison est composé de 2 charts : 
prometheus-operator
secret : chart maison pour deployer les secrets

ex : dans notre cas on utilsie etcd en composant externe à kube.
on va devoir recupérer les metrics etcd en donnant les infos secrets (certif tls etcd) pour que prometheus-operator puisse recupérerer les valeurs.


on va avoir en plus les servicesmonitor pour exposer les metriques des composants externes : 

calico

> on va créer des objets services
> pod ( on doit avoir la liste des pod ) calico
> service monitor : fait un match sur les endpoints ( pod ) pour recupérer les data à monitorer 

idem pour typha
..
....


prometheus-operator peut donner des infos à grafana
> ex : on met les dashboard dans un volume 
mais pb en cas de scaling ( il faut pousser et repliquer les données ..)

on va plutot fournir des configmaps : 
on va lui donner les dashboards en configmap : c'est du json ..il faut faire du json dans du yaml .
il faut faire attention car les data doivent etre protégées ( les instructions go peuvent être mal interprétées ..) 
ex {{`{{ instance }}`}} 


stockage volume en local 
hostpath
pv  : physical volume
pvc : demande de stockage 

stockage local peut etre fait sur les nodes.
on stick l'appli sur les nodes dédiés.


= deploiment chart : ==


chart.yaml
( en v3 contient les dependancies) 

on verif les dépendancies :
helm dep list                                                                  [☸ |kubernetes-admin@sandbox:kube-system]
NAME               	VERSION	REPOSITORY                                                         	STATUS
prometheus-operator	8.9.2  	https://artifact.lapin.net/artifactory/helm-remote-stable/  	ok
secrets            	0.1.4  	https://artifact.lapin.net/artifactory/helm-ilius-incubator/	ok

si pas ok  :on meet a jour 

helm dependencies update 

> dans le rep charts on recup les charts gzip : on ne gzip pas  : pas nécéssaire.

helm_vars : on gere nos environments 

tree helm_vars                                                                 [☸ |kubernetes-admin@sandbox:kube-system]
helm_vars
├── ci
│   ├── secrets.ci.yaml
│   └── values.yaml
├── infra
│   ├── secrets.srs.yaml
│   └── values.yaml
├── recette
│   ├── secrets.srs.yaml
│   └── values.yaml
├── sandbox
│   └── values.yaml
└── siops
    ├── secrets.srs.yaml
    └── values.yaml

5 directories, 9 files


tree templates                                                                 [☸ |kubernetes-admin@sandbox:kube-system]
templates
├── calico
│   ├── endpoints.yaml
│   ├── servicemonitor.yaml
│   ├── service.yaml
│   ├── typha-endpoints.yaml
│   ├── typha-servicemonitor.yaml
│   └── typha-service.yaml
├── grafana
│   └── dashboards
│       ├── calico-felix.yaml
│       ├── calico-typha.yaml
│       └── prometheus-alertmanager.yaml
├── _helpers.tpl
├── ssl
│   └── grafana-certmanager.yaml
└── storage
    └── prometheus
        └── persistentvolume.yaml

6 directories, 12 files



helm template monitoring artifact/prometheus-operator < on recupere sur une registry

si on déploit en local on met .

              nomde notre deploiement . (endroit) -f valeurs --namespace voulu  ( si le namespace n'existe pas il le crée )
helm template monitoring . -f helm_vars/sandbox/values.yaml --namespace monitoring
                

la commande template va juste générer la conf mais n'applique rien 


on install 
helm install  monitoring . -f helm_vars/sandbox/values.yaml --namespace monitoring --create-namespace
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
manifest_sorter.go:192: info: skipping unknown hook: "crd-install"




le deployement fonctionne sauf qu'on a une erreur sur le pod prometheus
on voit dans les erreurs :


il nous manque le repertoire defini dans le volume :
/data/prometheus-database

on crée les repo et on change les droits au bon user chown -R 1000:1000 

on bute le pod et on c'est bon.


on peut voir toutes les rules crées par prometheus, services monitor, dahboard ..

l'inegralité de promethzus est piloté par kube


on va examiner prometheus en forwardant le port du pod 


kubectl port-forward prometheus-monitoring-prometheus-oper-prometheus-0 9090:9090
Forwarding from 127.0.0.1:9090 -> 9090
Forwarding from [::1]:9090 -> 9090
Handling connection for 9090
Handling connection for 9090
Handling connection for 9090
Handling connection for 9090
Handling connection for 9090
Handling connection for 9090


on voit que les metrics des composants kube et autre calico des service monitor sont récupérées : le protocole de service discovery interne de kube est alimenté.

des labels sont automatiquement fixé par kube pour les composants 


on peut créer les rules ,les dashboars



grafana : on examine grafana 

kubectl port-forward monitoring-grafana-584cb44f78-kv7vh 3000:3000


on peut voir les configmaps si on a comme label  grafana-dashboard -> on a un dashboard grafana 

ex :
monitoring/monitoring-prometheus-oper-k8s-resources-cluster


datasource :

on a la datasource prometheus mais aussi la datasource alartmanager 
http://127.0.0.1:9090/targets



==== exposition de services :


on va créer un deployment  et un service :

on creer un namespace :
kubectl create ns echoserver                                                                                                               [☸ |kubernetes-admin@sandbox:monitoring]
namespace/echoserver created

kubectl create deployment source-ip-app --image=k8s.gcr.io/echoserver:1.4 -n echoserver                                                    [☸ |kubernetes-admin@sandbox:monitoring]
deployment.apps/source-ip-app created


apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  creationTimestamp: "2020-06-18T12:57:46Z"
  generation: 1
  labels:
    app: source-ip-app
  name: source-ip-app
  namespace: echoserver
  resourceVersion: "1558431"
  selfLink: /apis/apps/v1/namespaces/echoserver/deployments/source-ip-app
  uid: 465a45d8-dced-4770-8e17-b2fe77b01aa0
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: source-ip-app
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: source-ip-app
    spec:
      containers:
      - image: k8s.gcr.io/echoserver:1.4
        imagePullPolicy: IfNotPresent
        name: echoserver
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 1
  conditions:
  - lastTransitionTime: "2020-06-18T12:57:48Z"
    lastUpdateTime: "2020-06-18T12:57:48Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2020-06-18T12:57:46Z"
    lastUpdateTime: "2020-06-18T12:57:48Z"
    message: ReplicaSet "source-ip-app-7c79c78698" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 1
  readyReplicas: 1
  replicas: 1
  updatedReplicas: 1


kubectl expose deployment source-ip-app --name=clusterip --port=80 --target-port=8080                                                      [☸ |kubernetes-admin@sandbox:echoserver]
service/clusterip exposed



 boogie@boogieland  ~/.kube  kctl get svc -o yaml                                                                                                                       [☸ |kubernetes-admin@sandbox:echoserver]
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2020-06-18T12:58:04Z"
    labels:
      app: source-ip-app
    name: clusterip
    namespace: echoserver
    resourceVersion: "1558471"
    selfLink: /api/v1/namespaces/echoserver/services/clusterip
    uid: 0d90febe-2f3a-4f2a-b30b-73cc8c18c979
  spec:
    clusterIP: 10.86.58.232
    ports:
    - port: 80
      protocol: TCP
      targetPort: 8080
    selector:
      app: source-ip-app
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

on a trois maniere d'acceder aux elements du kube 
cluster ip : interne au kube 

kube proxy va creer une ip qui sera dans ipvs sur chacun des noeuds 



4: kube-ipvs0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN group default 
    link/ether 62:3c:a3:d6:cf:be brd ff:ff:ff:ff:ff:ff
    inet 10.80.0.10/32 brd 10.80.0.10 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.80.0.1/32 brd 10.80.0.1 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.82.149.145/32 brd 10.82.149.145 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.89.116.97/32 brd 10.89.116.97 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.82.146.232/32 brd 10.82.146.232 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.93.61.50/32 brd 10.93.61.50 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.86.73.253/32 brd 10.86.73.253 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.86.109.174/32 brd 10.86.109.174 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.86.58.232/32 brd 10.86.58.232 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
[root@fso-node-02 ~]# ip r get 10.86.58.232
local 10.86.58.232 dev lo src 10.86.58.232 
    cache <local> 



[root@fso-node-02 ~]# ipvsadm -Ln |grep -A5 10.86.58.232
TCP  10.86.58.232:80 rr
  -> 10.72.62.68:8080             Masq    1      0          0         
TCP  10.86.73.253:443 rr
  -> 10.71.80.128:8443            Masq    1      0          0         
TCP  10.86.73.253:8080 rr
  -> 10.71.80.128:8080            Masq    1      0          0   

les pods pour acceder vont acceder au service qui enverra vers le bakend 

ip r ipsvc sur un node

ipvs adm -Ln |grep service
on voit notre port 
nos backend  avec le port final 



nodeport : on expose un port qui permettra de router vers le service
loadbalancer : ( c'est un élément externe ) 




si on change notre service de type clusterip en loadbalancer dans notre service une entrée external ip est créer en pending
 kctl get svc                                                                                                                               [☸ |kubernetes-admin@sandbox:echoserver]
NAME        TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
clusterip   LoadBalancer   10.86.58.232   <pending>     80:32735/TCP   30m

on a pas de service qui expose le service sur l'exterreiur

en principe un objet loadbalancer va appeller les api de cloud qui va renvoyer une ip ( ex : requette envoyé a elb < renvoit une ip 

on a un service qui est accroché a chaque noeud avec un port :
on peut donc appellé un node suivi du port dédie :

 ✘ boogie@boogieland  ~/.kube  curl http://10.121.253.208:32735                                                                                                         [☸ |kubernetes-admin@sandbox:echoserver]
CLIENT VALUES:
client_address=10.121.253.208
command=GET
real path=/
query=nil
request_version=1.1
request_uri=http://10.121.253.208:8080/

SERVER VALUES:
server_version=nginx: 1.10.0 - lua: 10001

HEADERS RECEIVED:
accept=*/*
host=10.121.253.208:32735
user-agent=curl/7.68.0
BODY:
-no body in request-%

Il nous faut donc un service pour donner une ip external.

on va pouvoir dans notre exemple ajouter une ip de service dans notre lan de test :
dans notre service :

spec:
  clusterIP: 10.86.58.232
  externalIPs:                 <<< on ajoute le champ externalIPs: et une ip de notre reseau
  - 10.121.253.211

Ceci n'est pas à faire puisque l'ip sera presente sur les noeuds via ipvs 

c'est du dépannage.

quand on creer un service de type Loadbalancer on a toujours un service nodeport de créer
