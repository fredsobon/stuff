==== Notes from puppet_essntials_2nd edition ====


== Chapitre 1 Writing  first manifests ==

= Demarrage :
 l'installation se fait via les repos des distrib ou alors directement depuis le site puppetlabs
 On peut aussi décider d'intaller puppet en ruby gem mais ce n'est pas recommandé.
Apres l'install on peut commencer à ecrire un manifest ce qui est le language / script de puppet . il est ecris endsl (domain specfic language)


on utilise pour l'instant una machine vagrant avec un client puppet installé.
On se place dans une arbo , on crée notre manifest et on le lance :

[root@client manifests]# cat helloworld.pp 
notify {'hello, world !':
}

[root@client manifests]# puppet apply helloworld.pp 
Notice: Compiled catalog for client.example.com in environment production in 0.06 seconds
Notice: hello, world !
Notice: /Stage[main]/Main/Notify[hello, world !]/message: defined 'message' as 'hello, world !'
Notice: Applied catalog in 0.02 seconds

Pour eviter de mettre la bazar sur le system on va essayer de ne pas faire démarrer auto un service : exemple puppet :) 

puppet_service.pp
service { 'puppet':
ensure => 'stopped',
enable => false,
}

[root@client manifests]# puppet apply puppet_service.pp 
Notice: Compiled catalog for client.example.com in environment production in 0.25 seconds
Notice: /Stage[main]/Main/Service[puppet]/ensure: ensure changed 'running' to 'stopped'
Notice: Applied catalog in 0.11 seconds

A noter que l'on execute les commandes puppet avec un sudo ou en root

Si on relance notre run : rien ne se passe car le service a dejà ete arreté

[root@client manifests]# puppet apply puppet_service.pp 
Notice: Compiled catalog for client.example.com in environment production in 0.24 seconds
Notice: Applied catalog in 0.03 seconds


On met ici en evidence qe puppet est un systeme indepomdent : il examine une resssoure, l'etat attendu de cette ressource et ne procede aux changements que si quelque chose n'est pas configuré comme attendu.



= Ressources et propriétés :=

Les resources sont les blocs élémentaires des manifests :chacune à un type ( exemple notify, service) et un nom , un titre ( exemple : hello world , puppet )
Chaque resource est unique dans un manifest et peut être référencées par la combinaison de son nom et son type 
Une ressource est aussi definie par un ensemble de 0 à plusieurs attributs : un attribut est un enemble clé valeur de type : "enable" => false

Attention le nom des attributs depend des ressources on ne peut pas mettre n'inporte quoi . Certains param sont dispo pour tout type de ressource (metaparametres) d'autre sont commun : ex "ensure" 

Ex le type service supporte la proprieté ensure ( status de la ressource) alors que la propriéte enable a comme scope le demarrage du system par l'os.
Les termes attributs, parametres et proprité sont utilisés de diffrentes manière.

On doit juste savoir que les param et proprietes sont deux differents type d'attributs que puppet utilise 

on voit ici deux proprités et un parametre dans le manifest suivant 

service { 'puppet':
ensure   => 'stopped',
enable   => false,
provider => 'upstart',
}

le parametre provider indique à puppe qu'il doit travailler avec upstart contrairement par exemple  systemd ou init
Sans cette definition explicite : puppet gerera le param de son choix grace a des fonctions internes

EN gros les paramètres indique à puppet commennt gérer une ressource et pas quel est l'etat désiré.

Une propriété est considére synchro avec le systeme pour une ressource donnée 

Pour mémo : les propriétes  peuvent être hors synchro  alors que les param eux ne le peuvent pas.

Puppet peut lire une config sur le systeme avec la commande puppet ressource : 


root@puppetmaster:~# puppet resource user root
user { 'root':
ensure      => 'present',
comment     => 'root',
gid         => '0',
home        => '/root',
password    => '$6$17/7FtU/$TvYEDtFgGr0SaS7xOVloWXVTqQxxDUgH. eBKJ7bgHJ.hdoc03Xrvm2ru0HFKpu1QSpVW/7o.rLdk/9MZANEGt/',
password_max_age => '99999',
password_min_age => '0',
shell => '/bin/bash',
uid => '0',
}

Interpretatin de la sortie de la commande apply 


On a lors de la sortie de commande en gros deux phases :
une premiere pour la compilation du catalogue et la seconde correspondant à l'application du catalogue


[root@client manifests]# puppet apply puppet_service.pp 
Notice: Compiled catalog for client.example.com in environment production in 0.26 seconds
Notice: Applied catalog in 0.03 seconds

0n peut avoir beaucoup plus d'info en invoquand par exemple :

[root@client manifests]# puppet apply -e'service { "puppet": enable => true, }'
Notice: Compiled catalog for client.example.com in environment production in 0.24 seconds
Notice: /Stage[main]/Main/Service[puppet]/enable: enable changed 'false' to 'true'
Notice: Applied catalog in 0.11 seconds

On voit ici qu'on forcer en commande ligne la modif de param de notre resource


- Dry run :

on va pouvoir lancer les comandes en dry run : pas d'effet on voit juste le comportement de notre run : 

[root@client manifests]# puppet apply puppet_service.pp --noop
Notice: Compiled catalog for client.example.com in environment production in 0.24 seconds
Notice: /Stage[main]/Main/Service[puppet]/enable: current_value true, should be false (noop)
Notice: Class[Main]: Would have triggered 'refresh' from 1 events
Notice: Stage[main]: Would have triggered 'refresh' from 1 events
Notice: Applied catalog in 0.03 seconds


- Structures de controle dans les manifests :

on peut comme dans les language utilisés des formes de controle .
ex : 

bloc if /else :


if 'mail_lda' in $needed_services {
service { 'dovecot': enable => true }
} else {
service { 'dovecot': enable => false }
}

Case :


case $role {
'imap_server': {
    package { 'dovecot': ensure => 'installed' }
    service { 'dovecot': ensure => 'running' }
  }
/_webserver$/: {
    service { [ 'apache', 'ssh' ]: ensure => 'running' }
  }
default: {
    service { 'ssh': ensure => running }
  }
}

on a une definiton de cas par défaut .

On peut trouver egalement une autre forme de tests de controle : les selectors : 

package { 'dovecot':
    ensure => $role ? {
    'imap_server' => 'installed',
    /desktop$/    => 'purged',
default    => 'removed',
  },
}


- Utilisation de variables : 

Toutes les variables commencent avec un $ 

$download_server = 'img2.example.net'
$url = "https://${download_server}/pkg/example_source.tar.gz"

Comme dans les autres languages on a un comportement différent si on place des ",' ...pour l'interprétation de nos variables.

Dans puppet une fois qu'une variable a été créee elle ne peut pas être modifier ( il y a une copie d'objet)

- Types de variables :

  $a_bool = true
  $a_string = 'This is a string value'
  $an_array = [ 'This', 'forms', 'an', 'array' ]
  $a_hash = {
  'subject' => 'Hashes',
  'predicate' => 'are written',
  'object'    => 'like this',
  'note'      => 'not actual grammar!',
  'also note' => [ 'nesting is',
  { 'allowed' => ' of course' } ],
}

Pour l'assignement de valeurs : c'est simple 

$x = $a_string
$y = $an_array[1]
$z = $a_hash['object']

Les strings peuvent être des attibuts de variable
il faut faire attention que le titre d'une ressource soit aussi une référence  de variable 

package { $apache_package:
ensure => 'installed'
}

on peut egalement utiliser un tableau pour déclarer tout un lot de resource dans une seule section.
ex : ici on s'assure que tous les packets mentionnés dansle tableau soient bien installés.

$packages = [ 'apache2',
    'libapache2-mod-php5',
     'libapache2-mod-passenger', ]
package { $packages:
ensure => 'installed'
}

Il n'est pas nécéssaire de stocker les valeurs du tableau dans une variable mais c'est une bonne pratique.


- Controle de l'ordre d'évaluation : 

Un manifest n'est pas un script : c'est juste un outil pour définir l'etat d'un systeme a travers differentes ressources (packages , services, fichiers, cron ...;)
Le language de puppet est déclaratif : le manifest déclare un set de resources qui doivent avoir des états  particulier .Ces ressources sont mises dans un catalogue et puppet essaie de construire le build . Le compilateur parse les manifests dans l'ordre mais le configurateur le fait dans un tout autre ordre.
Le manifest décrit ce que l'on veut obtenir : les actions spécifiques pour atteindre ce résultat sont prises par puppet.


package { 'haproxy':
    ensure => 'installed',
}
file {'/etc/haproxy/haproxy.cfg':
    ensure => file,
    owner => 'root',
    group => 'root',
    mode => '0644',
    source => 'puppet:///modules/haproxy/etc/haproxy/haproxy.cfg',
}
service { 'haproxy':
ensure => 'running',
}

Dans ce manifest puppet s'assure que le packet haproxy est installé , le fichier haproxy.cfg a un contenu particulier présent dans un repertoire module et haproxy est démarré.
Dans les versions  récentes de puppet ont peu définir l'ordre d'évaluation dans le puppet.conf
ordering = manifest
c'est la setting par defaut dans puppet4

-Déclaration de dépendances : 

Un  des moyens les plus simple pour assurer un ordre est d'utiliser un chaining de ressource : on utilise un symbole "->"


package { 'haproxy':
  ensure => 'installed',
  }
->
file { '/etc/haproxy/haproxy.cfg':
ensure => file,
owner => 'root',
group => 'root',
mode
=> '0644',
source => 'puppet:///modules/haproxy/etc/haproxy/haproxy.cfg',
}
->
service {'haproxy':
ensure => 'running',
}

Ceci  est possible si toutes les ressources peuvent être définies  dans un seul et même fichier.
Il existe des méthodes beaucoup plus fléxibles en utilisant des metaparamètres : paramètres qui sont utilisables pour differents type de resources
Pour la gestion de l'ordre des resources puppet utilisent par exemple :
before et require .
Attention on ne peut déclarer des metaparametres que sur des ressources existant dans le catalogue.

On voit ici la manifest haproxy avec l'utilisation de require :

package { 'haproxy':
   ensure => 'installed',
  }
file {'/etc/haproxy/haproxy.cfg':
ensure => file,
owner => 'root',
group => 'root',
mode  => '0644',
source => 'puppet:///modules/haproxy/etc/haproxy/haproxy.cfg',
require => Package['haproxy'],
}
service {'haproxy':
ensure => 'running',
require => File['/etc/haproxy/haproxy.cfg'],
}


Ici le même manifest est utilisant maintenant before :

package { 'haproxy':
  ensure => 'installed',
  before => File['/etc/haproxy/haproxy.cfg'],
}
file { '/etc/haproxy/haproxy.cfg':
  ensure => file,
  owner => 'root',
  group => 'root',
  mode  => '0644',
  source => 'puppet:///modules/haproxy/etc/haproxy/haproxy.cfg',
before => Service['haproxy'],
  }
service { 'haproxy':
ensure => 'running',
}

Il est courant d'utiliser require mais dans certains cas ( gestion de packages ) before peut être très pratique.

- Erreurs de propagation : la definition de require permet de definir un autre sujet important : les references sur les resources déclarées seront considérées comme valides si la dépendance initiale s'est finie correctement : c'est un "point d'arret de puppet" lorsqu'une dependance n'est pas satisfaite.
ex : on a une erreur de run si notre fichier de conf suivant n'est pas trouvé :

file { '/etc/haproxy/haproxy.cfg':
ensure => file,
source => 'puppet:///modules/haproxy/etc/haproxy.cfg',
}

root@puppetmaster:~# puppet apply typo.pp
Notice: Compiled catalog for puppetmaster.example.net in environment
production in 0.62 seconds
Error: /Stage[main]/Main/File[/etc/haproxy/haproxy.cfg]: Could not
evaluate: Could not retrieve information from environment production
source(s) puppet:///modules/haproxy/etc/haproxy.cfg
Notice: /Stage[main]/Main/Service[haproxy]: Dependency File[/etc/haproxy/
haproxy.cfg] has failures: true
Warning: /Stage[main]/Main/Service[haproxy]: Skipping because of failed
dependencies
Notice: Applied catalog in 0.06 seconds

On a donc une erreur de run : on voit ici que le service n'est pas modifié (redémarré par ex) car le fichier de conf n'est pas trouvé. : c'est donc une méthode sécure.


- Interdire les dépendances circulaires :

Il est capitale de ne pas définir de dépendances circulaires 
ex :

file { '/etc/haproxy':
ensure => 'directory',
owner => 'root',
group => 'root',
mode  => '0644',
}

file { '/etc/haproxy/haproxy.cfg':
ensure => file',
owner => 'root',
group => 'root',
mode  => '0644',
source => 'puppet:///modules/haproxy/etc/haproxy/haproxy.cfg',
}

service { 'haproxy':
ensure => 'running',
require => File['/etc/haproxy/haproxy.cfg'],
before => File['/etc/haproxy'],
}


on a ici des dépendances  a tous les niveaux : le fichier /etc/haproxy/haproxy.cfg dépend implictement de  la création du rep /etc/haproxy . Le repertoire /etc/haproxy dépend du service  haproxy et le service haproxy dépend du fichier de conf /etc/haproxy/haproxy.cfg ...

A noter :
si un fichier et un rep dépendent de la creation d'un rep superrieur : puppet le créer en auto
si un user et le groupe primaire du user sont définis : puppet crée en premier le groupe 
si un fichier et son user sont déclarés : puppet crée en premier le user 

on aura donc comme message lors de notre run une alerte de dépendance circulaire : 

root@puppetmaster:~# puppet apply circle.pp
Notice: Compiled catalog for puppetmaster.example.net in environment
production in 0.62 seconds
Error: Failed to apply catalog: Found 1 dependency cycle:
(File[/etc/haproxy/haproxy.cfg] => Service[haproxy] => File[/etc/haproxy]
=> File[/etc/haproxy/haproxy.cfg])
Try the '--graph' option and opening the resulting '.dot' file in
OmniGraffle or GraphViz

on a un message qui nous montre les dépendances . Pour les cas complexes on peut utiliser une option qui va nous aider à mieux comprendre les dépendances :

--graph option.

si on utilise  cette option puppet incluera le chemin complet de notre fichier .dot (fichier de graph) dans sa sortie

digraph Resource_Cycles {
label = "Resource Cycles"
"File[/etc/haproxy/haproxy.cfg]" ->"Service[haproxy]" ->"File[/etc/
haproxy]" ->"File[/etc/haproxy/haproxy.cfg]"
}



- Implementation des interractions de ressources :

En parallele des dépendances les ressources peuvent aussi avoir des relations 
ex: 

root@puppetmaster:~# puppet apply puppet_service.pp
--noop
Notice: Compiled catalog for puppetmaster.example.net in environment
production in 0.62 seconds
Notice: /Stage[main]/Main/Service[puppet]/ensure: current_value running,
should be stopped (noop)
Notice: Class[Main]: Would have triggered 'refresh' from 1 events
Notice: Stage[main]: Would have triggered 'refresh' from 1 events
Notice: Applied catalog in 0.05 seconds

on voit ici que le refresh devra être lancé car la ressource service aura un status changé : un event aura changé le comportement.
Le mechanisme rentrant en ligne de commpte est comparable au pub/sub queue : les resources sont configurées pour réagir a un event : on place dans  les manifests un notify : qui va donc déclencher une réaction.
Typiquement on a des reload de services quand un fichier de conf a été modifié pour un service.

ex: avec subscribe :


file { '/etc/haproxy/haproxy.cfg':
ensure => file,
owner  => 'root',
group  => 'root',
mode   => '0644',
source => 'puppet:///modules/haproxy/etc/haproxy/haproxy.cfg',
require => Package['haproxy'],
}
service { 'haproxy':
  ensure    => 'running',
  subscribe => File['/etc/haproxy/haproxy.cfg'],
}


Equivalence avec un notify :

file { '/etc/haproxy/haproxy.cfg':
  ensure => file,
  owner  => 'root',
  group  => 'root',
  mode   => '0644',
  source => 'puppet:///modules/haproxy/etc/haproxy/haproxy.cfg',
  require => Package['haproxy'],
  notify => Service['haproxy'],
}
service { 'haproxy':
  ensure => 'running',
}

On peut eventuellement utiliser la notion de dashing :

file { '/etc/haproxy/haproxy.cfg': ... }
   ~>  service { 'haproxy': ... }

La resource service est une de celle à utiliser régulierement les notify / subscribe.

- Examen des principales resources : 


-> files :

ex :

file { '/etc/modules':
  ensure => file,
  content => "# Managed by Puppet!\n\ndrbd\n",
}
The double quotes allow expansion of escape sequences such as \n.

Another useful capability is managing symbolic links:
file { '/etc/apache2/sites-enabled/001-puppet-lore.org':
ensure => 'link',
target => '../sites-available/puppet-lore.org',
}

-> package :

on va ici pouvoir avoir la notion de provider ( apt / yum ..) 
package { 'haproxy':
ensure   => present,
provider => 'dpkg',
source   => '/opt/packages/haproxy-1.5.1_amd64.dpkg',
}

-> service :
on peut gérer les services avec le provider base  qui peut gérer les process en background 

service { 'count-logins':
provider  => 'base',
ensure    => 'running',
binary    => '/usr/local/bin/cnt-logins',
start     => '/usr/local/bin/cnt-logins --daemonize',
subscribe => File['/usr/local/bin/cnt-logins'],
}

ici le service sera reloasd si la conf est changé ou le service non démarré ...(? a voir pas clair ) 


-> user / group : 

Si on a pas de gestion centralisée avec un ldap par ex , il va être crucial de gérer nos users sur nos systèmes 
On va pouvoir gérer les infos classiques ( /home , bash ,uid ...) 


group { 'proxy-admins':
ensure => present,
gid    => 4002,
}
user { 'john':
ensure        => present,
uid           => 2014,
home          => '/home/john'
managehome    => true, # <- adds -m to useradd
gid           => 1000,
shell         => '/bin/zsh',
groups        => [ 'proxy-admins' ],
}

Il est toujours nécéssaire de définir un group avant le user ..comme in faut un repertoire pour ecrire un fichier à l'interrieur.

NB  : si un attribut n'est pas gérer pour la resource user : le run ne sera pas cassé mais un warning apparaitra.

-> exec : 

il peut être  utile dans certains cas d'utiliser la commande exec mais c'est en général à proscrire : ce n'est pas le rôle de puppet :


exec { 'tar cjf /opt/packages/homebrewn-3.2.tar.bz2':
cwd     => '/opt',
path    => '/bin:/usr/bin',
creates => '/opt/homebrewn-3.2',
}

ici creates est important car nous indique l'endroit ou la commande doit être executée : une fois crééer puppet considere la conf updatée 

Il est possible de spécifier des param spéciaux pour puppet et gérer des cas . On peut utiliser unlessou onlyif.
ex :

exec { 'perl -MCPAN -e "install YAML"':
path   => '/bin:/usr/bin',
unless => 'cpan -l | grep -qP ^YAML\\b',
}

ici la command exec sera en echec si le retour de unless est vrai : pas d'install de module perl si le package est trouvé .
On va aussi pour la resource  exec utiliser les param notify et subscribe :

exec { 'apt-get update':
path        => '/bin:/usr/bin',
subscribe   => File['/etc/apt/sources.list.d/jenkins.list'],
refreshonly => true,
}


On va pouvoir avoir des infos :

"puppet describe <type> [-s]
In case you are unsure whether a type exists, you can tell Puppet
describe to return a full list of all available resource types:
puppet describe --list"


-> cron :

on va pouvoir gérer nos cronjobs :

cron { 'clean-files':
ensure      => present,
user        => 'root',
command     => '/usr/local/bin/clean-files',
minute      => '1',
hour        => '3',
weekday     => [ '2', '6' ],
environment => 'MAILTO=felix@example.net',
}


On peut ajouter des variables dédiées à notre cron en utilisant le param "environment" 

-> mount :

on va pouvoir gérer nos points de montage  avec les infos essentielles (device, mountpoint ..)

La traduction d'une ligne de fstab pourra être faite comme ceci :

mount { '/media/gluster-data':
ensure  => 'mounted',
device  => 'gluster01:/data',
fstype  => 'glusterfs',
options => 'defaults,_netdev',
dump    => 0,
pass    => 0,
}

pour cette resource puppet va s'assurer que la resource est bien montée et dispo après le run 


== Chapter 2 : puppet server / agent ==

l'utilisation de puppet apply est parfaite pour tester des confs en local .mais c'est souvent la notion master / agent qiu est utilisée. le master compile le catalogue que l'agent vient récupérer régulièrement via une connection ssl.

- master :

-> il comporte toutes les infos de tous les systemes gérés.
-> stocke les manifests et les compilation de catalogue 
-> sert d'authorité de certif
-> génère les rapports  des agents.
-> recupere les infos des agents

A l'initialisation le master génere un ca certificate pour les agents .Le certif est autosigné et la clé priv de puppet doit être protégé .
Les nouveaux clients demandent un certif qui est signé avec la ca du master

c'est une bonne pratique de copietr la ca dans notre provisionning : pour gérer facilement la signature du certif après la validation de l'identité  du master 

Anciennement avant puppet 4 on parlait de master : la gestion ssl etait faite par apache et un module passenger 
maintenant puppet embarque du jruby qui embarque du ssl natif servi par une jvm jetty 

puppetserver est donc plus rapide et stable 



= set up de server : =

Il est relativement simple d'installer le puppetserver : packages de distributions classiques.
On peut aussi installer l'appli via la puppet collection : eco systeme mis a dispo par puppetlabs contenant donc les outils. : ceci est disponible depuis la v4 de puppet.
le package puppetserver contient un server jetty et une api clojure. le package puppet-agent contient tout un lot de composants : ruby etc ...
On peut lancer la commande puppet sur le master également.

En utilsant les version de puppetlabs : il faut s'aassurer de rajouter dans notre path l'arbo dédiée :
/opt/puppetlabs + /opt/puppetlabs/bin
on démarre notre appli ensuite comme ceci : 
root@puppetmaster# service puppetserver start 

Le boot peut être long la première fois. Il faut s'assurer que le port 8140 ne soit pas filtrer sur le fw.
Il est possible d'avoir un souci de certif que l'on peut observer dans :
/var/log/puppetlabs/puppetserver/puppetserver-daemon.log
pour fixer le pb il peut être possible de lancer un run comme ceci :

puppet master –-no-daemonize

- Creation du manifest master :

Le point de départ de toutes les compilations se trouvent dans un fichier fondamental :
he site manifest, which can be found in /opt/
puppetlabs/code/environments/production/manifests/site.pp

Tous les agents vont se connecter à ce point d'entrée :
on va pouvoir faire le distingo entre les besoins de chaque server en specifiant des confs dédiées :

node 'agent' {
$packages = [ 'apache2',
  'libapache2-mod-php5',
  'libapache2-mod-passenger', ]
  package { $packages:
  ensure => 'installed',
  before => Service['apache2'],
  }
  service { 'apache2':
  ensure => 'running',
  enable => true,
 }
}
Avant de connecter notre premier node au master on doit s'assurer de points essentiels :

-> les agents doivent résoudre les noms en ip
-> le master doit ecouter les connections entrantes sur cette adresse
-> le master utilise le certificat avec le CN common name choisi (ou SAN) 

La resolution de nom depend des circonstances ( le fichier hosts ..peut convenir )

Le master va créer un certif pour le client et l'utiliser par la suite.Il faut pour cela renseigner dans notre fichier de conf principal :/etc/puppetlabs/puppet/puppet.conf la section suivante : 

[master]
certname=master.example.net   <<< on met ici le fqdn correspondant à nos besoins.

Après le prochain redémmarage tous les connection entre le server et les clients se feront avec le ssl dédié.
Attention si on change notre CA : il ya aura un pb global .
Il faut donc s'assurer que la ca sera correctement préservée :

/etc/puppetlabs/puppet/ssl/ca

- Inspection de la configuration : 

on va pouvoir utiliser une commande dédiée pour examiner la config :

root@puppetmaster # puppet master --configprint manifest
/etc/puppetlabs/code/environments/production/manifests

Il est possible d'examiner la conf globale sans souci :

root@puppetmaster# puppet master --configprint all | less

...

- Config de l'agent puppet :

Des l'install du package on peut lancer un test :

root@agent# puppet agent --test
Info: Creating a new SSL key for agent
Error: Could not request certificate: getaddrinfo: Name or service not
known
Exiting; failed to retrieve certificate and waitforcert is disabled

Puppet dans un premier temps crée une clé de  certif ssl pour lui même :pour son propre nom il récupère son hostname 
Il faudra donc eventuellement renseigner le fichier hosts  


root@agent# puppet agent --test
Info: Caching certificate for ca
Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_
attributes.yaml
Info: Creating a new SSL certificate request for agent
Info: Certificate Request fingerprint (SHA256): 52:65:AE:24:5E:2A:C6:17:E
2:5D:0A:C9: 86:E3:52:44:A2:EC:55:AE:3D:40:A9:F6:E1:28:31:50:FC:8E:80:69
Error: Could not request certificate: Error 500 on SERVER: Internal
Server Error: java.io.FileNotFoundException: /etc/puppetlabs/puppet/ssl/
ca/requests/agent.pem (Permission denied)
Exiting; failed to retrieve certificate and waitforcert is disabled

ici on voit que le client a créer une deman,de de certificat et l'a envoyé au master
Il est possible de définir une conf pour autosigner les certifs 

pour examiner le cert du master et pour le signer on peut faire :

root@puppetmaster# puppet cert --list
"agent" (SHA256) 52:65:AE:24:5E:2A:C6:17:E2:5D:0A:C9:86:E3:52:44:A2:EC:55
:AE: 3D:40:A9:F6:E1:28:31:50:FC:8E:80:69
This looks alright, so now you can sign a new certificate for the agent:


root@puppetmaster# puppet cert --sign agent
Notice: Signed certificate request for agent
Notice: Removing file Puppet::SSL::CertificateRequest agent at '/etc/
puppetlabs/ puppet/ssl/ca/requests/agent.pem'


On ppeut donc maintenant lancer notre run sur notre server  :

root@agent# puppet agent --test
Info: Caching certificate for agent
Info: Caching certificate_revocation_list for ca
Info: Caching certificate for agent
Info: Retrieving pluginfacts
Info: Retrieving plugin
Info: Caching catalog for agent
Info: Applying configuration version '1437065761'
Notice: Applied catalog in 0.11 seconds

Nb: ici on a déclarer pour l'exemple que le master puppet devait utiliser le  nom : master.example.net
les run pourront fonctionner sur le master si la version est puppet4 :car depuis cette version le certificate alt name "puppet" est maintenant configuré de base dans la conf.
Il est important de toujours avoir un fqdn bien défini pour notre server :
on peut rajouter la conf suivante : 
[main]
server=master.example.net

Evidemment si on a pas de dns ..les entrées dans le fichier host sont fondamentales.


Attention : il faut avoir des synchro de dates en regles : des conf ntp peuvent souvent régler des soucis ssl 

= Cycle de vie de l'agent : =

Des qu'on va recycler un serveur on va devoir supprimer le certificat etabli avec la commande :

root@puppetmaster# puppet cert revoke agent 
Le server va enregistrer dans une liste les certificats revoqués : le client quand il voudra se connecter se fera recaller.

Si on a besoin de regénérer un certificat (pb sur un serveur ou autre ) ..il nous faudra regénérer un certificat 
L'opération se fera en deux etapes :

1/ sur le master : 

puppet cert clean agent.example.net

2/ sur le client : 

find /etc/puppetlabs/puppet/ssl -name agent.example.net.pem –delete



root@puppetmaster# puppet cert clean agent


= Planifier les run puppet : =

On va pouvoir facilement gérer les run puppet grace un une cron créee sous puppet :

service { 'puppet': enable => false }
cron { 'puppet-agent-run':
user    => 'root',
command => 'puppet agent --no-daemonize --onetime --logdest=syslog',
minute  => fqdn_rand(60),
hour    => absent,
}

On voit ici l'utilisation de la fonction fqdn_rand(60) : qui va générer un nombre aléatoire pour le node .
Le fait de flagguer le param hour à absent de fait fait tourner la cron toutes les heures.

= Performance considerations : =

Le fait de travailler en mode server / client a des avantages mais il faut faire attention a ne pas générer trop de charge sur le server. Le cleint puppet : agent génére le max de travail mais la compilation du catalogue reste à la charge du server .

Le master va aussi héberger les sources des fdichiers de conf de nos servers .
ex :

file { '/usr/local/etc/my_app.ini':
ensure => file,
owner => 'root',
group => 'root',
source => 'puppet:///modules/my_app/usr/local/etc/my_app.ini',
}

Il sera potentiellemennt nécéssaire d'optimiser nos conf server si la charge devient trop importante.


= config de server =

Des param simples peuvent changer les perf du puppetserver 

Il va être important de configurer la jvm de notre puppet en jouant sur les param :-Xmx and -Xms

Il va ausso être important de prendre en compte la puppetdb 
elle est classiquement en postgresql et permet des actions via une api clojure .
La puppetdb aide le master a stocker les favts etc ..;


=== Chapitre 3 :  Facts / types et providers ===

= facts =

La gestion hétérogène de materiel et de différents écosystem peut rendre complexe  la gestion des système.
Il va être interressant d'utiliser facter qui va pouvoir nous fournir énormément d'informations sur le system, hardware etc  ..

exemple :

puppet apply -e 'notify { "I am ${::fqdn} and have ${::processorcount} CPUs": }' 
va nous donner au run :

[root@client ~]# puppet apply -e 'notify { "I am ${::fqdn} and have ${::processorcount} CPUs": }'
Notice: Compiled catalog for client.example.com in environment production in 0.06 seconds
Notice: I am client.example.com and have 1 CPUs
Notice: /Stage[main]/Main/Notify[I am client.example.com and have 1 CPUs]/message: defined 'message' as 'I am client.example.com and have 1 CPUs'
Notice: Applied catalog in 0.02 seconds

Acceder et utiliser des valeurs de facter :

Chaque fact est accessible comme une variable globale :c'est pour cela que l'on utilise la notation ::processorcount par exemple.
Il est courant de voir la notation suivante (qui fait partie d'une best practice) $::processorcount et qui correspond aux variables facter 
Ce prefix indique que l'on accede à une donnée exposée par facter 

On va biensur avoir plusieurs facts dispos :
ex :

file { '/etc/mysql/conf.d/bind-address':
ensure  => 'file',
mode    => '0644',
content => "[mysqld]\nbind-address=${::ipaddress}\n",


$::operatingsystem
$::osfamilly
$::operatingsystemrelease 

[root@client ~]# puppet apply -e 'notify { "oh yeah ${::osfamily}: cool":}'
Notice: oh yeah RedHat: cool


Creation et personalisation  de facts : 

on peut sans  pb créer nos facts perso .Il y a pour les fact un design assez simple : un bloc ruby pour chaque section et des données en retour du bloc qui est un fact 

vi /etc/puppetlabs/code/environments/production/modules/hello_world/lib/facter/hello.rb
Facter.add(:hello) do
setcode { "Hello, world!" }
end

la valeur du bloc setcode est donc "Hello, world!" et on peut appeller ce fact $::hello dans un manifest.
Les facts peuvent être dépendant les un des autres.

root@client facter]# puppet apply -e 'notify {"oh Yeah ${::hello}":}'
Notice: Compiled catalog for client.example.com in environment production in 0.06 seconds
Notice: oh Yeah Hello, world!
Notice: /Stage[main]/Main/Notify[oh Yeah Hello, world!]/message: defined 'message' as 'oh Yeah Hello, world!'
Notice: Applied catalog in 0.02 seconds

Il est tres important d'avoir l'option pluginsync de configurée sur le client cela permet d'avoir une synchro des facts entre le master et les clients : une fois synchro les facts sont présentssur le client .

On peut interroger nos fact facilement : 

[root@client facter]# puppet facts |grep hello
    "hello": "Hello, world!",

On peut definir des facts selon nos besoin et en utilisant des méthodes :

Facter.add(:msvs_version) do
    confine :kernel => :windows
        setcode do
    # ...
    end
end

You can confine a fact to several alternative values as well:
confine :kernel => [ :linux, :sunos ]

On peut simplifier au quotidien l'utilisatin de facter en se servant des external facts : ce qui va nous permettre de ne pas être obliger d'ecrire du code ruby mais du shell, python ou autre voir même définir des data statiques.

Les external facts doivent être stocker dans une arbo preciose :

/etc/puppetlabs/facter/facts.d/
les data ne doivent pas être simplement des strings mais peuvent aussi etre sous la forme clé / valeur 

les format peuvent être en ini ou yaml / json 

# site-facts.txt
workgroup=CT4Site2
domain_psk=nm56DxLp%
The facts can be written in the YAML format in the following way:
# site-facts.yaml
workgroup: CT4Site2
domain_psk: nm56DxLp%

# site-facts.json
{ 'workgroup': 'CT4Site2', 'domain_psk': 'nm56DxLp%' }
The deployment of the external facts works simply through file resources in your
Puppet manifest:
file { '/etc/puppetlabs/facter/facts.d/site-facts.yaml':
ensure => 'file',
source => 'puppet:///...',



Dans les versions récentes de puppet tous les external facts présents dans tous les modules seront synchronisé via le pluginsysn comme les custom facts.

Quand il n'est pas possible d'ecrire des fichiers txt, json ou yaml : il est tout a fait possible de créer un fichier executable et de rajouter un shebang et la sortie du script doit sortie une valeur 
La seule condition est d'avoir un fichier sous la forme de fichier ini : cle=valeur 

ex : 

[root@client hello_world]# cat facts.d/hello.sh 
#!/bin/bash

echo hello=Hello, world from external fact\!

va nous donner au run : 

[root@client hello_world]# puppet apply -e 'notify {"yep it is ${::hello}":}'
Notice: Compiled catalog for client.example.com in environment production in 0.06 seconds
Notice: yep it is Hello, world from external fact!
Notice: /Stage[main]/Main/Notify[yep it is Hello, world from external fact!]/message: defined 'message' as 'yep it is Hello, world from external fact!'
Notice: Applied catalog in 0.02 seconds

Facter2 a introduit des données structurées : array, dictionnaires ...
Le but de facter est de rendre puppet agnostic : ne pas dependre d'un systeme / hardware spécifique 

= Comprehension de type : =

Une fois que le catalogue est compilé le master le met a dispo de l'agent qiu lui va entrer dans  une phase de validation : chaque type de ressource peut defoinir des  methodes ruby qui examineront que les valeurs reçues sont cohérentes.
ex : une gestion de clé ssh s'assurera que le contenu de la clé ne contient pas  d'espace : le type ssh_authorized_key tombe ko si la clé contient un espace : une clé  ssh ne contenant pas plusieurs caractères.

La validation entiere de ressource comme cron sera faite pour s'assurer que les moments  définis sont cohérents.
ex  : ici le test tombera en erreur car ici midnight ne peut pas être cominé avec des champs numériques :

cron { 'invalid-resource':
command => 'apt-get update',
special => 'midnight',
weekday => [ '2', '5' ],
}

= providers : =
on va être ammené à gérer plusieurs systemes ..qui veut fournir des provider : apt, yum, zypper etc ..gem , pip ..
Il ya a certains type de resources qui n'utilisent aucun provider
pour les taches les plus classiques ont peut avoir un provider : ex pour la gestion du fichier /etc/hosts 

ex: 

host { 'puppet':
ip
=> '10.144.12.100',
host_aliases => [ 'puppet.example.net', 'master' ],
}

== Modularization de manifests avec les classes et les defined types : ==




