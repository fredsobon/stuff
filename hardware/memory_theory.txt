
Memory – Part 1: Memory Types
July 3, 2013, by Florent Bruneau	

    1 Introduction
    2 Virtual Memory
        2.1 fork()
        2.2 Pages
    3 Memory Types
        3.1 Private Memory
        3.2 Shared Memory
        3.3 Anonymous Memory
        3.4 File-backed and Swap
    4 Next: Resident Memory and Tools

Introduction

At Intersec we chose the C programming language because it gives us a full control on what we’re doing, and achieves a high level of performances. For many people, performance is just about using as few CPU instructions as possible. However, on modern hardware it’s much more complicated than just CPU. Algorithms have to deal with memory, CPU, disk and network I/Os… Each of them adds to the cost of the algorithm and each of them must be properly understood in order to guarantee both the performance and the reliability of the algorithm.

The impact of CPU (and as a consequence, the algorithmic complexity) on performances is well understood, as are disk and network latencies. However the memory seems much less understood. As our experience with our customers shows, even the output of widely used tools, such as top, are cryptic to most system administrators.

This post is the first in a series of five about memory. We will deal with topics such as the definition of memory, how it is managed, how to read the output of tools… This series will address subjects that will be of interest for both developers and system administrators. While most rules should apply to most modern operating systems, we’ll talk more specifically about Linux and the C programming language.

We’re not the first ones to write about memory. In particular, we’d like to highlight the high quality paper by Ulricht Drepper: What every programmer should know about memory.

This first post will provide a definition of memory. It supposes at least a basic knowledge of notions such as an address or a process. It also often deals with subjects such as system calls and the difference between user-land and kernel mode, however, what you need to know is that your process (user-land) runs above the kernel that itself talks to the hardware, and that system calls let your process talks to the kernel in order to request more resources. You can get details about the system calls by reading their respective manual pages.
Virtual Memory

On modern operating systems, each process lives in its own memory allocation space. Instead of mapping memory addresses directly to hardware addresses, the operating system serves as a hardware abstraction layer and creates a virtual memory space for each process. The mapping between the physical memory address and the virtual address is done by the CPU using a per-process translation table maintained by the kernel (each time the kernel changes the running process on a specific CPU core, it changes the translation table of that CPU).

Virtual memory has several purposes. First, it allows process isolation. A process in userland can only express memory accesses as addresses in the virtual memory. As a consequence it can only access data that has been previously mapped in its own virtual space and thus cannot access the memory of other processes (unless explicitly shared).

The second purpose is the abstraction of the hardware. The kernel is free to change the physical address to which a virtual address is mapped. It can also choose not to provide any physical memory for a specific virtual address until it becomes actually needed. Moreover it can swap out the memory to disk when it has not been used for a long time and the system is getting short of physical memory. This globally gives a lot of freedom to the kernel, its only constraint is that when the program reads the memory it actually finds what it previously wrote there.

The third purpose is the possibility to give addresses to things that are not actually in RAM. This is the principle behind mmap and mapping files. You can give a virtual memory address to a file so that it can be accessed as if it was a memory buffer. This is a very useful abstraction that helps keeping the code quite simple and, since on 64-bit systems you have a huge virtual space1, if you want, you can map your whole hard drive to the virtual memory.

The fourth purpose is sharing. Since the kernel knows what process is mapped in virtual space of the various running processes, it can avoid loading stuff twice in memory and make the virtual addresses of processes that use the same resources point to the same physical memory (even if the actual virtual address is specific to each process). A consequence of sharing is the use of copy-on-write (COW) by the kernel: when two processes use the same data but one of them modifies it while the other one is not allowed to see the change, the kernel will make the copy when the data get modified. More recently, operating systems have also gained the ability to detect identical memory in several address spaces and automatically make them map to the same physical memory (marking them as subject to COW)2, on Linux this is called KSM (Kernel SamePage Merging).
fork()

The best known use case of COW is fork(). On Unix-like systems, fork() is the system call that creates a process by duplicating the current one. When fork() returns, both processes continue at exactly the same point, with the same opened files and the same memory. Thanks to COW, fork() will not duplicate the memory of a process when you fork it, only data that are modified by either the parent of the child get duplicated in RAM. Since most uses of fork() are immediately followed by a call to exec() that invalidates the whole virtual memory addressing space, the COW mechanism avoids a full useless copy of the memory of the parent process.

Another side effect, is that fork() creates a snapshot of the (private) memory of a process at little cost. If you want to perform some operation on the memory of a process without taking the risk of it to be modified under your feet, and don’t want to add a costly and error-prone locking mechanism, just fork, do your work and communicate the result of your computation back to your parent process (by return code, file, shared memory, pipe, …).

This will work extremely well as long as your computation is fast-enough so that a large part of the memory remains shared between both the parent and the child processes. This also helps keeping your code simple, the complexity is hidden in the virtual-memory code of the kernel, not in yours.
Pages

The virtual memory is divided in pages. The size of a page size is imposed by the CPU and is usually 4KiB3. What this means is that memory management in the kernel is done with a granularity of a page. When you require new memory, the kernel will give you one or more pages, when you release memory, you release one or more pages… Every finer-grained API (e.g. malloc) is implemented in user land.

For each allocated page, the kernel keeps a set of permissions: the page can be readable, writable and/or executable (note that not all combinations are possible). These permissions are set either while mapping the memory or by using the mprotect() system call afterward. Pages that have not been allocated yet, are not accessible. When you try to perform a forbidden action on a page (for example, reading data from a page without the read permission), you’ll trigger (on Linux) a Segmentation Fault. As a side note, you may see that since the segmentation fault has a granularity of a page, you may perform out-of-buffer accesses that don’t lead to a segfault.
Memory Types

Not all memory allocated in the virtual memory space is the same. We can classify it through two axis: the first axis is whether memory is private (specific to that process) or shared, the second axis is whether the memory is file-backed or not (in which case it is said the be anonymous). This creates a classification with 4 memory classes:
	Private 	Shared
Anonymous 	

1

stack
malloc()
mmap(ANON, PRIVATE)
brk()/sbrk()
1
2
3
4
	
stack
malloc()
mmap(ANON, PRIVATE)
brk()/sbrk()

	2 

mmap(ANON, SHARED)
1
	
mmap(ANON, SHARED)

File-Backed 	

3

mmap(fd, PRIVATE)
binary/shared libraries
1
2
	
mmap(fd, PRIVATE)
binary/shared libraries

	

4

mmap(fd, SHARED)
1
	
mmap(fd, SHARED)

Private Memory

Private memory is, as its name says, memory that is specific to the process. Most of the memory you deal with in a program is actually private memory.

Since changes made in private memory are not visible to other processes, it is subject to copy-on-write. As a side-effect, this means that even if the memory is private, several processes might share the same physical memory to store the data. In particular, this is the case for binary files and shared libraries. A common misbelief is that KDE takes a lot of RAM because every single process loads Qt and the KDElibs, however, thanks to the COW mechanism, all the processes will use the exact same physical memory for the read-only parts of those libs.

In case of file-backed private memory, the changes made by the process are not written back to the underlying file, however changes made to the file may or may not be made available to the process.
Shared Memory

Shared memory is something designed for inter-process communication. It can only be created by explicitly requesting it using the right mmap() call or a dedicated call (shm*). When a process writes in a shared memory, the modification is seen by all the processes that map the same memory.

In case the memory is file-backed, any process mapping the file will see the changes in the file since those changes are propagated through the file itself.
Anonymous Memory

Anonymous memory is purely in RAM. However, the kernel will not actually map that memory to a physical address before it gets actually written. As a consequence, anonymous memory does not add any pressure on the kernel before it is actually used. This allows a process to “reserve” a lot of memory in its virtual memory address space without really using RAM. As a consequence, the kernel lets you reserve more memory than actually available. This behavior is often referenced as over-commit (or memory overcommitment).
File-backed and Swap

When a memory map is file-backed, the data is loaded from the disk. Most of the time, it is loaded on demand, however, you can give hints to the kernel so that it can prefetch memory ahead of read. This helps keeping your program snappy when you know you have a particular pattern of accesses (mostly sequential accesses). In order to avoid using too much RAM, you can also tell the kernel that you don’t care to have the pages in RAM anymore without unmapping the memory. All this is done using the madvise() system call.

When the system falls short of physical memory, the kernel will try to move some data from RAM to the disk. If the memory is file-backed and shared, this is quite easy. Since the file is the source of the data, it is just removed from RAM, then the next time it will be read, it will be loaded from the file.

The kernel can also choose to remove anonymous/private memory from RAM. In which case that data is written in a specific place on disk. It’s said to be swapped out. On Linux, the swap is usually stored in a specific partition, on other systems this can be specific files. Then, it just works the same way it works for file-backed memory: when it gets accessed, it is read from the disk and reloaded in RAM.

Thanks to the use of a virtual addressing space, swapping pages in and out is totally transparent for the process… what is not, though, is the latency induced by the disk I/O.
Next: Resident Memory and Tools

We’ve covered here some important notions about memory. While we talked a few times about physical memory and the difference with reserved address spaces, we avoided dealing with the actual memory pressure of the process. We will address that topic and describe some tools that let you understand the memory consumption of a process in the next article.

== part 2 :


Memory – Part 2: Understanding Process memory
July 27, 2013, by Florent Bruneau	

    1 From Virtual to Physical
    2 top: process statistics
        2.1 Trivial columns
        2.2 Shared memory
        2.3 Data
        2.4 Swap
    3 pmap: detailed mapping
        3.1 Basic content
        3.2 Extended content
    4 More?
    5 Next: Allocating memory

From Virtual to Physical

In the previous article, we introduced a way to classify the memory a process reclaimed. We used 4 quadrants using two axis: private/shared and anonymous/file-backed. We also evoked the complexity of the sharing mechanism and the fact that all memory is basically reclaimed to the kernel.

Everything we talked about was virtual. It was all about reservation of memory addresses, but a reserved address is not always immediately mapped to physical memory by the kernel. Most of the time, the kernel delays the actual allocation of physical memory until the time of the first access (or the time of the first write in some cases)… and even then, this is done with the granularity of a page (commonly 4KiB). Moreover, some pages may be swapped out after being allocated, that means they get written to disk in order to allow other pages to be put in RAM.

As a consequence, knowing the actual size of physical memory used by a process (known as resident memory of the process) is really a hard game… and the sole component of the system that actually knows about it is the kernel (it’s even one of its jobs). Fortunately, the kernel exposes some interfaces that will let you retrieve some statistics about the system or a specific process. This article enters into the depth of the tools provided by the Linux ecosystem to analyze the memory pattern of processes.

On Linux, those data are exposed through the /proc file-system and more specifically by the content of /proc/[pid]/. These directories (one per process) contain some pseudo-files that are API entry points to retrieve information directly from the kernel. The content of the /proc directory is detailed in proc(5) manual page (this content changes from one Linux version to another).

The human front-end for those API calls are tools such as procps (ps, top, pmap…). These tools display the data retrieved from the kernel with little to no modification. As a consequence they are good entry points to understand how the kernel classifies the memory. In this article we will analyze the memory-related outputs of top and pmap.
top: process statistics

top is a widely known (and used) tool that allows monitoring the system. It displays one line per process with various columns that may contain CPU related, memory related, or more general information.

When running top, you can switch to the memory view by pressing G3. In that view, you will find, among others, the following columns: %MEM, VIRT, SWAP, RES, CODE, DATA, SHR. With the exception of SWAP, all these data are extracted from the file /proc/[pid]/statm that exposes some memory related statistics. That file contains 7 numerical fields: size (mapped to VIRT), resident (mapped to RES), share (mapped to SHR), text (mapped to CODE), lib (always 0 on Linux 2.6+), data (mapped to DATA) and dt (always 0 on Linux 2.6+, mapped to nDrt).
Trivial columns

As you may have guessed, some of these columns are trivial to understand. VIRT is the total size of the virtual address space that has been reserved by the process so far. CODE is the size of the executable code of the binary executed by the process. RES is the resident set size, that is the amount of physical memory the kernel considers assigned to the process. As a direct consequence, %MEM is strictly proportional to RES.

The resident set size is computed by the kernel as the sum of two counters. The first one contains the number of anonymous resident pages (MM_ANONPAGES), the second one is the number of file-backed resident pages (MM_FILEPAGES). Some pages may be considered as resident for more than one process at once, so the sum of the RES may be larger than the amount of RAM effectively used, or even larger than the amount of RAM available on the system.
Shared memory

SHR is the amount of resident sharable memory of the process. If you remember well the classification we made in the previous article, you may suppose this includes all the resident memory of the right column. However as already discussed, some private memory may be shared too. So, in order to understand the actual meaning of that column, we must dig a bit deeper in the kernel.

The SHR column is filled with the shared field of /proc/[pid]/statm which itself is the value of the MM_FILEPAGES counter of the kernel, which is one of the two components of the resident size. This just means that this column contains the amount of file-backed resident memory (thus including quadrant 3 and 4).

That’s pretty cool… however remember quadrant 2: shared anonymous memory does exist… the previous definition only includes file-backed memory… and running the following test program shows that the shared anonymous memory is taken into account in the SHR column:
#include <sys/mman.h>
#include <unistd.h>
#include <stdint.h>

int main()
{
    /* mmap 50MiB of shared anonymous memory */
    char *p = mmap(NULL, 50 << 20, PROT_READ | PROT_WRITE,
                   MAP_ANONYMOUS | MAP_SHARED, -1, 0);

    /* Touch every single page to make them resident */
    for (int i = 0; i < (50 << 20) / 4096; i++) {
        p[i * 4096] = 1;
    }

    /* Let us see the process in top */
    sleep(1000000);

    return 0;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
	
#include <sys/mman.h>
#include <unistd.h>
#include <stdint.h>
 
int main()
{
    /* mmap 50MiB of shared anonymous memory */
    char *p = mmap(NULL, 50 << 20, PROT_READ | PROT_WRITE,
                   MAP_ANONYMOUS | MAP_SHARED, -1, 0);
 
    /* Touch every single page to make them resident */
    for (int i = 0; i < (50 << 20) / 4096; i++) {
        p[i * 4096] = 1;
    }
 
    /* Let us see the process in top */
    sleep(1000000);
 
    return 0;
}

top indicates 50m in both the RES and the SHR columns1…

This is due to a subtlety of the Linux kernel. On Linux, a shared anonymous map is actually file-based. The kernel creates a file in a tmpfs (an instance of /dev/zero). The file is immediately unlinked so it cannot be accessed by any other processes unless they inherited the map (by forking). This is quite clever since the sharing is done through the file layer the same way it’s done for shared file-backed mappings (quadrant 4).

A last point, since private file-backed pages that are modified don’t get synced back to disk, they are not file-backed anymore (the are transferred from MM_FILEPAGES counter to MM_ANONPAGES). As a consequence, they don’t account in the SHR anymore.

Note that the man page of top is wrong since it states that SHR may contain non-resident memory: the amount of shared memory available to a task, not all of which is typically resident. It simply reflects memory that could be potentially shared with other processes.
Data

The meaning of the DATA column is quite opaque. The documentation of top states “Data + Stack”… which does not really help since it does not define “Data”. Thus we’ll need to dig once again into the kernel.

That field is computed by the kernel as a difference between two variables: total_vm which is the same as VIRT and shared_vm. shared_vm is somehow similar to SHR in that it shares the definition of the shareable memory, but instead of only accounting the resident part, it contains the sum of all addressed file-backed memory. Moreover, the count is done at the mapping level, not the page one, thus shared_vm does not have the same subtlety as SHR for the modified private file-backed memory. As a consequence shared_vm is the sum of the quadrants 2, 3 and 4. This means that the difference between total_vm and shared_vm is exactly the content of quadrant 1.

The DATA column contains the amount of reserved private anonymous memory. By definition, the private anonymous memory is the memory that is specific to the program and that holds its data. It can only be shared by forking in a copy-on-write fashion. It includes (but is not limited to) the stacks and the heap2. This column does not contain any piece of information about how much memory is actually used by the program, it just tells us that the program reserved some amount of memory, however that memory may be left untouched for a long time.

A typical example of a meaningless DATA value is what happens when a x86_64 program compiled with Address Sanitizer is launched. ASan works by reserving 16TiB of memory, but only use 1 byte of those terabytes per 8-bytes word of memory actually allocated by the process. As a consequence, the output of top looks like this:
3 PID %MEM  VIRT    SWAP RES   CODE  DATA    SHR  COMMAND
16190 0.687 16.000t 0    56056 13784 16.000t 2912 zchk-asan
1
2
	
3 PID %MEM  VIRT    SWAP RES   CODE  DATA    SHR  COMMAND
16190 0.687 16.000t 0    56056 13784 16.000t 2912 zchk-asan

Note that the man page of top is once again wrong since it states that DATA is the amount of physical memory devoted to other than executable code, also known as the ‘data resident set’ size or DRS; and we just saw that DATA has no link at all with resident memory.
Swap

SWAP is somehow different from the other ones. That column is supposed to contain the amount of memory of the process that gets swapped out by the kernel. First of all, the content of that column totally depends on both the version of Linux and the version of top you are running. Prior to Linux 2.6.34, the kernel didn’t expose any per-process statistics about the number of pages that were swapped out. Prior to top 3.3.0, top displayed a totally meaningless information here (but that was in accordance with the man page). However, if you use Linux 2.6.34 or later with top 3.3.0 or later, that count is actually the number of pages that were swapped out.

If your top is too old, the SWAP column is filled with the difference between the VIRT and the RES column. This is totally meaningless because that difference effectively contains the amount of memory that has been swapped out, but it also includes the file-backed pages that get unloaded or the pages that are reserved but untouched (and thus have not been actually allocated yet). Some old Linux distributions still have a top with that buggy SWAP value, among them stands the still widely used RHEL5.

If your top is up-to-date but your kernel is too old, the column will always contain 0, which is not really helpful.

If both your kernel and your top are up-to-date, then the column will contain the value of the field VmSwap of the file /proc/[pid]/status. That is maintained by the kernel as a counter that gets incremented each time a page is swapped out and decremented each time a page get swapped in. As a consequence it is accurate and will provide you with an important piece of information: basically if that value is non-0, this means your system is under memory pressure and the memory of your process cannot fit in RAM.

The man page describes SWAP as the non-resident portion of a task’s address space, which is what was implemented prior to top 3.3.0, but has nothing to do with the actual amount of memory that has been swapped out. On earlier versions of top, the man page properly explains what is displayed, however the SWAP naming is not appropriate.
pmap: detailed mapping

pmap is another kind of tool. It goes deeper than top by displaying information about each separate mapping of the process. A mapping, in that view is a range of contiguous pages having the same backend (anonymous or file) and the same access modes.

For each mapping, pmap shows the previously listed options as well as the size of the mapping, the amount of resident pages as well as the amount of dirty pages. Dirty pages are pages that have been written to, but have not been synced back to the underlying file yet. As a consequence, the amount of dirty pages is only meaningful for mappings with write-back, that is shared file-backed mappings (quadrant 4).

The source of pmap data can be found in two human-readable files: /proc/[pid]/maps and /proc/[pid]/smaps. While the first file is a simple list of mappings, the second one is a more detailed version with a paragraph per mapping. smaps is available since Linux 2.6.14, which is old enough to be present on all popular distributions.

pmap usage is simple:

    pmap [pid]: display the content of the /proc/[pid]/maps, but removes the inode and device columns.
    pmap -x [pid]: this enriches the output by adding some pieces of information from /proc/[pid]/smaps (RSS and Dirty).
    since pmap 3.3.4 there are -X and -XX to display even more data but there are Linux specific (moreover this seems to be a bit buggy with recent kernel versions).

Basic content

The pmap utility finds its inspiration in a similar command on Solaris and mimics its behavior. Here is the output of pmap and the content of /proc/[pid]/maps for the small program given as example for shared anonymous memory testing:
3009:   ./blah
0000000000400000      4K r-x--  /home/fruneau/blah
0000000000401000      4K rw---  /home/fruneau/blah
00007fbb5da87000  51200K rw-s-  /dev/zero (deleted)
00007fbb60c87000   1536K r-x--  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb60e07000   2048K -----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb61007000     16K r----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100b000      4K rw---  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100c000     20K rw---    [ anon ]
00007fbb61011000    128K r-x--  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61221000     12K rw---    [ anon ]
00007fbb6122e000      8K rw---    [ anon ]
00007fbb61230000      4K r----  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61231000      4K rw---  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61232000      4K rw---    [ anon ]
00007fff9350f000    132K rw---    [ stack ]
00007fff9356e000      4K r-x--    [ anon ]
ffffffffff600000      4K r-x--    [ anon ]
 total            55132K
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
	
3009:   ./blah
0000000000400000      4K r-x--  /home/fruneau/blah
0000000000401000      4K rw---  /home/fruneau/blah
00007fbb5da87000  51200K rw-s-  /dev/zero (deleted)
00007fbb60c87000   1536K r-x--  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb60e07000   2048K -----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb61007000     16K r----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100b000      4K rw---  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100c000     20K rw---    [ anon ]
00007fbb61011000    128K r-x--  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61221000     12K rw---    [ anon ]
00007fbb6122e000      8K rw---    [ anon ]
00007fbb61230000      4K r----  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61231000      4K rw---  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61232000      4K rw---    [ anon ]
00007fff9350f000    132K rw---    [ stack ]
00007fff9356e000      4K r-x--    [ anon ]
ffffffffff600000      4K r-x--    [ anon ]
 total            55132K

00400000-00401000 r-xp 00000000 08:01 3507636                            /home/fruneau/blah
00401000-00402000 rw-p 00000000 08:01 3507636                            /home/fruneau/blah
7fbb5da87000-7fbb60c87000 rw-s 00000000 00:04 8467                       /dev/zero (deleted)
7fbb60c87000-7fbb60e07000 r-xp 00000000 08:01 3334313                    /lib/x86_64-linux-gnu/libc-2.13.so
7fbb60e07000-7fbb61007000 ---p 00180000 08:01 3334313                    /lib/x86_64-linux-gnu/libc-2.13.so
7fbb61007000-7fbb6100b000 r--p 00180000 08:01 3334313                    /lib/x86_64-linux-gnu/libc-2.13.so
7fbb6100b000-7fbb6100c000 rw-p 00184000 08:01 3334313                    /lib/x86_64-linux-gnu/libc-2.13.so
7fbb6100c000-7fbb61011000 rw-p 00000000 00:00 0
7fbb61011000-7fbb61031000 r-xp 00000000 08:01 3334316                    /lib/x86_64-linux-gnu/ld-2.13.so
7fbb61221000-7fbb61224000 rw-p 00000000 00:00 0
7fbb6122e000-7fbb61230000 rw-p 00000000 00:00 0
7fbb61230000-7fbb61231000 r--p 0001f000 08:01 3334316                    /lib/x86_64-linux-gnu/ld-2.13.so
7fbb61231000-7fbb61232000 rw-p 00020000 08:01 3334316                    /lib/x86_64-linux-gnu/ld-2.13.so
7fbb61232000-7fbb61233000 rw-p 00000000 00:00 0
7fff9350f000-7fff93530000 rw-p 00000000 00:00 0                          [stack]
7fff9356e000-7fff9356f000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
	
00400000-00401000 r-xp 00000000 08:01 3507636                            /home/fruneau/blah
00401000-00402000 rw-p 00000000 08:01 3507636                            /home/fruneau/blah
7fbb5da87000-7fbb60c87000 rw-s 00000000 00:04 8467                       /dev/zero (deleted)
7fbb60c87000-7fbb60e07000 r-xp 00000000 08:01 3334313                    /lib/x86_64-linux-gnu/libc-2.13.so
7fbb60e07000-7fbb61007000 ---p 00180000 08:01 3334313                    /lib/x86_64-linux-gnu/libc-2.13.so
7fbb61007000-7fbb6100b000 r--p 00180000 08:01 3334313                    /lib/x86_64-linux-gnu/libc-2.13.so
7fbb6100b000-7fbb6100c000 rw-p 00184000 08:01 3334313                    /lib/x86_64-linux-gnu/libc-2.13.so
7fbb6100c000-7fbb61011000 rw-p 00000000 00:00 0
7fbb61011000-7fbb61031000 r-xp 00000000 08:01 3334316                    /lib/x86_64-linux-gnu/ld-2.13.so
7fbb61221000-7fbb61224000 rw-p 00000000 00:00 0
7fbb6122e000-7fbb61230000 rw-p 00000000 00:00 0
7fbb61230000-7fbb61231000 r--p 0001f000 08:01 3334316                    /lib/x86_64-linux-gnu/ld-2.13.so
7fbb61231000-7fbb61232000 rw-p 00020000 08:01 3334316                    /lib/x86_64-linux-gnu/ld-2.13.so
7fbb61232000-7fbb61233000 rw-p 00000000 00:00 0
7fff9350f000-7fff93530000 rw-p 00000000 00:00 0                          [stack]
7fff9356e000-7fff9356f000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]

There are a few interesting points in that output. First of all, pmap‘s choice is to provide the size of the mappings instead of the ranges of addresses and to add the sum of those sizes at the end. This sum is the VIRT size of top: the sum of all the reserved ranges of addresses in the virtual address space.

Each map is associated with a set of modes:

    r: if set, the map is readable
    w: if set, the map is writable
    x: if set, the map contains executable code
    s: if set, the map is shared (right column in our previous classification). You can notice that pmap only has the s flag, while the kernel exposes two different flags for  shared (s) and private (p) memory.
    R: if set, the map has no swap space reserved (MAP_NORESERVE flag of mmap), this means that we can get a segmentation fault by accessing that memory if it has not already been mapped to physical memory and the system is out of physical memory.

The first three flags can be manipulated using the mprotect(2) system call and can be set directly in the mmap call.

The last column is the source of the data. In our example, we can notice that pmap does not keep the kernel-specific details. It has three categories of memory: anon, stack and file-backed (with the path of file, and the (deleted) tag if the mapped file has been unlinked). In addition to these categories, the kernel has vdso, vsyscall and heap. It’s quite a shame that pmap didn’t keep the heap mark since it’s important for programmers (but that is probably in order to be compatible with its Solaris counterpart).

Concerning that last column, we also see that executable files and shared libraries are mapped privately (but this was already spoiled by the previous article) and that different parts of the same file are mapped differently (some parts are even mapped more than once). This is because executable files contain different sections: text, data, rodata, bss … each has a different meaning and is mapped differently. We will cover those sections in the next post.

Last (but not least), we can see that our shared anonymous memory is actually implemented as a shared mapping of an unlinked copy of /dev/zero.
Extended content

The output of pmap -x contains two additional columns:
Address           Kbytes     RSS   Dirty Mode   Mapping
0000000000400000       4       4       4 r-x--  blah
0000000000401000       4       4       4 rw---  blah
00007fc3b50df000   51200   51200   51200 rw-s-  zero (deleted)
00007fc3b82df000    1536     188       0 r-x--  libc-2.13.so
00007fc3b845f000    2048       0       0 -----  libc-2.13.so
00007fc3b865f000      16      16      16 r----  libc-2.13.so
00007fc3b8663000       4       4       4 rw---  libc-2.13.so
00007fc3b8664000      20      12      12 rw---    [ anon ]
00007fc3b8669000     128     108       0 r-x--  ld-2.13.so
00007fc3b8879000      12      12      12 rw---    [ anon ]
00007fc3b8886000       8       8       8 rw---    [ anon ]
00007fc3b8888000       4       4       4 r----  ld-2.13.so
00007fc3b8889000       4       4       4 rw---  ld-2.13.so
00007fc3b888a000       4       4       4 rw---    [ anon ]
00007fff7e6ef000     132      12      12 rw---    [ stack ]
00007fff7e773000       4       4       0 r-x--    [ anon ]
ffffffffff600000       4       0       0 r-x--    [ anon ]
----------------  ------  ------  ------
total kB           55132   51584   51284
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
	
Address           Kbytes     RSS   Dirty Mode   Mapping
0000000000400000       4       4       4 r-x--  blah
0000000000401000       4       4       4 rw---  blah
00007fc3b50df000   51200   51200   51200 rw-s-  zero (deleted)
00007fc3b82df000    1536     188       0 r-x--  libc-2.13.so
00007fc3b845f000    2048       0       0 -----  libc-2.13.so
00007fc3b865f000      16      16      16 r----  libc-2.13.so
00007fc3b8663000       4       4       4 rw---  libc-2.13.so
00007fc3b8664000      20      12      12 rw---    [ anon ]
00007fc3b8669000     128     108       0 r-x--  ld-2.13.so
00007fc3b8879000      12      12      12 rw---    [ anon ]
00007fc3b8886000       8       8       8 rw---    [ anon ]
00007fc3b8888000       4       4       4 r----  ld-2.13.so
00007fc3b8889000       4       4       4 rw---  ld-2.13.so
00007fc3b888a000       4       4       4 rw---    [ anon ]
00007fff7e6ef000     132      12      12 rw---    [ stack ]
00007fff7e773000       4       4       0 r-x--    [ anon ]
ffffffffff600000       4       0       0 r-x--    [ anon ]
----------------  ------  ------  ------
total kB           55132   51584   51284

The first one is RSS, it tells us how much the mapping contributes to the resident set size (and ultimately provides a sum that is the total memory consumption of the process). As we can see some mappings are only partially mapped in physical memory. The biggest one (our manual mmap) is totally allocated because we touched every single page.

The second new column is Dirty and contains the number of pages from their source. For shared file-backed mappings, dirty pages can be written back to the underlying file if the kernel feels it has to make some room in RAM or that there are too many dirty pages. In that case the page is marked clean. For all the remaining quadrants, since the backend is either anonymous (so no disk-based back-end) or private (so changes are not available to other processes), unloading the dirty pages requires writing them to the swap file3.

This is only a subset of what the kernel actually exposes. A lot more information is present in the smaps file (which make it a bit too verbose to be readable) as you can see in the following snippet:
00400000-00401000 r-xp 00000000 08:01 3507636                            /home/fruneau/blah
Size:                  4 kB
Rss:                   4 kB
Pss:                   4 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         4 kB
Private_Dirty:         0 kB
Referenced:            4 kB
Anonymous:             0 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB
00401000-00402000 rw-p 00000000 08:01 3507636                            /home/fruneau/blah
Size:                  4 kB
Rss:                   4 kB
Pss:                   4 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         0 kB
Private_Dirty:         4 kB
Referenced:            4 kB
Anonymous:             4 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB
7f55c4dd2000-7f55c7fd2000 rw-s 00000000 00:04 8716                       /dev/zero (deleted)
Size:              51200 kB
Rss:               51200 kB
Pss:               51200 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         0 kB
Private_Dirty:     51200 kB
Referenced:        51200 kB
Anonymous:             0 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
	
00400000-00401000 r-xp 00000000 08:01 3507636                            /home/fruneau/blah
Size:                  4 kB
Rss:                   4 kB
Pss:                   4 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         4 kB
Private_Dirty:         0 kB
Referenced:            4 kB
Anonymous:             0 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB
00401000-00402000 rw-p 00000000 08:01 3507636                            /home/fruneau/blah
Size:                  4 kB
Rss:                   4 kB
Pss:                   4 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         0 kB
Private_Dirty:         4 kB
Referenced:            4 kB
Anonymous:             4 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB
7f55c4dd2000-7f55c7fd2000 rw-s 00000000 00:04 8716                       /dev/zero (deleted)
Size:              51200 kB
Rss:               51200 kB
Pss:               51200 kB
Shared_Clean:          0 kB
Shared_Dirty:          0 kB
Private_Clean:         0 kB
Private_Dirty:     51200 kB
Referenced:        51200 kB
Anonymous:             0 kB
AnonHugePages:         0 kB
Swap:                  0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB

Adding pmap‘s output to a bug report is often a good idea.
More?

As you can see, understanding the output of top and other tools requires some knowledge of the operating system you are running. Even if top is available on various systems, each version is specific to the system it runs on. For example, on OS X, you will not find the RES, DATA, SHR… columns, but instead some named RPRVT, RSHRD, RSIZE, VPRVT, VSIZE (note that those names are somehow a bit less opaque than Linux ones). If you want to dive a bit deeper in Linux memory management, you can read the mm/ directory of the source tree, or traverse Understand the Linux Kernel.

Because this post is quite long, here is a short summary:

    top‘s man page cannot be trusted.
    top‘s RES gives you the actual physical RAM used by your process.
    top‘s VIRT gives you the actual virtual memory reserved by your process.
    top‘s DATA gives you the amount of virtual private anonymous memory reserved by your process. That memory may or may not be mapped to physical RAM. It corresponds to the amount of memory intended to store process specific data (not shared).
    top‘s SHR gives you the subset of resident memory that is file-backed (including shared anonymous memory). It represents the amount of resident memory that may be used by other processes.
    top‘s SWAP column can only be trusted with recent versions of top (3.3.0) and Linux (2.6.34) and is meaningless in all other cases.
    if you want details about the memory usage of your process, use pmap.

Memory Types

If you are a fan of htop, note that its content the exact same as top‘s. Its man page is also wrong or sometimes at least unclear.
Next: Allocating memory

In these two articles we have covered subjects that are (we do hope) of interest for both developers and system administrators. In the following articles we will start going deeper in how the memory is managed by the developer.

= part 3 :


Memory – Part 3: Managing memory
August 29, 2013, by Florent Bruneau	

    1 Developer point of view
    2 Locality
    3 Ownership
    4 Memory pools
        4.1 Static pool
        4.2 Stack
            4.2.1 Allocation
            4.2.2 Lifetime
    5 Heap
    6 mmap()
    7 malloc()
    8 Next: Intersec’s custom allocators

Developer point of view

In the previous articles we dealt with memory classification and analysis from an outer point of view. We saw that memory can be allocated in different ways with various properties. In the remaining articles of the series we will take a developer point of view.

At Intersec we write all of our software in C, which means that we are constantly dealing with memory management. We want our developers to have a solid knowledge of the various existing memory pools. In this article we will have an overview of the main sources of memory available to C programmers on Linux. We will also see some rules of memory management that will help you keep your program correct and efficient.

Locality

We talked a lot about memory pages which are the allocation unit in the kernel (and in the hardware). The CPU uses a thinner addressing unit: the cache line. A cache line is usually 64 bytes long. It’s the size the CPU will fetch from the main memory to its various internal caches.

Old CPUs had no cache, but CPU performances evolved more quickly that memory bus performances. As a consequence, to avoid spending too much time fetching data from the main memory, the CPU gained some small amounts of memory included directly in the chip. Initially there was a single small cache, but modern CPU may have up to three levels of cache. The closer the cache is to the CPU the faster it is. The farther the cache is from the CPU, the larger it gets. Here is a small table with the order of magnitude of the size and access time for each cache level on an i5-750 Core from 20101:
Level 	Size 	Expected CPU Cycles 	Observed CPU Cycles 	Access Time
Register 	A few words 	0 	0 	0 ns
Cache L1d 	32KiB 	4 	2 	0.8 ns
Cache L2 	256KiB 	11 	5 	1.9 ns
Cache L3 	8MiB 	31 	38 	15 ns
Main Memory 	Several GiB 	100+ 	40+ ns
Rotating Disk 	Hundreds of GiB 	10M+ 	5M+ ns

In order to avoid losing CPU time fetching data from memory, you must try to reuse the memory that is already in a cache. This is the the locality principle.

We talk about spatial and temporal locality:

    Spatial locality: organize your program so that variables accessed together are physically grouped.
    Temporal locality: organize your code so that accesses to the same location are done close to each other.

Since the memory is fetched by cache lines, a good practice is to group variables that often get accessed together in the same cache line2. Some tools such as pahole let you inspect the layout of your structures:
struct mem_stack_pool_t {
        const void  *              start;                /*     0     8 */
        size_t                     size;                 /*     8     8 */
        dlist_t                    blk_list;             /*    16    16 */
        mem_stack_frame_t          base;                 /*    32    32 */
        /* --- cacheline 1 boundary (64 bytes) --- */
        mem_stack_frame_t *        stack;                /*    64     8 */
        size_t                     stacksize;            /*    72     8 */
        uint32_t                   minsize;              /*    80     4 */
        uint32_t                   nbpages;              /*    84     4 */
        uint32_t                   nbpops;               /*    88     4 */
        uint32_t                   alloc_nb;             /*    92     4 */
        size_t                     alloc_sz;             /*    96     8 */
        mem_pool_t                 funcs;                /*   104    24 */
        /* --- cacheline 2 boundary (128 bytes) --- */

        /* size: 128, cachelines: 2, members: 12 */
};
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
	
struct mem_stack_pool_t {
        const void  *              start;                /*     0     8 */
        size_t                     size;                 /*     8     8 */
        dlist_t                    blk_list;             /*    16    16 */
        mem_stack_frame_t          base;                 /*    32    32 */
        /* --- cacheline 1 boundary (64 bytes) --- */
        mem_stack_frame_t *        stack;                /*    64     8 */
        size_t                     stacksize;            /*    72     8 */
        uint32_t                   minsize;              /*    80     4 */
        uint32_t                   nbpages;              /*    84     4 */
        uint32_t                   nbpops;               /*    88     4 */
        uint32_t                   alloc_nb;             /*    92     4 */
        size_t                     alloc_sz;             /*    96     8 */
        mem_pool_t                 funcs;                /*   104    24 */
        /* --- cacheline 2 boundary (128 bytes) --- */
 
        /* size: 128, cachelines: 2, members: 12 */
};

CPUs also have access pattern detection primitives. They are used to prefetch memory if the CPU guesses it will be probably accessed in a short time. When prefetching is done appropriately, it avoids more latency since memory is already fetched when the CPU actually needs it.

You can find more details in the already cited What every programmer should know about memory.
Ownership

Memory management requires good habits. When a program deals with some memory, it must know which component is responsible for that memory and it should not access it once that component has decided the memory is not valid anymore.

This implies that, for each memory chunk, the developer must maintain two properties:

    Ownership: who is responsible for that memory?
    Lifetime: when does that memory get invalidated?

These properties may be dealt with in different ways. First, this can be done implicitly: some structures may always own the memory they point to. This implicit contract can be part of a coding convention or documented in a function or structure prototype.
struct im_ptr_t {
    /* This pointer is owned by the structure */
    void *ptr;
};

void im_ptr_wipe(struct im_ptr_t *ptr)
{
    free(ptr->ptr);
    ptr->ptr = NULL;
}
1
2
3
4
5
6
7
8
9
10
	
struct im_ptr_t {
    /* This pointer is owned by the structure */
    void *ptr;
};
 
void im_ptr_wipe(struct im_ptr_t *ptr)
{
    free(ptr->ptr);
    ptr->ptr = NULL;
}

Secondly, this can be done explicitly: the pointer can be associated with a flag (or another variable) indicating whether the pointer owns its memory or not.
struct ex_ptr_t {
    bool  own;
    void *ptr;
};

void ex_ptr_wipe(struct ex_ptr_t *ptr)
{
    if (ptr->own) {
        free(ptr->ptr);
    }
    ptr->own = false;
    ptr->ptr = NULL;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
	
struct ex_ptr_t {
    bool  own;
    void *ptr;
};
 
void ex_ptr_wipe(struct ex_ptr_t *ptr)
{
    if (ptr->own) {
        free(ptr->ptr);
    }
    ptr->own = false;
    ptr->ptr = NULL;
}

This wiping function resets the variables on exit, which avoids keeping a pointer to some freed memory and thus ensure that this memory will not be accessed “by accident” in the future. We can still dereference the NULL pointer, but this will lead to an immediate error instead of risking corrupting the allocation pool. BTW, this ensures the wiping function is idempotent which makes memory cleanup code simpler.

A proper ownership tracking avoids issues such as use-after-free, double free, leaked memory, …
Memory pools

A quick vocabulary note: while in the literature pool and arena are often used as synonyms, in this and further articles, we will use these terms for two different concepts. Pools are conceptual sources of data, while arenas are large chunks of memory intended to be split into smaller chunks by a memory allocator.

To be able to track the lifetime of a particular memory chunk, developers have to know its originating memory pool. Several standard pools exist. The next paragraphs will detail the most important ones.
Static pool
Owner 	The runtime (dynamic loader)
Lifetime 	The same as the file that holds the data
Initialization 	Explicit value or 0

Static memory is memory allocated at program start by the runtime, or when a dynamic library is loaded. It contains the global variables, whatever their visibility is (extern, static, static in a function…), as well as all the constants (this includes literal strings and exported const variables). In C, a global variable is always initialized to 0 unless explicitly initialized. As a consequence, a large amount of the static memory is probably going to be initialized to 0 when the program starts.

The content of the static memory is extrapolated from the executable files. On Linux, most executables use the ELF format. That format is a succession of sections, each section having a particular purpose: holding code, data, or various meta-data about the binary (debug information, dynamic linking pointers, …). When the executable is loaded, those sections are selectively loaded in memory according to some flags. Among the few tens of standard sections, only a few will be of interest for this article.

First of all, the .text section. That section contains the main code of the binary file and is completed by a few other ones containing special-purposed executable code (such as the .init section that contains initialization code executed when the file is loaded, and the .fini section that contains termination code executed when the file is unloaded). Those sections are mapped in memory with the PROT_EXEC mode. If you recall the previous article, those sections are easily identifiable in pmap‘s output:
3009:   ./blah
0000000000400000      4K r-x--  /home/fruneau/blah
0000000000401000      4K rw---  /home/fruneau/blah
00007fbb5da87000  51200K rw-s-  /dev/zero (deleted)
00007fbb60c87000   1536K r-x--  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb60e07000   2048K -----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb61007000     16K r----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100b000      4K rw---  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100c000     20K rw---    [ anon ]
00007fbb61011000    128K r-x--  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61221000     12K rw---    [ anon ]
00007fbb6122e000      8K rw---    [ anon ]
00007fbb61230000      4K r----  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61231000      4K rw---  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61232000      4K rw---    [ anon ]
00007fff9350f000    132K rw---    [ stack ]
00007fff9356e000      4K r-x--    [ anon ]
ffffffffff600000      4K r-x--    [ anon ]
 total            55132K
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
	
3009:   ./blah
0000000000400000      4K r-x--  /home/fruneau/blah
0000000000401000      4K rw---  /home/fruneau/blah
00007fbb5da87000  51200K rw-s-  /dev/zero (deleted)
00007fbb60c87000   1536K r-x--  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb60e07000   2048K -----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb61007000     16K r----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100b000      4K rw---  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100c000     20K rw---    [ anon ]
00007fbb61011000    128K r-x--  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61221000     12K rw---    [ anon ]
00007fbb6122e000      8K rw---    [ anon ]
00007fbb61230000      4K r----  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61231000      4K rw---  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61232000      4K rw---    [ anon ]
00007fff9350f000    132K rw---    [ stack ]
00007fff9356e000      4K r-x--    [ anon ]
ffffffffff600000      4K r-x--    [ anon ]
 total            55132K

Then come the sections that hold some data. There are three of them: .data, .rodata and .bss. The first one contains the mutable variables with an explicit initialization value, the second one contains the constants (and as a consequence it is supposed to be read-only), and the last one is dedicated to uninitialized data. The exact repartition of the data among those three sections depends on your compiler. Most of the time we can observe that:

    variables and constants initialized to 0 are put in the .bss section.
    remaining variables are put in the .data section.
    remaining constants are put in the .rodata section.

Usually, the .rodata is placed just after the executable sections since neither of them are writable. This allows the read-only data and the executable code to be mapped at once and thus simplifies the initialization process. This is mostly noticeable when the executable section is small.
3009:   ./blah
0000000000400000      4K r-x--  /home/fruneau/blah
0000000000401000      4K rw---  /home/fruneau/blah
00007fbb5da87000  51200K rw-s-  /dev/zero (deleted)
00007fbb60c87000   1536K r-x--  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb60e07000   2048K -----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb61007000     16K r----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100b000      4K rw---  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100c000     20K rw---    [ anon ]
00007fbb61011000    128K r-x--  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61221000     12K rw---    [ anon ]
00007fbb6122e000      8K rw---    [ anon ]
00007fbb61230000      4K r----  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61231000      4K rw---  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61232000      4K rw---    [ anon ]
00007fff9350f000    132K rw---    [ stack ]
00007fff9356e000      4K r-x--    [ anon ]
ffffffffff600000      4K r-x--    [ anon ]
 total            55132K
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
	
3009:   ./blah
0000000000400000      4K r-x--  /home/fruneau/blah
0000000000401000      4K rw---  /home/fruneau/blah
00007fbb5da87000  51200K rw-s-  /dev/zero (deleted)
00007fbb60c87000   1536K r-x--  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb60e07000   2048K -----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb61007000     16K r----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100b000      4K rw---  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100c000     20K rw---    [ anon ]
00007fbb61011000    128K r-x--  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61221000     12K rw---    [ anon ]
00007fbb6122e000      8K rw---    [ anon ]
00007fbb61230000      4K r----  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61231000      4K rw---  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61232000      4K rw---    [ anon ]
00007fff9350f000    132K rw---    [ stack ]
00007fff9356e000      4K r-x--    [ anon ]
ffffffffff600000      4K r-x--    [ anon ]
 total            55132K

In a similar fashion, since both .data and .bss are writable sections, the latter usually directly follows the former. .bss has the additional property of being sparse: since it only contains uninitialized data that will be filled with zeros, the size of the section is enough to define it. As a consequence, if needed3, the .bss section is built as a read-write anonymous mapping directly following the read-write mapping of the .data section:
3009:   ./blah
0000000000400000      4K r-x--  /home/fruneau/blah
0000000000401000      4K rw---  /home/fruneau/blah
00007fbb5da87000  51200K rw-s-  /dev/zero (deleted)
00007fbb60c87000   1536K r-x--  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb60e07000   2048K -----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb61007000     16K r----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100b000      4K rw---  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100c000     20K rw---    [ anon ]
00007fbb61011000    128K r-x--  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61221000     12K rw---    [ anon ]
00007fbb6122e000      8K rw---    [ anon ]
00007fbb61230000      4K r----  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61231000      4K rw---  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61232000      4K rw---    [ anon ]
00007fff9350f000    132K rw---    [ stack ]
00007fff9356e000      4K r-x--    [ anon ]
ffffffffff600000      4K r-x--    [ anon ]
 total            55132K
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
	
3009:   ./blah
0000000000400000      4K r-x--  /home/fruneau/blah
0000000000401000      4K rw---  /home/fruneau/blah
00007fbb5da87000  51200K rw-s-  /dev/zero (deleted)
00007fbb60c87000   1536K r-x--  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb60e07000   2048K -----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb61007000     16K r----  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100b000      4K rw---  /lib/x86_64-linux-gnu/libc-2.13.so
00007fbb6100c000     20K rw---    [ anon ]
00007fbb61011000    128K r-x--  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61221000     12K rw---    [ anon ]
00007fbb6122e000      8K rw---    [ anon ]
00007fbb61230000      4K r----  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61231000      4K rw---  /lib/x86_64-linux-gnu/ld-2.13.so
00007fbb61232000      4K rw---    [ anon ]
00007fff9350f000    132K rw---    [ stack ]
00007fff9356e000      4K r-x--    [ anon ]
ffffffffff600000      4K r-x--    [ anon ]
 total            55132K

The various sections have no reason to start or end exactly at a page limit. As a consequence, when the .bss section spreads over the end of the map made for the .data section, that memory is overridden with zeros in order to conform to the .bss initialization value4. The .bss section is then completed with the anonymous memory.

As you can see, the loading of binary files is not straightforward. An ELF executable is in fact loaded as several mappings corresponding to the various chunks of memory that must be made available at runtime.

Note that this description is not exhaustive and as you can see we didn’t cover all the sections mapped in memory.
Stack
Owner 	The runtime (the activation record)
Lifetime 	The scope in which it is declared
Initialization 	None (random content)

The stack is the place where functions put their contexts. It is composed of a succession of frames (also called activation records) each frame being the context of a different function.
Allocation

The stack is memory region allocated when a thread starts. The allocation of the stack of the main thread is a bit different from the additional ones. Using pmap you can identify the location of the main stack (it appears as [stack]), however the additional stacks are shown as [anon] (the information is however available in /proc/[pid]/maps as [stack:pid_of_the_thread]).

The main thread’s stack is dynamically managed by the kernel; the initial size of the map is not definitive, it will automatically grow as the stack grows. The additional stacks are allocated at thread initialization as a private anonymous map of the stacksize attribute of pthread_attr. The stacks have a limited size, however the default limit on recent Linux distributions is several mega-bytes, which can typically store several thousands of frames. That maximum size is defined as a resource limit and can be manipulated at different levels on the system: through the /etc/limits.conf file, using the ulimit command-line utility or by calling setrlimit().
00400000-00638000 r-xp 00000000 fe:02 507579                             /home/fruneau/zchk
00838000-0084a000 rw-p 00238000 fe:02 507579                             /home/fruneau/zchk
0084a000-0085c000 rw-p 00000000 00:00 0
02431000-02866000 rw-p 00000000 00:00 0                                  [heap]
[...]
7f5c7e8bd000-7f5c7e8be000 ---p 00000000 00:00 0
7f5c7e8be000-7f5c7f0be000 rw-p 00000000 00:00 0                          [stack:711]
[...]
7f5c800c0000-7f5c801bd000 r-xp 00000000 08:06 558238                     /lib/x86_64-linux-gnu/libm-2.17.so
7f5c801bd000-7f5c803bc000 ---p 000fd000 08:06 558238                     /lib/x86_64-linux-gnu/libm-2.17.so
[...]
7f5c817d3000-7f5c817d4000 r--p 00021000 08:06 561168                     /lib/x86_64-linux-gnu/ld-2.17.so
7f5c817d4000-7f5c817d5000 rw-p 00022000 08:06 561168                     /lib/x86_64-linux-gnu/ld-2.17.so
7f5c817d5000-7f5c817d6000 rw-p 00000000 00:00 0
7fff985e7000-7fff98608000 rw-p 00000000 00:00 0                          [stack]
7fff986c5000-7fff986c7000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
	
00400000-00638000 r-xp 00000000 fe:02 507579                             /home/fruneau/zchk
00838000-0084a000 rw-p 00238000 fe:02 507579                             /home/fruneau/zchk
0084a000-0085c000 rw-p 00000000 00:00 0
02431000-02866000 rw-p 00000000 00:00 0                                  [heap]
[...]
7f5c7e8bd000-7f5c7e8be000 ---p 00000000 00:00 0
7f5c7e8be000-7f5c7f0be000 rw-p 00000000 00:00 0                          [stack:711]
[...]
7f5c800c0000-7f5c801bd000 r-xp 00000000 08:06 558238                     /lib/x86_64-linux-gnu/libm-2.17.so
7f5c801bd000-7f5c803bc000 ---p 000fd000 08:06 558238                     /lib/x86_64-linux-gnu/libm-2.17.so
[...]
7f5c817d3000-7f5c817d4000 r--p 00021000 08:06 561168                     /lib/x86_64-linux-gnu/ld-2.17.so
7f5c817d4000-7f5c817d5000 rw-p 00022000 08:06 561168                     /lib/x86_64-linux-gnu/ld-2.17.so
7f5c817d5000-7f5c817d6000 rw-p 00000000 00:00 0
7fff985e7000-7fff98608000 rw-p 00000000 00:00 0                          [stack]
7fff986c5000-7fff986c7000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]

When the content of the stack does not fit in its allowed size, the process crashes with a segmentation fault due to a stack overflow. In the case of the main thread, this is dynamically handled by the kernel, while additional threads’ stacks are preceded5 by a small no-access region, so that any access there is illegal and generates the segmentation fault. As a consequence, a deeply recursive function can cause a stack overflow, since each recursion creates a new frame.

Each time a function is called, a new frame is pushed by putting the parameters and various state information on the top of the stack. When the function returns, its frame is popped and the stack is set back to its previous state. The exact size and content of a frame depend on the ABI and thus on the operating system, the architecture of the computer and even on the compilation options. However, it generally grows with the number of parameters and the number of local variables of the callee.

Traditionally, the size of the frame was statically defined by the compiler. However, dynamic allocations are allowed in a non-standard fashion using the alloca(3) call. Each call to alloca extends the current frame. There is no call to release or resize an alloca allocation. Since the size of the stack is limited, alloca must be handled with care to avoid stack overflows6. Putting a call to alloca in a loop or having a call to alloca with a dynamically defined size (that may be large) are bad ideas.
Lifetime

A common (wrong) belief is that each local variable of a function has its own memory slot allocated on the stack. However, even if this may be true when the program is compiled with no optimization, this is usually wrong. The compiler job is to ensure that the resulting process is as fast as possible. As a consequence, it will try to keep the data in the registers of the CPU whenever possible in order to reduce the access latency, but since the number of registers is limited, when there are too many variables (or when we need a pointer to one of them), some must be put on the stack. The compiler analyzes the accesses to each variable and perform a register and stack allocation pass based on the result.

The result of that pass is that two variables that are never used at the same time may share the same register and/or the same location on the stack. A variable may also not always be assigned to the same register or memory location. Thus you must keep in mind that even if the memory on the stack remains valid as long as the frame is active (that is as long as the function didn’t return), a particular memory location can be used by several local variables belonging to different scopes:
void my_broken_function()
{
    int b;
    void *ptr;

    {
        int a = 1;
        ptr = &a;
    }
    /* ptr is now invalid */

    b = 2;
    assert (&b == ptr); /* this assert may be true because b wasn't "alive" before
                           so the compiler is allowed to delay it's allocation on the stack
                           and to reuse the placeholder of a "dead" variable" such as "a"
                           that is now out of scope */

    {
        int c = 3;
        assert (&c == ptr); /* this assert may be true too */
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
	
void my_broken_function()
{
    int b;
    void *ptr;
 
    {
        int a = 1;
        ptr = &a;
    }
    /* ptr is now invalid */
 
    b = 2;
    assert (&b == ptr); /* this assert may be true because b wasn't "alive" before
                           so the compiler is allowed to delay it's allocation on the stack
                           and to reuse the placeholder of a "dead" variable" such as "a"
                           that is now out of scope */
 
    {
        int c = 3;
        assert (&c == ptr); /* this assert may be true too */
    }
}

As a consequence, a pointer to a variable placed on the stack must not exit the lexical scope of that particular variable and a fortiori it must not be propagated as a returned value of the function. The compiler is able to report some broken usage of pointers to stacked variables, but that’s only a small part of the possible errors. So you must be very careful when using pointers to variables on the stack, and especially ensure that the pointers never escape (that is, they never get returned or stored in a global variables or other variables with a longer lifetime) their validity scopes.
Heap
Owner 	The caller of brk()
Lifetime 	Until another brk() invalidates the memory
Initialization 	0

The heap is a special memory area that has a fixed location and can be grown. It is managed using the brk() and sbrk() standard calls. Those calls let you add or remove memory at the end of the heap with the granularity of a page. Traditionally these calls were supposed to grow the data segment (that is increasing the map corresponding to the .bss section). However, this was at a time where memory management was much less advanced and memory was much more constrained. Nowadays, the virtual address space is large and there is no need to keep it packed anymore.

As you can see in the content of /proc/[pid]/maps, on modern operating systems, the [heap] is still locating near the beginning of the memory address space, after the mapping of the executable (and thus after the .bss section), but there is a large gap between the .bss section and the heap:
00400000-00638000 r-xp 00000000 fe:02 507579                             /home/fruneau/zchk
00838000-0084a000 rw-p 00238000 fe:02 507579                             /home/fruneau/zchk
0084a000-0085c000 rw-p 00000000 00:00 0
02431000-02866000 rw-p 00000000 00:00 0                                  [heap]
[...]
1
2
3
4
5
	
00400000-00638000 r-xp 00000000 fe:02 507579                             /home/fruneau/zchk
00838000-0084a000 rw-p 00238000 fe:02 507579                             /home/fruneau/zchk
0084a000-0085c000 rw-p 00000000 00:00 0
02431000-02866000 rw-p 00000000 00:00 0                                  [heap]
[...]

As for the stack, the size of the heap is subject to a resource limitation.

In practice, you will never have to manage the heap manually. It is used internally by most malloc() implementations.
mmap()
Owner 	The caller
Lifetime 	Until corresponding munmaps
Initialization 	File content or 0

The mmap system call is the primitive to interact with the virtual memory manager of the kernel. It reserves any of the categories of memory we defined in the first article with the granularity of the page. That granularity does not forbid you to map a file which size is not a multiple of the page size, the remaining area is the last page will simply be filled with zeros (which won’t be added to disk)7.

When calling mmap you manipulate the properties of an internal lookup structure of the kernel, you don’t actually allocate a chunk of memory. As a consequence running mmap several times on the same page (which is possible using the MAP_FIXED flag) won’t create a new map, it will just change the attributes of the pages at the specified address. munmap, the mmap counterpart, removes a particular set of pages from the kernel lookup structure. There is no need to call mmap and munmap in a symetric fashion: you can both unmap several maps with a single large munmap or unmap a single map with several smaller munmap.

A small example to illustrate this all:
/** mmap a file of 256MB and ensure it is aligned on 256MB.
 */
void *mmap_256(int fd)
{
#define FILE_SIZE  (256 << 20)

    /* Create a first map to find a sequence of pages that can contain
     * a sequence of 256MiB properly aligned
     */
    byte *ptr = mmap(NULL, 2 * FILE_SIZE, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0);
    byte *aligned_ptr;

    if (ptr == MAP_FAILED) {
        return ptr;
    }

    /* Find an aligned pointer in the mapped chunk
     */
    aligned_ptr = (byte *)ROUND_UP((uintptr_t)ptr, FILE_SIZE);

    /* Unmap pages that do not belong to the aligned 256MB long chunk.
      *
      * This is done by calling munmap twice: once for the pages at the beginning
      * of the map, and once for those at the end of the map.
      */
    if (aligned_ptr != ptr) {
        munmap(ptr, aligned_ptr - ptr);
    }
    munmap(aligned_ptr + FILE_SIZE, FILE_SIZE - (aligned_ptr - ptr));

    /** Map the file in the remaining pages.
      *
      * Provides both an explicit address (from aligned_ptr) and the MAP_FIXED flags
      * to tell the kernel that we really want to map those pages. Since these are pages we just mapped
      * we know they are available.
      */
    return mmap(aligned_ptr, FILE_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_FIXED, fd, 0);
}

/** Unmap a file mapped by mmap_256
  */
void munmap_256(void *ptr)
{
    /* A simple mnumap suffice */
    if (munmap(ptr, FILE_SIZE) < 0) {
        assert (false);
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
	
/** mmap a file of 256MB and ensure it is aligned on 256MB.
 */
void *mmap_256(int fd)
{
#define FILE_SIZE  (256 << 20)
 
    /* Create a first map to find a sequence of pages that can contain
     * a sequence of 256MiB properly aligned
     */
    byte *ptr = mmap(NULL, 2 * FILE_SIZE, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0);
    byte *aligned_ptr;
 
    if (ptr == MAP_FAILED) {
        return ptr;
    }
 
    /* Find an aligned pointer in the mapped chunk
     */
    aligned_ptr = (byte *)ROUND_UP((uintptr_t)ptr, FILE_SIZE);
 
    /* Unmap pages that do not belong to the aligned 256MB long chunk.
      *
      * This is done by calling munmap twice: once for the pages at the beginning
      * of the map, and once for those at the end of the map.
      */
    if (aligned_ptr != ptr) {
        munmap(ptr, aligned_ptr - ptr);
    }
    munmap(aligned_ptr + FILE_SIZE, FILE_SIZE - (aligned_ptr - ptr));
 
    /** Map the file in the remaining pages.
      *
      * Provides both an explicit address (from aligned_ptr) and the MAP_FIXED flags
      * to tell the kernel that we really want to map those pages. Since these are pages we just mapped
      * we know they are available.
      */
    return mmap(aligned_ptr, FILE_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_FIXED, fd, 0);
}
 
/** Unmap a file mapped by mmap_256
  */
void munmap_256(void *ptr)
{
    /* A simple mnumap suffice */
    if (munmap(ptr, FILE_SIZE) < 0) {
        assert (false);
    }
}

malloc()
Owner 	The caller
Lifetime 	Until corresponding free()
Initialization 	None (random content)

malloc() is probably the most widely known source of memory in C. It is the standard dynamic allocator with its siblings calloc(), realloc(), memalign(), free(), … It works by requesting big chunks of memory from the kernel, splitting them into smaller ones that satisfy the size requested by the caller as well as limiting the overhead in both memory and CPU.

The Linux ecosystem is full of different implementations of malloc(). The most notable implementations are probably the ptmalloc family and tcmalloc from Google. The glibc uses the ptmalloc2 implementation which itself is an adaptation of Doug Lea’s malloc (dlmalloc). That version uses a somehow complex algorithm which varies depending on the size of the requested allocation. It uses two sources of memory. For small allocations, it uses the heap while for big ones, it will fallback on mmap(). The default threshold is dynamically estimated and is by default between 128KiB and 64MiB. This can be changed using the options M_MMAP_THRESHOLD and M_MMAP_MAX of the mallopt() call.

The allocator splits the heap into some lists of non-allocated memory chunks. When an allocation is requested, it traverses its lists looking for the more suitable chunk. When no chunk can be found, it grows the heap by issuing a brk() system call and put the additional memory in its internal lists.

When a chunk of memory is free’d (by calling free() on the pointer previously returned by the malloc() call), it is added in a free-chunk list. When the last pages of the heap are free, those pages are released and the heap is reduced (by issuing another brk() call). As a consequence, calling free() in a program may not have a direct impact of the actual memory used by the process. If the program performs a lot of allocation / deallocation with various lifetime, the heap may be fragmented: the heap cannot be reduced even if it contains a lot of free memory. Nevertheless, calling free() on a big chunk of memory (big enough for being allocated using the fallback on mmap()) will call munmap and thus will have a direct impact of the memory consumption of your process.

ptmalloc2 has a memory overhead of at least 8 bytes per allocation on 64-bit system. These bytes are used internally to store some meta-data about the allocation. This means it is extremely memory-inefficient for very small allocations (but this is the case for most malloc() implementations). Those administrative bytes are stored just before the returned pointer, which means they can easily be inadvertently overwritten by a memory underflow. The consequence of such an overwrite is a corruption of the allocator that will later lead to a segmentation fault ((Later means that the crash will seem totally random on a first sight)).

Nowadays, a challenge of a good malloc() implementation is to behave properly in a multithreaded environment. Most of the time, this is done by having thread-local caches and a shared heap. The allocator will first try to find a matching chunk in the local cache and fallback to the heap (which requires locking) only if no matching element can be found.
Next: Intersec’s custom allocators

After spending three full (and quite long) articles to lay the foundation for memory understanding, in the next post we will cover some of the specific implementations we chose to develop at Intersec to match our own requirements.

= part 4:

Memory – Part 4: Intersec’s custom allocators
October 1, 2013, by Florent Bruneau	

    1 malloc() is not the one-size-fits-all allocator
    2 Benchmarks
    3 Stack allocator
        3.1 Internals
        3.2 t_stack
        3.3 Benchmark
    4 FIFO allocator
        4.1 The FIFO problem
        4.2 Solution
        4.3 Benchmark
    5 Ring allocator
    6 Other custom allocators
    7 Next: debugging tools

malloc() is not the one-size-fits-all allocator

malloc() is extremely convenient because it is generic. It does not make any assumptions about the context of the allocation and the deallocation. Such allocators may just follow each other, or be separated by a whole job execution. They may take place in the same thread, or not… Since it is generic, each allocation is different from each other, meaning that long term allocations share the same pool as short term ones.

Consequently, the implementation of malloc() is complex. Since memory can be shared by several threads, the pool must be shared and locking is required. Since modern hardware has more and more physical threads, locking the pool at every single allocation would have disastrous impacts on performance. Therefore, modern malloc() implementations have thread-local caches and will lock the main pool only if the caches get too small or too large. A side effect is that some memory gets stuck in thread-local caches and is not easily accessible from other threads.

Since chunks of memory can get stuck at different locations (within thread-local caches, in the global pool, or just simply allocated by the process), the heap gets fragmented. It becomes hard to release unused memory to the kernel, and it becomes highly probable that two successive allocations will return chunk of memories that are far from each other, generating random accesses to the heap. As we have seen in the previous article, random access is far from being the optimal solution for accessing memory.

As a consequence, it is sometimes necessary to have specialized allocators with predictable behavior. At Intersec, we have several of them to use in various situations. In some specific use cases we increase performance by several orders of magnitude.

Benchmarks

In order to provide some comparison points, we ran a small synthetic benchmark. This benchmark tests the performance of malloc() and free() in two scenarios. The first scenario is simple: we allocate a 100 million pointers and then we free them all. The allocator’s raw performance is tested in a single-threaded environment for small allocations.
#include <stdlib.h>
#include <stdio.h>
#include <stdint.h>
#include <sys/time.h>

struct list {
    struct list *next;
};

static int64_t timeval_diffmsec(const struct timeval *tv2,
                                const struct timeval *tv1)
{
    int64_t delta = tv2->tv_sec - tv1->tv_sec;

    return delta * 1000 + (tv2->tv_usec - tv1->tv_usec) / 1000;
}

int main(int argc, char *argv[])
{
    for (int k = 0; k < 3; k++) {
        struct timeval start;
        struct timeval end;
        struct list *head = NULL;
        struct list *tail = NULL;

        /* Allocation */
        gettimeofday(&start, NULL);
        head = tail = malloc(sizeof(struct list));
        for (int i = 0; i < 100000000; i++) {
            tail->next = malloc(sizeof(struct list));
            tail = tail->next;
        }
        tail->next = NULL;
        gettimeofday(&end, NULL);

        printf("100,000,000 allocations in %ldms (%ld/s)\n",
               timeval_diffmsec(&end, &start),
               100000000UL * 1000 / timeval_diffmsec(&end, &start));

        /* Deallocation */
        gettimeofday(&start, NULL);
        while (head) {
            struct list *cur = head;

            head = head->next;
            free(cur);
        }
        gettimeofday(&end, NULL);
        printf("100,000,000 deallocations in %ldms (%ld/s)\n",
               timeval_diffmsec(&end, &start),
               100000000UL * 1000 / timeval_diffmsec(&end, &start));
    }

    return 0;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
	
#include <stdlib.h>
#include <stdio.h>
#include <stdint.h>
#include <sys/time.h>
 
struct list {
    struct list *next;
};
 
static int64_t timeval_diffmsec(const struct timeval *tv2,
                                const struct timeval *tv1)
{
    int64_t delta = tv2->tv_sec - tv1->tv_sec;
 
    return delta * 1000 + (tv2->tv_usec - tv1->tv_usec) / 1000;
}
 
int main(int argc, char *argv[])
{
    for (int k = 0; k < 3; k++) {
        struct timeval start;
        struct timeval end;
        struct list *head = NULL;
        struct list *tail = NULL;
 
        /* Allocation */
        gettimeofday(&start, NULL);
        head = tail = malloc(sizeof(struct list));
        for (int i = 0; i < 100000000; i++) {
            tail->next = malloc(sizeof(struct list));
            tail = tail->next;
        }
        tail->next = NULL;
        gettimeofday(&end, NULL);
 
        printf("100,000,000 allocations in %ldms (%ld/s)\n",
               timeval_diffmsec(&end, &start),
               100000000UL * 1000 / timeval_diffmsec(&end, &start));
 
        /* Deallocation */
        gettimeofday(&start, NULL);
        while (head) {
            struct list *cur = head;
 
            head = head->next;
            free(cur);
        }
        gettimeofday(&end, NULL);
        printf("100,000,000 deallocations in %ldms (%ld/s)\n",
               timeval_diffmsec(&end, &start),
               100000000UL * 1000 / timeval_diffmsec(&end, &start));
    }
 
    return 0;
}

The second scenario adds multithreading: after allocating all our pointers, we start freeing them in another thread while allocating new batches of pointers in the main thread. As a consequence, allocation and deallocation are run concurrently in two different threads, creating contention on the allocation pool.

malloc-benchmark

The benchmark was run three times: once with the ptmalloc (glibc‘s implementation), another with tcmalloc (Google’s implementation), and finally with jemalloc (Linux port of FreeBSD implementation).
Scenario 	Allocation 	Deallocation 	Memory 	Time
Uncontended 	ptmalloc 	1512ms (66M/s) 	1261ms (79M/s) 	2.9GiB 	9.98s
tcmalloc 	1712ms (58M/s) 	2229ms (44M/s) 	769MiB 	12.10s
jemalloc 	3312ms (30M/s) 	4191ms (23M/s) 	784MiB 	22.55s
Contended 	ptmalloc 	16154ms (6.2M/s) 	15309ms (6.3M/s) 	2.9GiB 	39.18s
tcmalloc 	2860ms (34M/s) 	6707ms (14M/s) 	1.7GiB 	14.62s
jemalloc 	3845ms (26M/s) 	11672ms (8.5M/s) 	2.3GiB 	23.55s

Indeed, the results depend vastly on the implementation of malloc(). While, on a non-contended environment, the ptmalloc shows slightly better performances than tcmalloc (at the cost of a much larger memory footprint), tcmalloc behaves much better in a multithreaded environment.

One allocation batch contains 100M 8-byte pointers, this means it allocates 800MB (762MiB). As a consequence, in the single threaded case, the payload is 762MiB. As we can see tcmalloc is near-optimal in terms of memory consumption. However, one odd thing about tcmalloc is that deallocation is slower than allocation: the deallocation thread is not able to free memory as fast as it is allocated, causing an ever growing memory footprint if we increase the number of threads run in the benchmark.

The benchmark is synthetic and stresses only the small-chunk allocator in an extremely specific use-case. Thus, it should not be considered as an absolute proof that tcmalloc is faster in multithreaded environment while ptmalloc is faster in single threaded ones. However, the benchmark shows that there is no perfect malloc() implementation and that choosing the right implementation for your use case may have huge impacts on overall performance.

Last, but not least, this benchmark shows that you can perform only a few millions of allocations/deallocations per second. This may seem quite large, but as soon as you want to process several hundreds of thousands of events per second, and if each event triggers one or more allocations, then malloc() will start being a bottleneck.
Stack allocator

The first (and certainly the most used) custom allocator at Intersec is the stack allocator. This is a LIFO allocator, meaning that allocations are deallocated in the reverse order of their allocation. It mimics the behavior of the program’s stack since allocations are grouped in frames, and frames are deallocated at once.
Internals

The stack allocator is an arena-based allocator. It allocates huge blocks and then splits them into smaller chunks.

It keeps track of two key pieces of information about each block:

    the bottom of the stack
    the delimitation of the frames

When an allocation is performed, the bottom of the stack is incremented by the size of the requested memory (plus the alignment requirements and the size of the canaries). If the requested size cannot fit in the current block, a new one is allocated: the allocator will not try to fill the gap left in the previous block.

When a frame is created, a mark is pushed at the bottom of the stack with the position of the beginning of the previous frame. The allocator always knows the position of the beginning of the current frame. That way, removing a frame is extremely fast: the allocator sets the bottom of the stack back to the current frame’s position, then it reloads the previous frame’s position and makes it its current. Additionally, the allocator will list the blocks that were totally freed by the operation and deallocate them.

mem-stack

The deallocation of a frame is done in amortized constant time, it does not depend on the number of allocations made in the frame, but on the number of blocks contained in the frame. Block size is chosen large enough to contain several typical frames, which means that deallocating a frame will most of the time not deallocate any block.

Since allocations and deallocations are done in a strict order, two consecutive allocations will return adjacent memory chunks (unless the new allocation requires a new arena). This helps improving the locality of memory accesses within the program. Moreover, thanks to the allocation ordering, there is very few fragmentation in a stack allocator. As a consequence, the memory pressure of the stack allocator goes down when the actual amount of allocated memory does so.
t_stack

We do have a special stack allocator: the t_stack. This is a thread-local singleton instance of the stack allocator. It is used as a complement of the normal program’s stack. The main advantage of the t_stack is that it allows efficient dynamic allocation of temporary memory. Whenever we want to allocate some memory in a function and release it at the end of the function, we just use t_stack-based allocation.

The frame creation and deletion on the t_stack are not bound to a function scope, it is defined using a special macro t_scope at the beginning of a lexical scope. That macro makes use of the GNU’s cleanup attribute to emulate a C++’s RAII behavior in C: it creates the frame and adds a cleanup handler that will destroy the frame whenever the lexical scope of its definition is exited1.
static inline void t_scope_cleanup(const void **frame_ptr)
{
    if (unlikely(*unused != mem_stack_pop(&t_pool_g))) {
          e_panic("unbalanced t_stack");
    }
}

#define t_scope__(n)  \
    const void *t_scope_##n __attribute__((unused,cleanup(t_scope_cleanup))) \
          = mem_stack_push(&t_pool_g)

#define t_scope_(n)  t_scope__(n)
#define t_scope      t_scope_(__LINE__)
1
2
3
4
5
6
7
8
9
10
11
12
13
	
static inline void t_scope_cleanup(const void **frame_ptr)
{
    if (unlikely(*unused != mem_stack_pop(&t_pool_g))) {
          e_panic("unbalanced t_stack");
    }
}
 
#define t_scope__(n)  \
    const void *t_scope_##n __attribute__((unused,cleanup(t_scope_cleanup))) \
          = mem_stack_push(&t_pool_g)
 
#define t_scope_(n)  t_scope__(n)
#define t_scope      t_scope_(__LINE__)

Since the frame allocation/deallocation is controlled by the developer, the t_stack is somehow more flexible than the normal stack. Behaviors that are dangerous or impossible using the stack, such as doing some allocations within a loop or returning t_stack-allocated memory, are safe with the t_stack. Moreover, since there is no size limitation (other than the available amount of RAM), the t_stack can be used for general purpose allocations as long as the memory lifetime is compatible with the frame allocation scheme.

The ability to allocate t_stack memory in a function that declares no t_scope is a clear departure from the behavior of the normal stack. With the standard program stack, a function cannot have side effects on the stack: when the function exits, it restores the stack to the state it had when the function started. In order to limit confusion, we do use a coding convention: when a function can have a side effect on the t_stack (that is, when it can allocate memory in a frame created by one of its callers) its name must be prefixed by t_. That way, it’s easy to detect missing t_scopes: if a function uses a t_ function but contains no t_scope, then either it should be named t_ or the t_scope has been inadvertently omitted.

An additional advantage of the t_stack is that it often (not always) makes error management easier compared to heap-allocations. Since the deallocation is automatic at the end of the t_scope, there is no need to have special code paths to handle them in case of error.
/* Error handling with heap-allocated memory.
 */
int process_data_heap(int len)
{
    /* We need a variable to remember the result. */
    int ret;
    /* We will need to deallocate memory, so we have to keep the
     * pointer in a variable.
     */
    byte *data = (byte *)malloc(len * sizeof(byte));

    ret = do_something(data, len);
    free(data);
    return ret;
}

/* Error handling with t_stack-allocated memory.
 */
int process_data_t_stack(int len)
{
    /* Associate the function scope to a t_stack frame.
     * That way all `t_stack`-allocated memory within the
     * function will be released at exit
     */
    t_scope;

    return do_something(t_new(byte, len), len);
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
	
/* Error handling with heap-allocated memory.
 */
int process_data_heap(int len)
{
    /* We need a variable to remember the result. */
    int ret;
    /* We will need to deallocate memory, so we have to keep the
     * pointer in a variable.
     */
    byte *data = (byte *)malloc(len * sizeof(byte));
 
    ret = do_something(data, len);
    free(data);
    return ret;
}
 
/* Error handling with t_stack-allocated memory.
 */
int process_data_t_stack(int len)
{
    /* Associate the function scope to a t_stack frame.
     * That way all `t_stack`-allocated memory within the
     * function will be released at exit
     */
    t_scope;
 
    return do_something(t_new(byte, len), len);
}

A side-effect of the use of the t_stack is that many short-term allocations that would have been done on the heap are now done on the t_stack. This reduces the fragmentation of the heap. And since the t_stack is thread-local, it is not subject to contentions.

The t_stack relies on non-standard extensions of the C language and is a bit of magic for newcomers at Intersec, but it certainly is one of the best addition to the language standard library we do have at Intersec.
Benchmark

We ran our benchmark on the stack allocator:
Scenario 	Allocation 	Deallocation 	Memory 	time
Uncontended 	833ms (120M/s) 	0ms 	1.5GiB 	2.99s

As you can see, the allocator is  fast: it outperforms both ptmalloc and tcmalloc in their optimal cases. Thanks to the frame mechanism, the deallocation does not depend at all on the number of allocations (the benchmark could be improved to measure the frame creation/destruction performance).

The current implementation of the stack allocator has a minimum allocation alignment of __BIGGEST_ALIGNMENT__, which is a platform-dependant constant that represents the maximum alignment requirement imposed by the CPU. On x86_64, that constant is set to 16 bytes because some instructions (such as SSE instructions) operate on 16 bytes vectors with a 16 bytes alignment requirement. This explains why the memory footprint is twice the optimal one.
FIFO allocator
The FIFO problem

Another frequent memory usage pattern is the use of (mostly) FIFO (first-in, first-out) pipes: meaning that memory is deallocated (approximatively) in the order which it was allocated. A typical use-case is  buffering request contexts in a network protocol implementation: each request is associated to a context that is allocated when the request is emitted and get freed when the reply is received. Most of the time, requests will be treated in the order they are emitted (this is not always true, but even long processing time is short compared to the execution time of this kind of process).

When FIFO data is allocated directly on the heap, it can amplify the fragmentation issue since the next deallocated chunk will probably not be at the end of the heap and thus will create a hole in it (and since the FIFO is not alone on the heap, other allocations will get inserted between two FIFO elements, making things even worse).
Solution

For those reasons, we decided to isolate such usage patterns from the remaining of the allocations. Instead of using heap allocations, we use a custom allocator.

This allocator works basically the same way as the the stack allocator: it consists of an arena of huge blocks of memory used linearly (a new block is allocated only when the next allocation cannot fit in the current block). Instead of using a frame-based model, the FIFO allocator uses a per-block size-accounting mechanism. Each block maintains the amount of allocated memory it contains. When all the data contained in a block has been released, the block itself is released. Blocks are allocated using mmap in order to ensure they will not interfere with the heap (and thus will not cause fragmentation).

Since the FIFO allocator shares the same allocation pattern (but not the same deallocation pattern) as the stack allocator, it shares some properties. One of the them is the fact that consecutive allocations are adjacent. However, the induced locality improvement is less important due to the usage pattern of FIFO allocators: most of the time, this is used to allocate independent elements that will rarely be used together.

The FIFO allocator is designed to be used in a single-threaded environment and thus is not subject to contention issues.
Benchmark

We ran our uncontended benchmark with the FIFO allocator in order to compare its performances with malloc()‘s performances:
Scenario 	Allocation 	Deallocation 	Memory 	time
Uncontended 	1100ms (90M/s) 	638ms (156M/s) 	1.5GiB 	5.30s

As for the stack allocator, the FIFO allocator outperforms malloc() implementations. However it is a bit slower than the stack allocator because it has to track each allocation independently and may not have been as optimized as the stack allocator.
Ring allocator

The ring allocator is somehow a mix between the stack and FIFO allocators. It uses frames to group allocations and allows constant time deallocation of a large number of allocations while having a mostly-FIFO usage pattern. The frames in the ring allocator are not imbricated in the previous ones, each frame is independent and self-contained.

In order to allocate memory in the ring allocator, the first step is to create a new frame. This requires that the previous frame has been sealed. Once a frame is opened in the allocator, allocations can be made and will automatically be part of the active frame. When all the allocations have been done, the frame must be sealed. A sealed frame is still alive, that means that the allocations it contains are still accessible, but the frame just cannot accept new allocations. When the frame is not needed anymore, it must be released.

Releasing memory in the ring allocator is thread safe. This makes that allocator very useful to build messages to be transferred for processing to a worker thread. In that context it works as a nearly immediate replacement of the t_stack for code that need multi-threaded treatment.
/* Single threaded version, use t_stack.
 */
void do_job(void)
{
    t_scope;
    job_ctx_t *ctx = t_new(job_ctx_t, 1);

    run_job(ctx);
}

/* Multi-threaded version, using ring allocation.
 * Note that it uses Apple's block extension.
 */
void do_job(void)
{
    const void *frame = r_newframe();
    job_ctx_t *ctx = r_new(job_ctx_t, 1);

    r_seal();
    thr_schedule(^{
        run_job(ctx);
        r_release(frame);
    });
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
	
/* Single threaded version, use t_stack.
 */
void do_job(void)
{
    t_scope;
    job_ctx_t *ctx = t_new(job_ctx_t, 1);
 
    run_job(ctx);
}
 
/* Multi-threaded version, using ring allocation.
 * Note that it uses Apple's block extension.
 */
void do_job(void)
{
    const void *frame = r_newframe();
    job_ctx_t *ctx = r_new(job_ctx_t, 1);
 
    r_seal();
    thr_schedule(^{
        run_job(ctx);
        r_release(frame);
    });
}

In this use case, frames get released in mostly-FIFO order.

Once again, we ran our benchmark using that allocator. Since the ring allocator is thread-safe, the benchmark covers both the contended and the non-contended cases:
Scenario 	Allocation 	Deallocation 	Memory 	time
Uncontended 	861ms (116M/s) 	0ms 	764MiB 	2.82s
Contended 	862ms (116M/s) 	0ms 	764MiB 	2.83s
Other custom allocators

This article covers three custom allocators we have at Intersec. These three allocators are not for a general purpose: they are optimized for specific usage patterns. Thankfully, most of the time a combination of these three allocators is enough to avoid most issues we can encounter with malloc() such as the lack of locality, locking contention during allocation and heap fragmentation.

However, sometimes this is not the case and we have no choice but to build a custom implementation of a general purpose allocator to fit with our performance requirements. For this reason, we also have a TLSF (Two Level Segregate Fit) based allocator. TLSF is an allocation algorithm that has been designed for real-time processing, it is guaranteed to operate in constant time (for both allocation and deallocation).

More anecdotal, we also have some page allocators and a persistent allocator. This last one will probably be covered in a future article.
Next: debugging tools

In the final article of this series, we will cover tools to deal with memory issues

= part 5 :

Memory – Part 5: Debugging Tools
December 14, 2013, by Florent Bruneau	

    1 Introduction
    2 Debugger
    3 valgrind
        3.1 memcheck
        3.2 massif
    4 Address Sanitizer
    5 Conclusion

Introduction

Here we are! We spent 4 articles explaining what memory is, how to deal with it and what are the kind of problems you can expect from it. Even the best developers write bugs. A commonly accepted estimation seems to be around of few tens of bugs per thousand of lines of code, which is definitely quite huge. As a consequence, even if you proficiently mastered all the concepts covered by our articles, you’ll still probably have a few memory-related bugs.

Memory-related bugs may be particularly hard to spot and fix. Let’s take the following program as an example:
#include <stdio.h>

#define MAX_LINE_SIZE  32

static const char *build_message(const char *name)
{
    char message[MAX_LINE_SIZE];

    sprintf(message, "hello %s!\n", name);
    return message;
}

int main(int argc, char *argv[])
{
    fputs(build_message(argc > 1 ? argv[1] : "world"), stdout);
    return 0;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
	
#include <stdio.h>
 
#define MAX_LINE_SIZE  32
 
static const char *build_message(const char *name)
{
    char message[MAX_LINE_SIZE];
 
    sprintf(message, "hello %s!\n", name);
    return message;
}
 
int main(int argc, char *argv[])
{
    fputs(build_message(argc > 1 ? argv[1] : "world"), stdout);
    return 0;
}

This program is supposed to take a message as argument and print “hello <message>!” (the default message being “world”).

The behavior of this program is completely undefined, it is buggy, however it will probably not crash. The function build_message returns a pointer to some memory allocated in its stack-frame. Because of how the stack works, that memory is very susceptible to be overwritten by another function call later, possibly by fputs. As a consequence, if fputs internally uses sufficient stack-memory to overwrite the message, then the output will be corrupted (and the program may even crash), in the other case the program will print the expected message. Moreover, the program may overflow its buffer because of the use of the unsafe sprintf function that has no limit in the number of bytes written.

So, the behavior of the program varies depending on the size of the message given in the command line, the value of MAX_LINE_SIZE and the implementation of fputs. What’s annoying with this kind of bug is that the result may not be obvious: the program “works” well enough with simple use cases and will only fail the day it will receive a parameter with the right properties to exhibit the issue. That’s why it’s important that developers are at ease with some tools that will help them to validate (or to debug) memory management.

In this last article, we will cover some free tools that we consider should be part of the minimal toolkit of a C (and C++) developer.

Debugger

The first of these tools is the debugger. On Linux this will probably be gdb. Most developers know at least the basics of gdb: inspecting a backtrace (bt, up, down, frame <id>, …), adding a breakpoint (break <function|line>, continue, …), executing step-by-step (step, next, fin, …), inspecting memory (print <expr>, call <func>, x/<FMT> <addr>, …), … The debugger is the tool of choice of most developers in the case the program crashes with a segmentation fault.Then the debugger will automatically catch the signal and allow inspecting the state of the program at that instant. A lot of segmentation faults are obvious (uninitialized pointer, NULL pointer dereference, …) and require little work from the debugger.

Less known however, is the ability to place a watchpoint: adding a dynamic breakpoint that will interrupt the program every time the result of an expression changes. This is extremely useful to detect the origin of a memory corruption: place a watchpoint on the content of the memory that get corrupted and as a consequence the program will be interrupted each time the content of that memory changes. This has very little impact on the performance of the program because, as long as you don’t want to monitor too much memory addresses, the watchpoint is managed directly by the hardware.

Take back the example given in the introduction: we do run fputs that prints the content of the pointer given as its first argument, however, the actually printed string is not the one we wrote in build_message. Here is a small debugging session:

    First we set a breakpoint on build message and check that sprintf properly built our message

(gdb) break build_message
Breakpoint 1 at 0x400598: file blah.c, line 7.
(gdb) run
Starting program: /home/fruneau/blah
warning: no loadable sections found in added symbol-file system-supplied DSO at 0x7ffff7ffa000
warning: Could not load shared library symbols for linux-vdso.so.1.
Do you need "set solib-search-path" or "set sysroot"?

Breakpoint 1, build_message (name=0x4006bf "world") at blah.c:7
7	    sprintf(message, "hello %s!\n", name);
(gdb) n
8	    return message;
(gdb) p message
$1 = "hello world!\n\000\000\000\001\000\000\000\000\000\000\000m\006@\000\000\000\000"
1
2
3
4
5
6
7
8
9
10
11
12
13
14
	
(gdb) break build_message
Breakpoint 1 at 0x400598: file blah.c, line 7.
(gdb) run
Starting program: /home/fruneau/blah
warning: no loadable sections found in added symbol-file system-supplied DSO at 0x7ffff7ffa000
warning: Could not load shared library symbols for linux-vdso.so.1.
Do you need "set solib-search-path" or "set sysroot"?
 
Breakpoint 1, build_message (name=0x4006bf "world") at blah.c:7
7	    sprintf(message, "hello %s!\n", name);
(gdb) n
8	    return message;
(gdb) p message
$1 = "hello world!\n\000\000\000\001\000\000\000\000\000\000\000m\006@\000\000\000\000"

    In order to be notified whenever the message gets modified, we place a watchpoint on the content of the first character of the string and we let the program continu. The debugger lets us know that it successfully put a hardware watchpoint, which is nice, because a software watchpoint would have a more noticeable impact on the overall performance.

(gdb) watch $1[0]
Hardware watchpoint 2: $1[0]
(gdb) c
Continuing.
1
2
3
4
	
(gdb) watch $1[0]
Hardware watchpoint 2: $1[0]
(gdb) c
Continuing.

    The watchpoint interrupts the execution of the program. The debugger prints the old and the new value and we can easily inspect the program. A quick look at the backtrace lets us know that we are somewhere in the code of the dynamic linker (probably during the resolution of the symbol for fputs).

Hardware watchpoint 2: $1[0]

Old value = 104 'h'
New value = 32 ' '
0x00007ffff7def1fc in ?? () from /lib64/ld-linux-x86-64.so.2
(gdb) bt
#0  0x00007ffff7def1fc in ?? () from /lib64/ld-linux-x86-64.so.2
#1  0x00000000004005ff in main (argc=1, argv=0x7fffffffe258) at blah.c:13
1
2
3
4
5
6
7
8
	
Hardware watchpoint 2: $1[0]
 
Old value = 104 'h'
New value = 32 ' '
0x00007ffff7def1fc in ?? () from /lib64/ld-linux-x86-64.so.2
(gdb) bt
#0  0x00007ffff7def1fc in ?? () from /lib64/ld-linux-x86-64.so.2
#1  0x00000000004005ff in main (argc=1, argv=0x7fffffffe258) at blah.c:13

Here, the debugger tells us where the memory gets changed, however understanding the issue requires some understanding of what is going on. The debugger provides raw information, the developer remains in charge of the analysis. More generally, the debugger is a good tool whenever you know what to look for.
valgrind

valgrind is some kind of swiss knife of the C/C++ developer. It provides various tools such as a memory checker (memcheck), a memory profiler (massif), a cache profiler (cachegrind), a CPU profiler (callgrind), some thread checkers (helgrind, DRD, tsan), …

valgrind is basically a virtual machine that monitors every interaction with the operating system and the virtualized hardware. In order to achieve this, it takes an unmodified executable and wraps every single CPU instruction and every system call with instrumented version. It is extremely configurable: you can define the exact desired behavior of your virtual machine: the number of cores, the size of the caches, the behavior of the system calls (for system calls whose behavior varies from one kernel version to another)… The main drawback however, is that since the code is not directly executed, valgrind has an important overhead and cause a substantial slowdown that varies from 5x to 50x, depending on the tool and the chosen options.

Running valgrind is easy. It requires no modification of your program or of your build system in order to work (however, it can benefit from making some code valgrind-aware). The most basic incantation is just: valgrind --tool=<toolname> <yourprogram and arguments>.
memcheck

memcheck is the default tool of valgrind. It’s a memory checker that tracks every single memory access and allocation looking for management errors such as:

    accessing not allocated memory
    making the program behavior depend on non-initialized memory
    leaking some allocated memory

To do this, the first thing memcheck does is to maintain a registry of all allocated memory. Every time a new chunk memory is allocated memcheck keeps track of it by remembering the returned pointer, the amount of memory allocated as well as the backtrace from which it has been allocated. Additionally, it adds some redzones around the allocated memory that cannot be allocated in order to easily detect out-of-buffer accesses.

Needless to say it will also catch every single deallocation in order to keep its registry up to date. The deallocation does not immediately remove the entry from the registry, it marks it as deallocated and remembers the deallocation backtrace. By putting deallocated memory in quarantine, it ensures that use-after-free accesses can be caught as such since that memory cannot be reused for other purpose too rapidly.

At the end of the execution of the program, memcheck will dump its registry: every entry that is not marked as deallocated is a leaked allocation. The report of leaked allocations is associated with the information whether the memory is still referenced or not. Memory that is not pointed anymore by the program is considered as definitely lost.

Additionally, for every single allocated byte, memcheck also maintains an initialization state: memory is considered initialized if, and only if, its value is the result of the computation that uses only initialized bytes. As soon as a non-initialized byte is used in a computation, the result of the computation is undefined and if the program behavior depends on that result, its own behavior is considered undefined.

Overall, at the cost of a massive slowdown and some memory overhead, memcheck detects most dynamic-allocation related errors. However, it’s far less efficient in detecting errors in code that uses static memory or stack-allocated memory because memcheck has very few insights on the internals of the program: it does not know about the various variables that are put on the stack and thus cannot check that you are not overflowing from a stack-allocated buffer on a nearby variable.

A good standard is to impose that every written code be memcheck-clean (or valgrind-clean): a program is not good enough if it produces some errors when run within valgrind. That does not guarantee the program is bug-free, however it ensures that the allocations are well-down. However, that standard is often hard to reach because, for real-life programs, the slowdown of memcheck reaches 40x which makes it almost impossible to run too often. Thankfully, tools such as ASan (covered later in that post) can be used for this purpose.

The documentation of memcheck is full of small examples, so let’s stop paraphrasing the upstream documentation and see what memcheck produces on our small buggy program:
==368== Memcheck, a memory error detector
==368== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al.
==368== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info
==368== Command: ./blah
==368==
==368== Invalid read of size 1
==368==    at 0x4C2C872: __GI_strlen (mc_replace_strmem.c:400)
==368==    by 0x4E9ED5D: fputs (iofputs.c:36)
==368==    by 0x40060D: main (blah.c:15)
==368==  Address 0x7fefffc10 is just below the stack ptr.  To suppress, use: --workaround-gcc296-bugs=yes
==368==
==368== Invalid read of size 1
==368==    at 0x4C2C884: __GI_strlen (mc_replace_strmem.c:400)
==368==    by 0x4E9ED5D: fputs (iofputs.c:36)
==368==    by 0x40060D: main (blah.c:15)
==368==  Address 0x7fefffc11 is just below the stack ptr.  To suppress, use: --workaround-gcc296-bugs=yes
==368==
==368== Invalid read of size 1
==368==    at 0x4EAB29C: _IO_default_xsputn (genops.c:481)
==368==    by 0x4EA9972: _IO_file_xsputn@@GLIBC_2.2.5 (fileops.c:1364)
==368==    by 0x4E9EDDB: fputs (iofputs.c:41)
==368==    by 0x40060D: main (blah.c:15)
==368==  Address 0x7fefffc10 is just below the stack ptr.  To suppress, use: --workaround-gcc296-bugs=yes
==368==
g==368==
==368== HEAP SUMMARY:
==368==     in use at exit: 0 bytes in 0 blocks
==368==   total heap usage: 0 allocs, 0 frees, 0 bytes allocated
==368==
==368== All heap blocks were freed -- no leaks are possible
==368==
==368== For counts of detected and suppressed errors, rerun with: -v
==368== ERROR SUMMARY: 5 errors from 3 contexts (suppressed: 2 from 2)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
	
==368== Memcheck, a memory error detector
==368== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al.
==368== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info
==368== Command: ./blah
==368==
==368== Invalid read of size 1
==368==    at 0x4C2C872: __GI_strlen (mc_replace_strmem.c:400)
==368==    by 0x4E9ED5D: fputs (iofputs.c:36)
==368==    by 0x40060D: main (blah.c:15)
==368==  Address 0x7fefffc10 is just below the stack ptr.  To suppress, use: --workaround-gcc296-bugs=yes
==368==
==368== Invalid read of size 1
==368==    at 0x4C2C884: __GI_strlen (mc_replace_strmem.c:400)
==368==    by 0x4E9ED5D: fputs (iofputs.c:36)
==368==    by 0x40060D: main (blah.c:15)
==368==  Address 0x7fefffc11 is just below the stack ptr.  To suppress, use: --workaround-gcc296-bugs=yes
==368==
==368== Invalid read of size 1
==368==    at 0x4EAB29C: _IO_default_xsputn (genops.c:481)
==368==    by 0x4EA9972: _IO_file_xsputn@@GLIBC_2.2.5 (fileops.c:1364)
==368==    by 0x4E9EDDB: fputs (iofputs.c:41)
==368==    by 0x40060D: main (blah.c:15)
==368==  Address 0x7fefffc10 is just below the stack ptr.  To suppress, use: --workaround-gcc296-bugs=yes
==368==
g==368==
==368== HEAP SUMMARY:
==368==     in use at exit: 0 bytes in 0 blocks
==368==   total heap usage: 0 allocs, 0 frees, 0 bytes allocated
==368==
==368== All heap blocks were freed -- no leaks are possible
==368==
==368== For counts of detected and suppressed errors, rerun with: -v
==368== ERROR SUMMARY: 5 errors from 3 contexts (suppressed: 2 from 2)

This is a bit more meaningful that the debugging session in gdb. It tells us that fputs is calling strlen (which is quite obviously needed to compute the length of the string it should print), but that strlen reaches some memory that is just below the stack pointer (it actually gone two bytes below the stack pointer). This will still require some analysis, but this time it is quite easy: we are computing the length of a string that is on the same memory as the stack, but that seems to be partially outside of the stack.

A last useful trick with valgrind is its ability to interact with a debugger. Start you program with valgrind --db-attach=yes <yourprogram>. Then every time memcheck reports an error, you’ll be asked whether or not you’d like to debug that error in a debugger.
massif

massif is a different kind of tool, it is a memory profiler. It also tracks memory allocations and deallocations, but instead of checking every memory address, it builds a timeline of memory usage. For some chosen moments of the program (such as the moment at which the program had the higher memory usage), it keeps the count of allocations for every single backtrace.

At the end, it dumps the report, by default named massif.out.<pid>. The report is a list of snapshots of the repartions of the memory allocations. It’s hard to process manually. However some tools such as ms_print produce reports easier to understand. The output of ms_print starts with an ASCII-art histogram that visually shows the memory usage:
     MB
    1.093^                                                                       #
         |                                                               @:@@:@@:#
         |                                                        @::::@:@:@@:@@:#
         |                                                    ::::@::::@:@:@@:@@:#
         |                                            :::::@::::::@::::@:@:@@:@@:#
         |                                    :@:::@::::: :@::::::@::::@:@:@@:@@:#
         |                               ::::::@:::@::::: :@::::::@::::@:@:@@:@@:#
         |                       @@::::::::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         |                    ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         |              @@::::::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         |        ::@@:@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@@:: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
       0 +----------------------------------------------------------------------->Gi
         0                                                                   2.093
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
	
     MB
    1.093^                                                                       #
         |                                                               @:@@:@@:#
         |                                                        @::::@:@:@@:@@:#
         |                                                    ::::@::::@:@:@@:@@:#
         |                                            :::::@::::::@::::@:@:@@:@@:#
         |                                    :@:::@::::: :@::::::@::::@:@:@@:@@:#
         |                               ::::::@:::@::::: :@::::::@::::@:@:@@:@@:#
         |                       @@::::::::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         |                    ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         |              @@::::::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         |        ::@@:@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@@:: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
         | ::::@ :: @ :@@ ::: ::@@ :::: :::: ::@:::@::::: :@::::::@::::@:@:@@:@@:#
       0 +----------------------------------------------------------------------->Gi
         0                                                                   2.093

The # column represents the peak of memory usage, while the @ columns are the detailed snapshots available in the report. If your report looks like this one, you probably have a memory leak in your program, and you should consider fixing it.

The diagram is followed by a table containing the memory usage at every snapshot. It looks like this:
--------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
  0              0                0                0             0            0
  1      3,168,761               56               36            20            0
  2      3,174,580            1,752            1,662            90            0
  3      3,212,178            1,936            1,838            98            0
  4      3,237,022            3,720            3,534           186            0
  5      3,265,560            5,096            4,942           154            0
  6      3,292,818            6,536            6,382           154            0
  7      3,311,840            6,784            6,622           162            0
  8      3,339,186            8,888            8,622           266            0
  9      3,357,738           17,768           17,470           298            0
 10      3,379,121           18,080           17,774           306            0
 11      3,401,477           18,104           17,789           315            0
 12      3,418,256           86,864           86,339           525            0
 13      3,446,913           87,680           87,078           602            0
 14      3,547,965           87,680           87,078           602            0
99.31% (87,078B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->87.85% (77,024B) 0x467826: libc_malloc (core-mem.c:50)
| ->74.74% (65,536B) 0x4688FD: mem_alloc (core-mem.h:290)
| | ->74.74% (65,536B) 0x42AB07: master_load_conf.isra.15 (master.blk:2612)
| |   ->74.74% (65,536B) 0x42F88E: platform_start_master (master.blk:2748)
| |     ->74.74% (65,536B) 0x42419E: main (master-main.c:120)
| |
| ->10.07% (8,832B) 0x45A240: thr_initialize (core-mem.h:290)
| | ->10.07% (8,832B) 0x43BD38: platform_initialize (platform.blk:856)
| |   ->10.07% (8,832B) 0x42F85B: platform_start_master (master.blk:2743)
| |     ->10.07% (8,832B) 0x42419E: main (master-main.c:120)
| |
| ->01.92% (1,680B) 0x42DAD0: platform_master_register_service (core-mem.h:290)
| | ->01.92% (1,680B) in 7 places, all below massif's threshold (01.00%)
| |
| ->01.11% (976B) in 6 places, all below massif's threshold (01.00%)
|
->05.64% (4,945B) 0x4678DE: libc_realloc (core-mem.c:74)
| ->03.54% (3,104B) 0x46326F: qhash_resize_start (core-mem.h:310)
| | ->03.54% (3,104B) 0x464A91: __qhash_put_vec (container-qhash.in.c:258)
| |   ->01.77% (1,552B) 0x44E44F: iop_register_class (iop.blk:40)
| |   | ->01.77% (1,552B) 0x456241: iop_register_packages (iop.blk:2924)
| |   | | ->01.77% (1,552B) 0x435018: bon_initialize (base.c:27)
| |   | |   ->01.77% (1,552B) 0x424143: main (master-main.c:109)
| |   | |
| |   | ->00.00% (0B) in 1+ places, all below ms_print's threshold (01.00%)
| |   |
| |   ->01.77% (1,552B) 0x44E540: iop_register_class (iop.blk:62)
| |     ->01.77% (1,552B) 0x456241: iop_register_packages (iop.blk:2924)
| |     | ->01.77% (1,552B) 0x435018: bon_initialize (base.c:27)
| |     |   ->01.77% (1,552B) 0x424143: main (master-main.c:109)
| |     |
| |     ->00.00% (0B) in 1+ places, all below ms_print's threshold (01.00%)
| |
| ->01.77% (1,552B) 0x463309: qhash_resize_start (core-mem.h:310)
| | ->01.77% (1,552B) 0x464A91: __qhash_put_vec (container-qhash.in.c:258)
| |   ->01.77% (1,552B) in 2 places, all below massif's threshold (01.00%)
| |
| ->00.33% (289B) in 1+ places, all below ms_print's threshold (01.00%)
|
->02.19% (1,923B) 0x5719785: __tzfile_read (tzfile.c:291)
| ->02.19% (1,923B) 0x5718DAE: tzset_internal (tzset.c:444)
|   ->02.19% (1,923B) 0x571903E: tzset (tzset.c:597)
|     ->02.19% (1,923B) 0x437D87: log_initialize (log.blk:932)
|       ->02.19% (1,923B) 0x43BD3D: platform_initialize (platform.blk:857)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
	
--------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
  0              0                0                0             0            0
  1      3,168,761               56               36            20            0
  2      3,174,580            1,752            1,662            90            0
  3      3,212,178            1,936            1,838            98            0
  4      3,237,022            3,720            3,534           186            0
  5      3,265,560            5,096            4,942           154            0
  6      3,292,818            6,536            6,382           154            0
  7      3,311,840            6,784            6,622           162            0
  8      3,339,186            8,888            8,622           266            0
  9      3,357,738           17,768           17,470           298            0
 10      3,379,121           18,080           17,774           306            0
 11      3,401,477           18,104           17,789           315            0
 12      3,418,256           86,864           86,339           525            0
 13      3,446,913           87,680           87,078           602            0
 14      3,547,965           87,680           87,078           602            0
99.31% (87,078B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->87.85% (77,024B) 0x467826: libc_malloc (core-mem.c:50)
| ->74.74% (65,536B) 0x4688FD: mem_alloc (core-mem.h:290)
| | ->74.74% (65,536B) 0x42AB07: master_load_conf.isra.15 (master.blk:2612)
| |   ->74.74% (65,536B) 0x42F88E: platform_start_master (master.blk:2748)
| |     ->74.74% (65,536B) 0x42419E: main (master-main.c:120)
| |
| ->10.07% (8,832B) 0x45A240: thr_initialize (core-mem.h:290)
| | ->10.07% (8,832B) 0x43BD38: platform_initialize (platform.blk:856)
| |   ->10.07% (8,832B) 0x42F85B: platform_start_master (master.blk:2743)
| |     ->10.07% (8,832B) 0x42419E: main (master-main.c:120)
| |
| ->01.92% (1,680B) 0x42DAD0: platform_master_register_service (core-mem.h:290)
| | ->01.92% (1,680B) in 7 places, all below massif's threshold (01.00%)
| |
| ->01.11% (976B) in 6 places, all below massif's threshold (01.00%)
|
->05.64% (4,945B) 0x4678DE: libc_realloc (core-mem.c:74)
| ->03.54% (3,104B) 0x46326F: qhash_resize_start (core-mem.h:310)
| | ->03.54% (3,104B) 0x464A91: __qhash_put_vec (container-qhash.in.c:258)
| |   ->01.77% (1,552B) 0x44E44F: iop_register_class (iop.blk:40)
| |   | ->01.77% (1,552B) 0x456241: iop_register_packages (iop.blk:2924)
| |   | | ->01.77% (1,552B) 0x435018: bon_initialize (base.c:27)
| |   | |   ->01.77% (1,552B) 0x424143: main (master-main.c:109)
| |   | |
| |   | ->00.00% (0B) in 1+ places, all below ms_print's threshold (01.00%)
| |   |
| |   ->01.77% (1,552B) 0x44E540: iop_register_class (iop.blk:62)
| |     ->01.77% (1,552B) 0x456241: iop_register_packages (iop.blk:2924)
| |     | ->01.77% (1,552B) 0x435018: bon_initialize (base.c:27)
| |     |   ->01.77% (1,552B) 0x424143: main (master-main.c:109)
| |     |
| |     ->00.00% (0B) in 1+ places, all below ms_print's threshold (01.00%)
| |
| ->01.77% (1,552B) 0x463309: qhash_resize_start (core-mem.h:310)
| | ->01.77% (1,552B) 0x464A91: __qhash_put_vec (container-qhash.in.c:258)
| |   ->01.77% (1,552B) in 2 places, all below massif's threshold (01.00%)
| |
| ->00.33% (289B) in 1+ places, all below ms_print's threshold (01.00%)
|
->02.19% (1,923B) 0x5719785: __tzfile_read (tzfile.c:291)
| ->02.19% (1,923B) 0x5718DAE: tzset_internal (tzset.c:444)
|   ->02.19% (1,923B) 0x571903E: tzset (tzset.c:597)
|     ->02.19% (1,923B) 0x437D87: log_initialize (log.blk:932)
|       ->02.19% (1,923B) 0x43BD3D: platform_initialize (platform.blk:857)

The first 14 lines here are simple snapshots with only the report about heap-consumption, while the line number 14 is followed by the detailed report about allocation. We can see that at that point, most of the allocated memory was the consequence of the configuration loading.
Address Sanitizer

Address Sanitizer (or ASan) is a much more recent tool. It has been initiated by Google in order to provide good memory checking tools without the performance drawback of memcheck for large projects such as WebKit or Chromium. ASan still slows the program down, but by a factor 2, not 40. The tradeoff however is that ASan won’t detect errors such as uses of uninitialized variables or leaks that memcheck can detect, but on the other hand it can detect more errors related to static or stack memory. ASan was first introduced in LLVM/clang 3.1 and has since made its way to GCC with GCC 4.8.

ASan is a pair of tools: first a compiler pass and second a runtime. The runtime of ASan allocates a shadow memory: a huge chunk of RAM that it used to store a single byte for every 8byte word of memory. By default all the memory has its shadow bytes set to 0 which means it is not accessible. Then, when memory gets allocated, the shadow bytes are set to some other values that bring information about which bytes of the word are allocated, who allocated them, … It also overloads the allocators in order to be able to track the allocations and deallocations of memory. Just like memcheck, it will put deallocated memory in a quarantine in order to be able to detect use-after-free accesses.

Then each time a memory access is performed, the runtime will check the values of the associated shadow bytes and if the access is disallowed, ASan will abort the execution of the program: ASan crashes the program on the first error, this forces the program to be ASan-clean.

Overall, the runtime of ASan is less-feature complete than valgrind: it won’t be able to detect memory leaks or access to non-initialized memory. However, most of the power of ASan comes from its compiler-side component. The fact that ASan is intrusive may seem inconvenient, however this allows some closer integration with the program itself. On the other hand, it will only check code that has been instrumented, and won’t be able to catch errors that occur in third party libraries (for example, in the libc).

The main role of the compiler pass is to wrap every single memory access in a small branch that will check that the access is allowed by checking the content of the shadow memory. But, since it is in the compiler, it has access to a lot of information such as, what memory we are accessing, what is the layout of the variables (or the structure members), … and it can also alter all of this. And that is where ASan shines: it can add redzones between global variables or between variables that are put on the stack in order to make bad accesses to those variables easy to detect.

ASan can detect both issues of our example, however since the issue occurs only in functions of the libc, this will not happen as-is. At Intersec, we have our own implementation of sprintf, which cause it to be instrumented by ASan with the program. Here is the output of ASan with a too-long string passed as argument (after running asan_symbolize.py on the output to get the symbol names):
% ./blah "coucoeucoijfmiqjfmiqjfmqifjqemfijeqmfijeqfmiqejfmqesifjqemsifj" 2>&1 | asan_symbolize.py
=================================================================
==17688==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7fffff9fc8c0 at pc 0x425633 bp 0x7fffff9f98f0 sp 0x7fffff9f90b0
WRITE of size 62 at 0x7fffff9fc8c0 thread T0
    #0 0x425632 in memcpy ??:0
    #1 0x4555ea in fmt_output_chunk /home/fruneau/dev/mmsx/lib-common/str-iprintf.c:372
    #2 0x438aa8 in fmt_output /home/fruneau/dev/mmsx/lib-common/str-iprintf.c:453
    #3 0x44b2dc in isprintf /home/fruneau/dev/mmsx/lib-common/str-iprintf.c:1275
    #4 0x4373c5 in build_message /home/fruneau/dev/mmsx/lib-common/blah.c:9
    #5 0x436faa in main /home/fruneau/dev/mmsx/lib-common/blah.c:22
    #6 0x7ff113f1da54 in __libc_start_main /home/adconrad/eglibc-2.17/csu/libc-start.c:260
    #7 0x436c6c in _start ??:0
Address 0x7fffff9fc8c0 is located in stack of thread T0 at offset 128 in frame
    #0 0x4372cf in build_message /home/fruneau/dev/mmsx/lib-common/blah.c:6
  This frame has 2 object(s):
    [32, 40) ''
    [96, 128) 'message'
HINT: this may be a false positive if your program uses some custom stack unwind mechanism or swapcontext
      (longjmp and C++ exceptions *are* supported)
Shadow bytes around the buggy address:
  0x10007ff378c0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007ff378d0: f1 f1 f1 f1 00 f4 f4 f4 f2 f2 f2 f2 00 f4 f4 f4
  0x10007ff378e0: f2 f2 f2 f2 00 00 00 f4 f2 f2 f2 f2 04 f4 f4 f4
  0x10007ff378f0: f3 f3 f3 f3 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007ff37900: 00 00 00 00 00 00 00 00 f1 f1 f1 f1 00 f4 f4 f4
=>0x10007ff37910: f2 f2 f2 f2 00 00 00 00[f3]f3 f3 f3 00 00 00 00
  0x10007ff37920: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007ff37930: f1 f1 f1 f1 04 f4 f4 f4 f2 f2 f2 f2 04 f4 f4 f4
  0x10007ff37940: f2 f2 f2 f2 00 f4 f4 f4 f3 f3 f3 f3 00 00 00 00
  0x10007ff37950: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007ff37960: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07
  Heap left redzone:     fa
  Heap right redzone:    fb
  Freed heap region:     fd
  Stack left redzone:    f1
  Stack mid redzone:     f2
  Stack right redzone:   f3
  Stack partial redzone: f4
  Stack after return:    f5
  Stack use after scope: f8
  Global redzone:        f9
  Global init order:     f6
  Poisoned by user:      f7
  ASan internal:         fe
==17688==ABORTING
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
	
% ./blah "coucoeucoijfmiqjfmiqjfmqifjqemfijeqmfijeqfmiqejfmqesifjqemsifj" 2>&1 | asan_symbolize.py
 
=================================================================
==17688==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7fffff9fc8c0 at pc 0x425633 bp 0x7fffff9f98f0 sp 0x7fffff9f90b0
WRITE of size 62 at 0x7fffff9fc8c0 thread T0
    #0 0x425632 in memcpy ??:0
    #1 0x4555ea in fmt_output_chunk /home/fruneau/dev/mmsx/lib-common/str-iprintf.c:372
    #2 0x438aa8 in fmt_output /home/fruneau/dev/mmsx/lib-common/str-iprintf.c:453
    #3 0x44b2dc in isprintf /home/fruneau/dev/mmsx/lib-common/str-iprintf.c:1275
    #4 0x4373c5 in build_message /home/fruneau/dev/mmsx/lib-common/blah.c:9
    #5 0x436faa in main /home/fruneau/dev/mmsx/lib-common/blah.c:22
    #6 0x7ff113f1da54 in __libc_start_main /home/adconrad/eglibc-2.17/csu/libc-start.c:260
    #7 0x436c6c in _start ??:0
Address 0x7fffff9fc8c0 is located in stack of thread T0 at offset 128 in frame
    #0 0x4372cf in build_message /home/fruneau/dev/mmsx/lib-common/blah.c:6
  This frame has 2 object(s):
    [32, 40) ''
    [96, 128) 'message'
HINT: this may be a false positive if your program uses some custom stack unwind mechanism or swapcontext
      (longjmp and C++ exceptions *are* supported)
Shadow bytes around the buggy address:
  0x10007ff378c0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007ff378d0: f1 f1 f1 f1 00 f4 f4 f4 f2 f2 f2 f2 00 f4 f4 f4
  0x10007ff378e0: f2 f2 f2 f2 00 00 00 f4 f2 f2 f2 f2 04 f4 f4 f4
  0x10007ff378f0: f3 f3 f3 f3 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007ff37900: 00 00 00 00 00 00 00 00 f1 f1 f1 f1 00 f4 f4 f4
=>0x10007ff37910: f2 f2 f2 f2 00 00 00 00[f3]f3 f3 f3 00 00 00 00
  0x10007ff37920: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007ff37930: f1 f1 f1 f1 04 f4 f4 f4 f2 f2 f2 f2 04 f4 f4 f4
  0x10007ff37940: f2 f2 f2 f2 00 f4 f4 f4 f3 f3 f3 f3 00 00 00 00
  0x10007ff37950: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007ff37960: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07
  Heap left redzone:     fa
  Heap right redzone:    fb
  Freed heap region:     fd
  Stack left redzone:    f1
  Stack mid redzone:     f2
  Stack right redzone:   f3
  Stack partial redzone: f4
  Stack after return:    f5
  Stack use after scope: f8
  Global redzone:        f9
  Global init order:     f6
  Poisoned by user:      f7
  ASan internal:         fe
==17688==ABORTING

Doing the same thing with a short string and a reimplementation of fputs gives the same kind of result:
% ./blah 2>&1 | asan_symbolize.py
=================================================================
==17891==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7fffd15a3ce4 at pc 0x426ae6 bp 0x7fffd15a3bd0 sp 0x7fffd15a3ba8
READ of size 14 at 0x7fffd15a3ce4 thread T0
    #0 0x426ae5 in strlen ??:0
    #1 0x43719a in my_fputs /home/fruneau/dev/mmsx/lib-common/blah.c:15
    #2 0x436fe7 in main /home/fruneau/dev/mmsx/lib-common/blah.c:22
    #3 0x7f1a99108a54 in __libc_start_main /home/adconrad/eglibc-2.17/csu/libc-start.c:260
    #4 0x436c6c in _start ??:0
Address 0x7fffd15a3ce4 is located in stack of thread T0 at offset 164 in frame
    #0 0x43704f in my_fputs /home/fruneau/dev/mmsx/lib-common/blah.c:14
  This frame has 3 object(s):
    [32, 40) ''
    [96, 104) ''
    [160, 164) 'len'
HINT: this may be a false positive if your program uses some custom stack unwind mechanism or swapcontext
      (longjmp and C++ exceptions *are* supported)
Shadow bytes around the buggy address:
  0x10007a2ac740: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac750: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac760: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac770: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac780: 00 00 00 00 00 00 00 00 f1 f1 f1 f1 00 f4 f4 f4
=>0x10007a2ac790: f2 f2 f2 f2 00 f4 f4 f4 f2 f2 f2 f2[04]f4 f4 f4
  0x10007a2ac7a0: f3 f3 f3 f3 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac7b0: 00 00 00 00 00 00 00 00 f1 f1 f1 f1 04 f4 f4 f4
  0x10007a2ac7c0: f2 f2 f2 f2 04 f4 f4 f4 f2 f2 f2 f2 00 f4 f4 f4
  0x10007a2ac7d0: f3 f3 f3 f3 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac7e0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07
  Heap left redzone:     fa
  Heap right redzone:    fb
  Freed heap region:     fd
  Stack left redzone:    f1
  Stack mid redzone:     f2
  Stack right redzone:   f3
  Stack partial redzone: f4
  Stack after return:    f5
  Stack use after scope: f8
  Global redzone:        f9
  Global init order:     f6
  Poisoned by user:      f7
  ASan internal:         fe
==17891==ABORTING
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
	
% ./blah 2>&1 | asan_symbolize.py
 
=================================================================
==17891==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7fffd15a3ce4 at pc 0x426ae6 bp 0x7fffd15a3bd0 sp 0x7fffd15a3ba8
READ of size 14 at 0x7fffd15a3ce4 thread T0
    #0 0x426ae5 in strlen ??:0
    #1 0x43719a in my_fputs /home/fruneau/dev/mmsx/lib-common/blah.c:15
    #2 0x436fe7 in main /home/fruneau/dev/mmsx/lib-common/blah.c:22
    #3 0x7f1a99108a54 in __libc_start_main /home/adconrad/eglibc-2.17/csu/libc-start.c:260
    #4 0x436c6c in _start ??:0
Address 0x7fffd15a3ce4 is located in stack of thread T0 at offset 164 in frame
    #0 0x43704f in my_fputs /home/fruneau/dev/mmsx/lib-common/blah.c:14
  This frame has 3 object(s):
    [32, 40) ''
    [96, 104) ''
    [160, 164) 'len'
HINT: this may be a false positive if your program uses some custom stack unwind mechanism or swapcontext
      (longjmp and C++ exceptions *are* supported)
Shadow bytes around the buggy address:
  0x10007a2ac740: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac750: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac760: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac770: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac780: 00 00 00 00 00 00 00 00 f1 f1 f1 f1 00 f4 f4 f4
=>0x10007a2ac790: f2 f2 f2 f2 00 f4 f4 f4 f2 f2 f2 f2[04]f4 f4 f4
  0x10007a2ac7a0: f3 f3 f3 f3 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac7b0: 00 00 00 00 00 00 00 00 f1 f1 f1 f1 04 f4 f4 f4
  0x10007a2ac7c0: f2 f2 f2 f2 04 f4 f4 f4 f2 f2 f2 f2 00 f4 f4 f4
  0x10007a2ac7d0: f3 f3 f3 f3 00 00 00 00 00 00 00 00 00 00 00 00
  0x10007a2ac7e0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07
  Heap left redzone:     fa
  Heap right redzone:    fb
  Freed heap region:     fd
  Stack left redzone:    f1
  Stack mid redzone:     f2
  Stack right redzone:   f3
  Stack partial redzone: f4
  Stack after return:    f5
  Stack use after scope: f8
  Global redzone:        f9
  Global init order:     f6
  Poisoned by user:      f7
  ASan internal:         fe
==17891==ABORTING

Still, as seen in the previous examples, this does not provide anything more than a hint, not a full answer to what is wrong with the program.
Conclusion

Memory is a fundamental resource for any computer program, but it is hard to understand and manage. Tools exist to help the developer and the system administrator but their output requires some brain juice in order to be really meaningful.

This series of article tried to covere a large range of subjects, a lot more could be said (and a lot more as already been said by others). The topic we have selected is what we consider the minimal toolkit for both developers and system administrators, both in term of raw knowledge and for the comprehension of the various limitations. We just hope this has been helpful.

= part 6 :


Memory – Part 6: Optimizing the FIFO and Stack allocators
September 28, 2014, by Aloÿs Augustin	

    1 Introduction
    2 Tools used
    3 The FIFO allocator
        3.1 Page management
        3.2 Page allocation
        3.3 Other optimisations
    4 The Stack allocator
        4.1 Block allocation policy
            4.1.1 Block searching
            4.1.2 Block sizing
        4.2 Fast path improvement
        4.3 realloc()
        4.4 Overall gains
    5 Conclusion

Introduction

The most used custom allocators at Intersec are the FIFO and the Stack allocators, detailed in a previous article. The stack allocator is extremely convenient, thanks to the t_scope macro, and the FIFO is well fitted to some of our use cases, such as inter-process communication. It is thus important for these allocators to be optimized extensively.

We are two interns at Intersec, and our objective for this 6 week internship was to optimize these allocators as far as possible. Optimizing an allocator can have several meanings: it can be in terms of memory overhead, resistance to contention, performance… As the FIFO allocator is designed to work in single threaded environments, and the t_stack is thread local, we will only cover performance and memory overhead.

Tools used

To be able to quickly assess the impact of our changes, we began by writing a quick benchmark that uses the allocator to make a few million allocations and measures the time it takes.

For the FIFO allocator, the scenario is the following: in the first loop, we request memory for the allocator and we immediately release it. In the second loop, we loop several times through an array of pointers, and at each iteration, the pointer is freed (if it is not NULL) and then reallocated. The effect of this is that there is a constant amount of memory allocated at all times, and we keep a FIFO behaviour: the first pointer allocated is also the first freed. The third loop still uses the array of pointers, but instead of looping through it regularly, it selects a random one at each iteration, frees it and re-allocates it. This way we still have a constant amount of memory allocated, but we lose the FIFO behaviour.

For the stack allocator the scenario is simpler: a recursive function allocates some memory, calls itself up to a given recursion depth, allocates some more memory after the recursive call ended and then returns. The t_scope mechanism ensures that all the memory allocated by a function is freed when it returns.

To look for performance bottlenecks, we extensively used the linux perf tool which allows to quickly see how our changes affect crucial parameters such as the number of branch misses or cache misses, and where these events originate from. Since the allocation routines are almost flat functions, we needed an insight down to the instruction level.

We also instrumented both allocators to keep track of several statistics such as the memory allocated, the memory used, the numbers of memory requests, the number of subsequent calls to mmap() or calloc(), and the time the different functions (malloc(), free(), realloc()) take to complete. This instrumentation also allowed us to check the behaviour of our allocators in real products, and not only in our benchmark. This instrumentation incrementally gathers all the necessary usage information, and periodically dumps it into a file.

Using this tool, we have analysed the main memory allocation patterns in Igloo, the Intersec Geo-Locator. The demonstration program for Igloo has been used to get a simplified real-world use-case. For both allocators, an entry in the file dump is issued each 300 simple operations (malloc(), free(), realloc()), and at each long operation (memory request from the system, memory page cleaning…). Feeding only 10,000 events per second for 5 minutes into Igloo already produces an overwhelming quantity of dumps, around 6GB. Exploiting this quantity of dumps has been a bit of a challenge, but has provided some insight into the effective usage of the allocators: for instance, we get around 100,000 allocations per minute.
The FIFO allocator

The FIFO allocator is relying on large pages of memory allocated through mmap(). The pages are split into variably-sized blocks as requested. Each block maintains a reference to the page it belongs to (actually the offset of the block in the page), as well as its size. The FIFO pool keeps a reference to the current page as well as a free page, which is not always set but is used to reduce the number of page deallocation / reallocation operations.
typedef struct mem_page_t {
    uint32_t used_size;    /* size used in the page */
    uint32_t used_blocks;  /* number of blocks not freed yet */
    size_t   size;         /* size of area[] */
    void    *last;         /* last result of an allocation */
    byte __attribute__((aligned(8))) area[];  /* space to create blocks into */
} mem_page_t;

typedef struct mem_block_t {
    uint32_t page_offs;  /* address of this minus address of containing page */
    uint32_t blk_size;   /* size of area[] */
    byte     area[];     /* user data goes here */
} mem_block_t;
1
2
3
4
5
6
7
8
9
10
11
12
13
	
typedef struct mem_page_t {
    uint32_t used_size;    /* size used in the page */
    uint32_t used_blocks;  /* number of blocks not freed yet */
    size_t   size;         /* size of area[] */
    void    *last;         /* last result of an allocation */
    byte __attribute__((aligned(8))) area[];  /* space to create blocks into */
} mem_page_t;
 
typedef struct mem_block_t {
    uint32_t page_offs;  /* address of this minus address of containing page */
    uint32_t blk_size;   /* size of area[] */
    byte     area[];     /* user data goes here */
} mem_block_t;

FIFO allocator

Representation of the FIFO allocator

With this structure, the behaviour of the 3 main functions (alloc(), realloc(), free()) is straightforward:

    For alloc(): if there is enough space in the current page, return a pointer to the beginning of the free space in the current page (fast path), else allocate a new page.
    For realloc(): if the new size is smaller than the original size, return the same pointer. Else if the pointer we are reallocating is the last block of its frame and there is enough space in the frame, return the same pointer too, else allocate a new block, copy the memory from the old block to the new and free the old one.
    For free(): decrease the number of blocks in the containing page. If this number is zero, destroy the page.

The FIFO allocator always returns memory initialized to zero. It also aligns all memory blocks on multiples of at least 8 bytes.

For these three functions, the fast code path (without operations on pages) is extremely fast, and the slow path is not supposed to happen too often (as long as the default page size is big enough to hold a reasonable number of allocations, which is the responsibility of the owner of the pool) but as we will see, there was still room for improvement. Trying to reduce the frequency of the slow paths and increasing the speed of the fast path allowed us to make the FIFO allocator 30% faster than it originally was.
Page management

The most significant improvements we have made to the FIFO allocator were achieved by improving the page management policy. What was initially done was:

    The pool is created without a page (current = NULL)
    When allocating or reallocating, if there is not enough room in the current page, request a new page.
    When freeing, if we are freeing the last block of a page:
        If the page is the current one, set current to NULL
        If there is already a freepage, delete our page, else reset the page and save it as freepage.

Requests for a new page are performed through mem_page_new(), which returns the freepage if it exists, and allocates a new one otherwise. An important thing to note is that the free() function is responsible for the deletion of unused pages: the pool doesn’t keep references to any page unless it is the current page. Instead, each page tracks the number of blocks still alive in it, and when all blocks are freed, this count reaches zero and the page must be freed.
FIFO allocator - old behaviour

Initial code flow of alloc() and free() – Click image to enlarge

This scheme is good, but it has several drawbacks: for instance, let’s consider the case where there is only one pointer allocated at a time. When it is freed, we set current to  NULL, and then we reset the page (assuming that there is no freepage, which is the case after the first iteration), i.e. we memset() the used space of the page to zero. As a consequence, each time we want to allocate, we need to fetch the free page first. This means that in this case, all calls trigger slow path runs.

To circumvent it, we gave the current page a special treatment in free(): if its last block is freed, we do nothing, so that the next allocations will keep filling it. However, we also had to add an extra check in the slow path of alloc(): when the current page is out of space, if it turns out that there is no alive block in it, we have to reset it (and then we can reuse it).

This has the side effect that current is never NULL once the first page has been created. If we allocate the first page at the creation of the pool, we can be sure that current will never be NULL, thus we can remove this check from the fast path of both alloc() and realloc().

Another improvement that was made, which is closer to a trade-off between memory overhead and performance, is the following: if a page becomes available, and we already have a freepage, instead of deleting it straight away, we check the remaining space available in the current page: if the free space in the current page is less than 1/8th of the size of the available page, we immediately replace it with the available page. This doesn’t incur a raw performance gain in the benchmark, but it tackles a bad behaviour that we spotted in a product where a page would be deleted just before a new one was allocated. This change greatly reduces the page allocation frequency in this case.
FIFO allocator - new behaviour

New code flow of alloc() and free() – Note: mem_page_new() has not changed – Click image to enlarge
Page allocation

The allocation of new pages was initially done through calls to mmap(), which always returns memory initialized to zero. However, using calloc() turned out to be significantly faster. Here are the results of the time it took for our benchmark to complete, depending on page size, for mmap() and calloc():
Comparison of calloc() and mmap() for page allocation

Comparison of calloc() and mmap() for page allocation

Both functions are approximately as fast for 1MiB pages, which (according to the malloc() source) is the threshold above which malloc() switches to mmap(). But surprisingly, for bigger pages calloc() is again faster than mmap(), so we switched to calloc() for all page sizes. The default page size being 64KiB, this simple switch made our benchmark run faster by 10%.
Other optimisations

A conventional optimisation technique that we went through is structure packing. Because of how the memory pools are managed, each pool structure has to inline a 40-byte mem_pool_t structure, which leaves 24 bytes on the first cache line for the specific pool data. The current and freepage pointers consume 16 of these 24 bytes.

The FIFO pool has a specific way of being destroyed: if there is still allocated memory in the pool when we try to delete it, it stays alive until all the memory is freed. Because of this, it has to keep a boolean indicating if the destructor has been called (and forbidding allocations if it is the case) and the number of pages allocated. It also keeps the default page size which is configured at the creation of the pool. Moreover, it keeps track of the total memory allocated, and of the currently used memory, which are needed by statistics reporting functions. This makes a lot of information for the 8 remaining bytes, however among these members, the only ones that are used in the fast paths are the alive boolean and the occupied integer. occupied can’t be stored on 4 bytes, because it may very well exceed 4GiB (it often does so in the benchmark), but if we use an 8-byte integer, then there is no room left for alive on the first cache line. The fastest solution here was to use bitfields: 63 bits for occupied and 1 for alive. This gave a ~3% speed improvement in the bench.

The resulting structure is the following:
typedef struct mem_fifo_pool_t {
    mem_pool_t  funcs;
    mem_page_t *freepage;
    mem_page_t *current;
    size_t      occupied : 63;
    bool        alive    : 1;

    /* cache line 1 end */
    size_t      map_size;
    uint32_t    page_size;
    uint32_t    nb_pages;

#ifdef MEM_BENCH
    /* Instrumentation */
    mem_bench_t mem_bench;
    dlist_t     pool_list;
#endif

} mem_fifo_pool_t;
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
	
typedef struct mem_fifo_pool_t {
    mem_pool_t  funcs;
    mem_page_t *freepage;
    mem_page_t *current;
    size_t      occupied : 63;
    bool        alive    : 1;
 
    /* cache line 1 end */
    size_t      map_size;
    uint32_t    page_size;
    uint32_t    nb_pages;
 
#ifdef MEM_BENCH
    /* Instrumentation */
    mem_bench_t mem_bench;
    dlist_t     pool_list;
#endif
 
} mem_fifo_pool_t;

Another optimisation we did is actually quite funny: consider the two code blocks below, taken from alloc():
...
/* Must round size up to keep proper alignment */
size = ROUND_UP((unsigned)size + sizeof(mem_block_t), 8);
page = mfp->current;
if (mem_page_size_left(page) < size) {
...
1
2
3
4
5
6
	
...
/* Must round size up to keep proper alignment */
size = ROUND_UP((unsigned)size + sizeof(mem_block_t), 8);
page = mfp->current;
if (mem_page_size_left(page) < size) {
...

...
page = mfp->current;
/* Must round size up to keep proper alignment */
size = ROUND_UP((unsigned)size + sizeof(mem_block_t), 8);
if (mem_page_size_left(page) < size) {
...
1
2
3
4
5
6
	
...
page = mfp->current;
/* Must round size up to keep proper alignment */
size = ROUND_UP((unsigned)size + sizeof(mem_block_t), 8);
if (mem_page_size_left(page) < size) {
...

Can you tell which one is the fastest? No you can’t, you would need to compile the whole code to do so. The thing is that thanks to the perf tool, we saw that the assembly instruction corresponding to page = mfp->current; was taking a lot of time. We tried moving it around, and we saw that putting it before the size assignment yielded a 2% improvement in the bench. Upon closer inspection of the assembly code generated, we saw that this modification completely changed GCC’s register allocation, and thus reduced register interlock in this portion of the code.
The Stack allocator

The Stack allocator, unlike the FIFO allocator, is frame-based: allocations are grouped in frames, to allow batch deallocation. Frames are stacked in a LIFO ordering. Prior to a group of allocations, one must push a frame into the allocator, and pop it to free the group. The frame object records all the bookkeeping information for allocations. It still shares some properties with the FIFO allocator, being block-based (a block here denotes what the FIFO allocator called a page). This way, it can achieve very fast size-agnostic allocations. The model is simple: the frame holds the current position in the block. Upon a memory request, we just need to bump this pointer forward. Thanks to the frame-based model, deallocation is almost free, we just need to pop the last frame. The allocator will recover its exact state, saved by the matching push. The third meaningful operation is realloc(). General purpose reallocation of an arbitrary memory chunk is in general difficult and slow. However, the block-based model allows a very useful case: reallocating the last allocation is almost free. We just need to update the position pointer.
typedef struct mem_stack_frame_t {
    mem_stack_frame_t *prev; /* previous frame */
    mem_stack_blk_t *blk;    /* current active block */
    uint8_t *pos;            /* allocation position */
    uint8_t *last;           /* address of last allocation */
} mem_stack_frame_t;

uint8_t *sp_alloc(mem_stack_frame_t *frame, size_t size)
{
    uint8_t *res = frame->pos;
    uint8_t *top = frame->pos + size; /* check for sufficient space */

    if (top >= blk_end(frame->blk)) {
        /* get more memory (slow path) */
    }
    frame->pos = top;
    return res;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
	
typedef struct mem_stack_frame_t {
    mem_stack_frame_t *prev; /* previous frame */
    mem_stack_blk_t *blk;    /* current active block */
    uint8_t *pos;            /* allocation position */
    uint8_t *last;           /* address of last allocation */
} mem_stack_frame_t;
 
uint8_t *sp_alloc(mem_stack_frame_t *frame, size_t size)
{
    uint8_t *res = frame->pos;
    uint8_t *top = frame->pos + size; /* check for sufficient space */
 
    if (top >= blk_end(frame->blk)) {
        /* get more memory (slow path) */
    }
    frame->pos = top;
    return res;
}

Stack allocator

Representation of the stack allocator

Since the fast path is already very efficient (16 cycles), the actual improvement resides mostly in controlling the frequency of slow paths, i.e. allocation of new blocks from system.
Block allocation policy

The block allocation policy is constrained by the need for very fast deallocations. This incurs that almost all the block handling is done on demand, at allocation time. The general block management uses a simple list of blocks. At all times, all the blocks before the current frame’s are in use, and all the latter blocks are free. When a block is required, the list is traversed. If no suitable block is found a new one is allocated. Because of the typical size of the blocks (at least 64KiB), the creation of new blocks is made via a call to the libc’s malloc(), which in turn yields a call to mmap(). This incurs a substantial latency, so it is important to reuse the blocks. This reduces memory consumption, memory fragmentation and allocation time.

Compared to the fast path of the allocator, searching a new block is very time-consuming, and creating one is all the more. A straightforward manner to reduce the penalty is to be eager with resizes. For instance, take the following diagram: the current frame (Frame 2) owns an almost full block, so pushing a new frame will require a new block. When pushing Frame 3, the code used to consider that it must not alter the former, so Frame 2 still points to Block A, and Frame 3 to Block B. After several operations, this frame will be popped, and this last block will be put back on free list, back to square one. Then, another frame will be pushed, and require that same free block. This forgetful behaviour is not the most efficient.

A first step towards solving this is to always update the current frame when a block is added. This way, on the example below, Frame 2 remembers it will soon need Block B, and avoids repeated block fetching. This furthermore allows to save a branch in the allocation code. A second step is to add speculative block replacement: whenever a block is added to the top frame, it can conditionally be added to the previous frames too.
Example situation

Example situation before pushing a new frame. The current frame (Frame 2) points to the almost full block A.
Block searching

When a block was needed (slow path), the block search was greedy:

    visit the free blocks list, if the block is big enough return it, else destroy it
    if no suitable block is found, create a new one

Actually, this scheme just considered that the small blocks will always be too small for further allocations. While this keeps memory usage bounded and aims at reducing the fragmentation, it relies on the assumption of fairly regular request sizes. This behaviour is deadly when an oversized allocation slips in. For instance, this pattern of allocation:
static void worst_case(int depth)
{
    for (int i = 0; i < depth; i++) {
        t_scope;
        byte* mem;

        { /* allocate and free a bunch of small objects */
            t_scope;

            for (int k = 0; k < 20000; k++) {
                mem = t_new_raw(byte, 100);
            } 
        }

        /* allocate an oversized block */
        mem = t_new_raw(byte, 80000 + PAGE_SIZE * depth);
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
	
static void worst_case(int depth)
{
    for (int i = 0; i < depth; i++) {
        t_scope;
        byte* mem;
 
        { /* allocate and free a bunch of small objects */
            t_scope;
 
            for (int k = 0; k < 20000; k++) {
                mem = t_new_raw(byte, 100);
            } 
        }
 
        /* allocate an oversized block */
        mem = t_new_raw(byte, 80000 + PAGE_SIZE * depth);
    }
}

Using our instrumentation of the allocator, we created the following graph, plotting the current memory allocated from the t_stack (black) and the memory available in blocks (purple). Horizontal axis is the number of file dumps, vertical axis is the size in bytes.
Original behaviour for worst_case()

Original behaviour of the allocator for worst_case(), initial depth 20, truncated at 2500 allocator operations. Cumulated size of block allocations: 35MiB

Analysing this graph, we observe that the allocator allocates a bunch of small blocks for the first scope, puts them on the free list when popping the frame, wipes everything to create a 80kB+ block, reallocates a similar bunch of small blocks, and repeat this all over. This is clearly suboptimal.

In order to avoid this, we chose to stop the block destruction as soon as we reached the requested size. This keeps the bounded memory usage and still reduces memory fragmentation. On this very example, the gain in time is around 30%.
Corrected behaviour for worst_case()

Corrected behaviour of the allocator for worst_case(), initial depth = 20, truncated at 2500 allocator operations. Cumulated size of block allocations: 7.5MiB
Block sizing

In order to bound the block switch frequency, those are sized proportionally to average of the size of the requests. A newly allocated block must be at least 64 times the mean allocation size as computed below.
typedef struct average_t {
    size_t sum;
    size_t nb;
} average_t;

void average_update(average_t *av, size_t request)
{
    /* truncate too big requests */
    if (request < (128 << 20)) {
        if (av->sum + request < av->sum
        ||  av->nb >= UINT16_MAX)
        {
            av->sum /= 4;
            av->nb /= 4;
        }
        av->sum += request;
        av->nb += 1;
    }
}

size_t average_get(average_t *av)
{
    return av->sum / av->nb;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
	
typedef struct average_t {
    size_t sum;
    size_t nb;
} average_t;
 
void average_update(average_t *av, size_t request)
{
    /* truncate too big requests */
    if (request < (128 << 20)) {
        if (av->sum + request < av->sum
        ||  av->nb >= UINT16_MAX)
        {
            av->sum /= 4;
            av->nb /= 4;
        }
        av->sum += request;
        av->nb += 1;
    }
}
 
size_t average_get(average_t *av)
{
    return av->sum / av->nb;
}

This method for computation is great for use in the allocator. It uses basic integer operations only (addition, comparison and shift), and be updated in a few clock cycles, and most of all is smooth. The resulting average converges roughly at the same speed than an exponential moving average with decay 1/27279, but is 25% smoother (computed from the expected deviation after an new input value).

Still, some parts of this algorithm could be elided by some maths. First, the maximum allocation allowed is 1GiB. This check is primarily made for sanity reasons, to avoid devious allocations caused by unchecked overflow. Since av->nb is smaller than UINT16_MAX, av->sum will always be smaller than 1GiB * UINT16_MAX < UINT64_MAX. Hence, the overflow check is always false.

Removing this check does not improve anything, it just removes a jump instruction that was always predicted. The other test we may want to remove is the truncation to 128MiB. A probability analysis shows that the expected oversize for a single peak p is roughly equal to p / 550, for any average request size. After an allocation of 1GiB, the expected overhead in block size will be 2MB. This is fairly tractable after a 1GiB allocation, so the truncation can be removed.
Average filters

Average filters on a 4M allocation sequence, with mean 16KiB, Gaussian noise of standard deviation 3KiB, 5 bunches of 2000 allocations of 256KiB, and a single peak allocation of 1GiB
Fast path improvement

Besides being already very efficient, the preferred path for allocation contained some overhead in the way alignment was computed.

Memory alignment is a central performance problematic. Most processors access memory with granularity of a word, which means that any read or store will at least fetch this size. From the way computer memory is handled, these accesses work best when addresses are word-aligned. Moreover, some recent instructions (and some old architectures) do require aligned operands (vector operations in SSE2 require 128-bit alignment).

The easiest way to fulfil alignment requirements in an allocator is to keep uniform alignment for all the allocated objects. This takes the form of rounding up the size to next boundary, an operation happily optimized by the compiler, since the alignment is known at compile time. Although being most efficient, the memory overhead of this scheme can be unbearable: for 16-byte alignment, allocating a single integer takes four times the size!

This behaviour has fortunately been changed in Intersec allocators in favour of on-demand alignment. This model requires to round up the returned pointer to demanded boundaries. In the original code, both the returned address and the size were rounded up. This accounts for unnecessary checking:

    for sizes computed with sizeof(), the alignment is guaranteed by the C language (C99 standard, paragraph 6.5.3.4/3)
    the processor only cares about address alignment

The key for efficient computation is to use the fact that alignment is always a power of two. The choice in implementation resides in the storage of the alignment boundary: either in full form (like the output of alignof() operator, a power of two), or in logarithmic form (the position of the bit).
/* Alignment computation */
uintptr_t full_mem_align(uintptr_t mem, size_t align)
{
    assert (!(align & (align - 1))); /* fire if not a power of two */
    return (mem + align - 1) & (-align);
}

uintptr_t log_mem_align(uintptr_t mem, unsigned logalign)
{
    size_t bitmask_le = (1 << logalign) - 1;
    size_t bitmask_ge = (size_t)-1 << logalign;
    return (mem + bitmask_le) & bitmask_ge;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
	
/* Alignment computation */
uintptr_t full_mem_align(uintptr_t mem, size_t align)
{
    assert (!(align & (align - 1))); /* fire if not a power of two */
    return (mem + align - 1) & (-align);
}
 
uintptr_t log_mem_align(uintptr_t mem, unsigned logalign)
{
    size_t bitmask_le = (1 << logalign) - 1;
    size_t bitmask_ge = (size_t)-1 << logalign;
    return (mem + bitmask_le) & bitmask_ge;
}

The full form has two advantages: first, it requires a smaller and simpler assembly, faster to execute, and it does not need to compute the logarithm of the alignment. Eventually, benchmarking shows a 9% improvement in the allocation code.
realloc()

In this kind of block-based allocator, the realloc() operation for last allocated block is very cheap. Indeed, at each allocation, we record the returned address. At realloc() time, it is just necessary to bump the position pointer a little farther. Since the work on the block allocation policy already impacts the realloc() function, the only part where improvements can be made is the realloc() code itself.

We followed a logic of branch-elimination on the function. The most used path is in red on the graph below. The typical use of this function is the growing of dynamic arrays: it is expected to be most efficient. This refactoring allows for better branch optimization, and results in a 10% gain in reallocation speed.
Old vs new realloc() - Click image to enlarge

Old vs New realloc() code path – Click image to enlarge
Overall gains

In order to evaluate the consequences of our work on the stack allocator, we considered benchmarking both the original and our final versions of the code. Measuring raw allocation speed for different allocation / deallocation ratios show a consistent 17% gain. Still, this benchmark only considers a very regular allocation pattern, and does not account for exceptional use cases like the worst_case() function above. Thanks to this observation, this former gain is more of a lower bound on the improvements.
Conclusion

These allocators were already quite efficient, but we still managed to find ways to improve them, the most significant of which are detailed in this article. By grabbing a few percent here and there, we eventually improved the overall performance of the two allocators by around 20-30%, depending on the use cases. It was a challenging task, because of the complexity of the matter as well as the fact that we had to dive into a particularly developed code base.

We learnt a lot of things during these six weeks, and we are particularly happy to have done so at Intersec, where skill meets cheerfulness.

