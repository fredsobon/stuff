
= Expressions régulières - regexp =

En python, les expressions régulières sont disponibles de manière plus traditionnelle, via le module re de la librairie standard.

-> findall :

On se donne deux exemples de chaînes
￼
sentences = ['Lacus a donec, vitae gravida proin sociis.', 
             'Neque ipsum! rhoncus cras quam.']
On peut chercher tous les mots se terminant par a ou m dans une chaîne avec findall
￼
for sentence in sentences:
    print(f"---- dans >{sentence}<")
    print(re.findall(r"\w*[am]\W", sentence))
---- dans >Lacus a donec, vitae gravida proin sociis.<
['a ', 'gravida ']
---- dans >Neque ipsum! rhoncus cras quam.<
['ipsum!', 'quam.']

Ce code permet de chercher toutes (findall) les occurrences de l'expression régulière, qui ici est définie par le raw-string r"\w*[am]\W"

details :
\w* : on veut trouver une sous-chaîne qui commence par un nombre quelconque, y compris nul (*) de caractères alphanumériques (\w). Ceci est défini en fonction de votre LOCALE, on y reviendra.
[am] : immédiatement après, il nous faut trouver un caratère a ou m.
\W : et enfin, il nous faut un caractère qui ne soit pas alphanumérique. Ceci est important puisqu'on cherche les mots qui se terminent par un a ou un m, si on ne le mettait pas on obtiendrait ceci
￼
# le \W final est important
# voici ce qu'on obtient si on l'omet
for sentence in sentences:
    print(f"---- dans >{sentence}<")
    print(re.findall(r"\w*[am]", sentence))
---- dans >Lacus a donec, vitae gravida proin sociis.<
['La', 'a', 'vita', 'gravida']
---- dans >Neque ipsum! rhoncus cras quam.<
['ipsum', 'cra', 'quam']


->split
Une autre forme simple d'utilisation des regexps est re.split, qui fournit une fonctionnalité voisine de str.split, mais ou les séparateurs sont exprimés comme une expression régulière
￼
for sentence in sentences:
    print(f"---- dans >{sentence}<")
    print(re.split(r"\W+", sentence))
    print()
---- dans >Lacus a donec, vitae gravida proin sociis.<
['Lacus', 'a', 'donec', 'vitae', 'gravida', 'proin', 'sociis', '']

---- dans >Neque ipsum! rhoncus cras quam.<
['Neque', 'ipsum', 'rhoncus', 'cras', 'quam', '']

Ici l'expression régulière, qui bien sûr décrit le séparateur, est simplement \W+ c'est-à-dire toute suite d'au moins un caractère non alphanumérique.
Nous avons donc là un moyen simple, et plus puissant que str.split, de couper un texte en mots.

->sub
Une troisième méthode utilitaire est re.sub qui permet de remplacer les occurrences d'une regexp, comme par exemple
￼
for sentence in sentences:
    print(f"---- dans >{sentence}<")
    print(re.sub(r"(\w+)", r"X\1Y", sentence))
    print()
---- dans >Lacus a donec, vitae gravida proin sociis.<
XLacusY XaY XdonecY, XvitaeY XgravidaY XproinY XsociisY.

---- dans >Neque ipsum! rhoncus cras quam.<
XNequeY XipsumY! XrhoncusY XcrasY XquamY.

Ici, l'expression régulière (le premier argument) contient un groupe : on a utilisé des parenthèses autour du \w+. Le second argument est la chaîne de remplacement, dans laquelle on a fait référence au groupe en écrivant \1, qui veut dire tout simplement "le premier groupe".
Donc au final, l'effet de cet appel est d'entourer toutes les suites de caractères alphanumériques par X et Y.


-> Pourquoi un raw-string ?
En guise de digression, il n'y a aucune obligation à utiliser un raw-string, d'ailleurs on rappelle qu'il n'y a pas de différence de nature entre un raw-string et une chaîne usuelle
￼
raw = r'abc'
regular = 'abc'
# comme on a pris une 'petite' chaîne ce sont les mêmes objets
print(f"both compared with is → {raw is regular}")
# et donc a fortiori
print(f"both compared with == → {raw == regular}")
both compared with is → True
both compared with == → True

Il se trouve que le backslash \ à l'intérieur des expressions régulières est d'un usage assez courant - on l'a vu déjà plusieurs fois. C'est pourquoi on utilise fréquemment un raw-string pour décrire une expression régulière, et en général à chaque fois qu'elle comporte un backslash. On rappelle que le raw-string désactive l'interprétation des \ à l'intérieur de la chaîne, par exemple, \t est interprété comme un caractère de tabulation. Sans raw-string, il faut doubler tous les \ pour qu'il n'y ait pas d'interprétation.


Un deuxième exemple
Nous allons maintenant voir comment on peut d'abord vérifier si une chaîne est conforme au critère défini par l'expression régulière, mais aussi extraire les morceaux de la chaîne qui correspondent aux différentes parties de l'expression.
Pour cela, supposons qu'on s'intéresse aux chaînes qui comportent 5 parties, une suite de chiffres, une suite de lettres, des chiffres à nouveau, des lettres et enfin de nouveau des chiffres.
Pour cela on considère ces trois chaines en entrée
￼
samples = ['890hj000nnm890',    # cette entrée convient
          '123abc456def789',   # celle-ci aussi
          '8090abababab879',   # celle-ci non
          ]

-> match :

pour commencer, voyons que l'on peut facilement vérifier si une chaîne vérifie ou non le critère.
￼
regexp1 = "[0-9]+[A-Za-z]+[0-9]+[A-Za-z]+[0-9]+"
Si on applique cette expression régulière à toutes nos entrées
￼
for sample in samples:
    match = re.match(regexp1, sample)
    print(f"{sample:16s} → {match}")  # ici pour gérer proprement l'alignement on fixe une sortie à 16 caracteres alignés a droite 

890hj000nnm890   → <_sre.SRE_Match object; span=(0, 14), match='890hj000nnm890'>
123abc456def789  → <_sre.SRE_Match object; span=(0, 15), match='123abc456def789'>
8090abababab879  → None

Pour rendre ce résultat un peu plus lisible nous nous définissons une petite fonction de confort.

# pour simplement visualiser si on a un match ou pas
def nice(match):
    # le retour de re.match est soit None, soit un objet match
    return "no" if match is None else "Match!"

Avec quoi on peut refaire l'essai sur toutes nos entrées.
￼
# la même chose mais un peu moins encombrant

# on affiche le pattern de notre regexp pour un mémo visuel sur la sortie :
print(f"REGEXP={regexp1}\n")
for sample in samples:
    match = re.match(regexp1, sample)
    print(f"{sample:>16s} → {nice(match)}")  # on garde avec le formatage ":>16s" l'alignement désiré.

REGEXP=[0-9]+[A-Za-z]+[0-9]+[A-Za-z]+[0-9]+

  890hj000nnm890 → Match!
 123abc456def789 → Match!
 8090abababab879 → no

Ici plutôt que d'utiliser les raccourcis comme \w j'ai préféré écrire explicitement les ensembles de caractères en jeu. De cette façon, on rend son code indépendant du LOCALE si c'est ce qu'on veut faire. Il y a deux morceaux qui interviennent tour à tour :
[0-9]+ signifie une suite de au moins un caractère dans l'intervalle [0-9],
[A-Za-z]+ pour une suite d'au moins un caractère dans l'intervalle [A-Z] ou dans l'intervalle [a-z].
Et comme tout à l'heure on a simplement juxtaposé les morceaux dans le bon ordre pour construire l'expression régulière complète.



> Nommer un morceau (un groupe)
￼
# on se concentre sur une entrée correcte
haystack = samples[1]
haystack
'123abc456def789'

Maintenant, on va même pouvoir donner un nom à un morceau de la regexp, ici on désigne par needle le groupe de chiffres du milieu.
￼
# la même regexp, mais on donne un nom au groupe de chiffres central
regexp2 = "[0-9]+[A-Za-z]+(?P<needle>[0-9]+)[A-Za-z]+[0-9]+"
# la même regexp, mais on donne un nom au groupe de chiffres central
regexp2 = "[0-9]+[A-Za-z]+(?P<needle>[0-9]+)[A-Za-z]+[0-9]+"
Et une fois que c'est fait, on peut demander à l'outil de nous retrouver la partie correspondante dans la chaine initiale:
￼
print(re.match(regexp2, haystack).group('needle'))
456

Dans cette expression on a utilisé un groupe nommé (?P<needle>[0-9]+), dans lequel :
les parenthèses définissent un groupe,
?P<needle> spécifie que ce groupe pourra être référencé sous le nom needle (cette syntaxe très absconse est héritée semble-t-il de perl).

Un troisième exemple
Enfin, et c'est un trait qui n'est pas présent dans tous les langages, on peut restreindre un morceau de chaîne à être identique à un groupe déjà vu plus tôt dans la chaîne. Dans l'exemple ci-dessus, on pourrait ajouter comme contrainte que le premier et le dernier groupes de chiffres soient identiques, comme ceci
￼
regexp3 = "(?P<id>[0-9]+)[A-Za-z]+(?P<needle>[0-9]+)[A-Za-z]+(?P=id)"
Si bien que maintenant, avec les mêmes entrées que tout à l'heure
￼
print(f"REGEXP={regexp3}\n")
for sample in samples:
    match = re.match(regexp3, sample)
    print(f"{sample:>16s} → {nice(match)}")    
REGEXP=(?P<id>[0-9]+)[A-Za-z]+(?P<needle>[0-9]+)[A-Za-z]+(?P=id)

  890hj000nnm890 → Match!
 123abc456def789 → no
 8090abababab879 → no
Comme précédemment on a défini le groupe nommé id comme étant la première suite de chiffres. La nouveauté ici est la contrainte qu'on a imposée sur le dernier groupe avec (?P=id). Comme vous le voyez, on n'obtient un match qu'avec les entrées dans lesquelles le dernier groupe de chiffres est identique au premier.

-> Notes techniques / perfs regexp :

on utilise souvent les fonctions de "commodités" (match, findall ...) des regexp qui toutes passent par de manière invisible pour le user par une methode de compilation: on a donc un coup de traitement élevé.
Il faut essayer de ne faire compiler qu'un minimum de fois pour les regex afin de ne pas avoir un surcout en calcul.   
les methodes de regexp font dont en fait : 
re.match(regexp, sample)  <==>  re.compile(regexp).match(sample)

Donc :

# au lieu de faire comme ci-dessus:

# imaginez 10**6 chaînes dans samples
for sample in samples:
    match = re.match(regexp3, sample)
    print(f"{sample:>16s} → {nice(match)}")    

 890hj000nnm890 → Match!
 123abc456def789 → no
 8090abababab879 → no


on fera plutôt : 


# dans du vrai code on fera plutôt:

# on compile la chaîne en automate une seule fois
re_obj3 = re.compile(regexp3)

# ensuite on part directement de l'automate
for sample in samples:
    match = re_obj3.match(sample)
    print(f"{sample:>16s} → {nice(match)}")
890hj000nnm890 → Match!
 123abc456def789 → no
 8090abababab879 → no

Cette deuxième version ne compile qu'une fois la chaîne en automate, et donc est plus efficace.


-> Les méthodes sur la classe RegexObject

Les objets de la classe RegexObject représentent donc l'automate à état fini qui est le résultat de la compilation de l'expression régulière. Pour résumer ce qu'on a déjà vu, les méthodes les plus utiles sur un objet RegexObject sont :

-match et search, qui cherchent un match soit uniquement au début (match) ou n'importe où dans la chaîne (search),
-findall et split pour chercher toutes les occurences (findall) ou leur négatif (split),
-sub (qui aurait pu sans doute s'appeler replace, mais c'est comme ça) pour remplacer les occurrences de pattern.

Exploiter le résultat
Les méthodes disponibles sur la classe re.MatchObject: on en a déjà rencontré quelques-unes, en voici à nouveau un aperçu rapide.
￼
# exemple
sample = "    Isaac Newton, physicist"
match = re.search(r"(\w+) (?P<name>\w+)", sample)

-re et string pour retrouver les données d'entrée du match.
￼
match.string
'    Isaac Newton, physicist'
￼
match.re
re.compile(r'(\w+) (?P<name>\w+)', re.UNICODE)


- group, groups, groupdict pour retrouver les morceaux de la chaîne d'entrée qui correspondent aux groupes de la regexp. On peut y accéder par rang, ou par nom (comme on l'a vu plus haut avec needle).
￼
match.groups()
￼
match.group(1)
'Isaac'
￼
match.group('name')
'Newton'
￼
match.group(2)
'Newton'
￼
match.groupdict()
{'name': 'Newton'}

Comme on le voit pour l'accès par rang les indices commencent à 1 pour des raisons historiques (on peut déjà référencer \1 en sed depuis la fin des années 70).
On peut aussi accéder au groupe 0 comme étant la partie de la chaîne de départ qui a effectivement été filtrée par l'expression régulière, et qui peut tout à fait être au beau milieu de la chaîne de départ, comme dans notre exemple

match.group(0)
'Isaac Newton'

- expand permet de faire une espèce de str.format avec les valeurs des groupes.
￼
match.expand(r"last_name \g<name> first_name \1")
'last_name Newton first_name Isaac'

- span pour connaître les index dans la chaîne d'entrée pour un groupe donné.
￼
begin, end = match.span('name')
sample[begin:end]
'Newton'

-> Les différents modes (flags)
Enfin il faut noter qu'on peut passer à re.compile un certain nombre de flags qui modifient globalement l'interprétation de la chaîne, et qui peuvent rendre service.
Vous trouverez une liste exhaustive de ces flags sur la doc en ligne python ex : https://docs.python.org/3/library/re.html#module-contents
Ils ont en général un nom long et parlant, et un alias court sur un seul caractère. Les plus utiles sontsans doute :

- IGNORECASE (alias I) pour, eh bien, ne pas faire la différence entre minuscules et majuscules,
- UNICODE (alias U) pour rendre les séquences \w et autres basées sur les propriétés des caractères dansla norme Unicode,
- LOCALE (alias L) cette fois \w dépend du locale courant,
- MULTILINE (alias M), et
- DOTALL (alias S) 

Comme c'est souvent le cas, on doit passer à re.compile un ou logique (caractère |) des différents flags que l'on veut utiliser, c'est-à-dire qu'on fera par exemple
￼
regexp = "a*b+"
re_obj = re.compile(regexp, flags=re.IGNORECASE | re.DEBUG)
MAX_REPEAT 0 MAXREPEAT
  LITERAL 97
MAX_REPEAT 1 MAXREPEAT
  LITERAL 98
￼
# on ignore la casse des caractères 
print(regexp, "->", nice(re_obj.match("AabB")))
a*b+ -> Match!



-> Construction de regexp 
https://docs.python.org/3/library/re.html

- La brique de base : le caractère
Au commencement il faut spécifier des caractères.
un seul caractère:
vous le citez tel quel, en le précédent d'un backslash \ s'il a par ailleurs un sens spécial dans le micro-langage de regexps (comme +, *, [, etc.);

- l'attrape-tout (wildcard):
un point . signifie "n'importe quel caractère";

- un ensemble de caractères avec la notation [...] qui permet de décrire par exemple:
[a1=] un ensemble in extenso, ici un caractère parmi a, 1, ou =,
[a-z] un intervalle de caractères, ici de a à z,
[15e-g] un mélange des deux, ici un ensemble qui contiendrait 1, 5, e, f et g,
[^15e-g] une négation, qui a ^ comme premier caractère dans les [], ici tout sauf l'ensemble précédent;

- un ensemble prédéfini de caractères, qui peuvent alors dépendre de l'environnement (UNICODE et LOCALE) avec entre autres les notations:
\w les caractères alphanumériques, et \W (les autres),
\s les caractères "blancs" - espace, tabulation, saut de ligne, etc., et \S (les autres),
\d pour les chiffres, et \D (les autres).

exemple : 
sample = "abcd"
for regexp in ['abcd', 'ab[cd][cd]', 'ab[a-z]d', r'abc.', r'abc\.']:
    match = re.match(regexp, sample)
    print(f"{sample} / {regexp:<10s} → {nice(match)}")
abcd / abcd       → Match!
abcd / ab[cd][cd] → Match!
abcd / ab[a-z]d   → Match!
abcd / abc.       → Match!
abcd / abc\.      → no

Pour ce dernier exemple, comme on a backslashé le . il faut que la chaîne en entrée contienne vraiment un .
￼
print(nice(re.match (r"abc\.", "abc.")))
Match!

-> En série ou en parallèle
Si je fais une analogie avec les montages électriques, jusqu'ici on a vu le montage en série, on met des expressions régulières bout à bout qui filtrent (match) la chaine en entrée séquentiellement du début à la fin. On a un peu de marge pour spécifier des alternatives, lorsqu'on fait par exemple
"ab[cd]ef"
mais c'est limité à un seul caractère. Si on veut reconnaitre deux mots qui n'ont pas grand-chose à voir comme abc ou def, il faut en quelque sorte mettre deux regexps en parallèle, et c'est ce que permet l'opérateur |
￼
regexp = "abc|def"
for sample in ['abc', 'def', 'aef']:
    match = re.match(regexp, sample)
    print(f"{sample} / {regexp} → {nice(match)}")
abc / abc|def → Match!
def / abc|def → Match!
aef / abc|def → no

-> Fin(s) de chaîne
Selon que vous utilisez match ou search, vous précisez si vous vous intéressez uniquement à un match en début (match) ou n'importe où (search) dans la chaîne.
Mais indépendamment de cela, il peut être intéressant de "coller" l'expression en début ou en fin de lig
ne, et pour ça il existe des caractères spéciaux:

^ lorsqu'il est utilisé comme un caractère (c'est à dire pas en début de []) signifie un début de chaîne
\A a le même sens (sauf en mode MULTILINE), et je le recommande de préférence à ^ qui est déjà pas mal surchargé;

$ matche une fin de ligne;
\Z est voisin mais pas tout à fait identique.

Reportez-vous à la documentation pour le détails des différences. Attention aussi à entrer le ^ correctement, il vous faut le caractère ASCII et non un voisin dans la ménagerie Unicode.
￼
sample = 'abcd'
for regexp in [ r'bc', r'\Aabc', r'^abc', 
                r'\Abc', r'^bc', r'bcd\Z', 
                r'bcd$', r'bc\Z', r'bc$' ]:
    match = re.match(regexp, sample)
    search = re.search(regexp, sample)
    print(f"{sample} / {regexp:5s} match → {nice(match):6s} search → {nice(search)}")
abcd / bc    match → no     search → Match!
abcd / \Aabc match → Match! search → Match!
abcd / ^abc  match → Match! search → Match!
abcd / \Abc  match → no     search → no
abcd / ^bc   match → no     search → no
abcd / bcd\Z match → no     search → Match!
abcd / bcd$  match → no     search → Match!
abcd / bc\Z  match → no     search → no
abcd / bc$   match → no     search → no
On a en effet bien le pattern bc dans la chaine en entrée, mais il n'est ni au début ni à la fin.

-> Parenthéser - (grouper)
Pour pouvoir faire des montages élaborés, il faut pouvoir parenthéser.
￼
# une parenthése dans une RE 
# pour mettre en ligne:
# un début 'a', 
# un milieu 'bc' ou 'de' 
# et une fin 'f'
regexp = "a(bc|de)f"
￼
for sample in ['abcf', 'adef',  'abef', 'abf']:
    match = re.match(regexp, sample)
    print(f"{sample:>4s} → {nice(match)}")
abcf → Match!
adef → Match!
abef → no
 abf → no

Les parenthèses jouent un rôle additionel de groupe, ce qui signifie qu'on peut retrouver le texte correspondant à l'expression régulière comprise dans les (). Par exemple, pour le premier match
￼
sample = 'abcf'
match = re.match(regexp, sample)
print(f"{sample}, {regexp} → {match.groups()}")
abcf, a(bc|de)f → ('bc',)
dans cet exemple, on n'a utilisé qu'un seul groupe (), et le morceau de chaîne qui correspond à ce groupe se trouve donc être le seul groupe retourné par MatchObject.group.

-> Compter les répétitions
Vous disposez des opérateurs suivants :
- * l'étoile qui signifie n'importe quel nombre, même nul, d'occurrences - par exemple, (ab)* pour indiquer '' ou 'ab' ou 'abab' ou etc.,
- + le plus qui signifie au moins une occurrence - e.g. (ab)+ pour ab ou abab ou ababab ou etc,
- ? qui indique une option, c'est-à-dire 0 ou 1 occurence - autrement dit (ab)? matche '' ou ab,
- {n} pour exactement n occurrences de (ab) - e.g. (ab){3} qui serait exactement équivalent à ababab,
- {m,n} entre m et n fois inclusivement.
￼
samples = [n*'ab' for n in [0, 1, 3, 4]] + ['baba']

# on va avoir sur la ligne precedente une sortie de 5 lignes : rien (0*'ab'), ab (1*'ab'), ababab (3*'ab'), abababab (4*'ab') , baba (l'ajout de 'baba' en fin de comprehension de liste : 
#>>> samples = [n*'ab' for n in [0, 1, 3, 4]] + ['baba']
#>>> for s in samples:
#...     print(s)
#... 
#
#ab
#ababab
#abababab
#baba

# 
for regexp in ['(ab)*', '(ab)+', '(ab){3}', '(ab){3,4}']:
    # on ajoute \A \Z pour matcher toute la chaine   : donc debut et fin 
    line_regexp = r"\A{}\Z".format(regexp)
    for sample in samples:
        match = re.match(line_regexp, sample)
        print(f"{sample:>8s} / {line_regexp:14s} → {nice(match)}")
         / \A(ab)*\Z      → Match!
      ab / \A(ab)*\Z      → Match!
  ababab / \A(ab)*\Z      → Match!
abababab / \A(ab)*\Z      → Match!
    baba / \A(ab)*\Z      → no
         / \A(ab)+\Z      → no
      ab / \A(ab)+\Z      → Match!
  ababab / \A(ab)+\Z      → Match!
abababab / \A(ab)+\Z      → Match!
    baba / \A(ab)+\Z      → no
         / \A(ab){3}\Z    → no
      ab / \A(ab){3}\Z    → no
  ababab / \A(ab){3}\Z    → Match!
abababab / \A(ab){3}\Z    → no
    baba / \A(ab){3}\Z    → no
         / \A(ab){3,4}\Z  → no
      ab / \A(ab){3,4}\Z  → no
  ababab / \A(ab){3,4}\Z  → Match!
abababab / \A(ab){3,4}\Z  → Match!
    baba / \A(ab){3,4}\Z  → no


-> Groupes et contraintes
Nous avons déjà vu un exemple de groupe nommé (voir needle plus haut), les opérateurs que l'on peut citer dans cette catégorie sont :

(...) les parenthèses définissent un groupe anonyme,

(?P<name>...) définit un groupe nommé,

(?:...) permet de mettre des parenthèses mais sans créer un groupe, pour optimiser l'exécution puisqu'on n'a pas besoin de conserver les liens vers la chaîne d'entrée,

(?P=name) qui ne matche que si l'on retrouve à cet endroit de l'entrée la même sous-chaîne que celle trouvée pour le groupe name en amont,

(?=...), (?!...)et (?<=...) permettent des contraintes encore plus élaborées, nous vous laissons le soin d'expérimenter avec elles si vous êtes intéressés; sachez toutefois que l'utilisation de telles constructions peut en théorie rendre l'interprétation de votre expression régulière beaucoup moins efficace.

- Greedy vs non-greedy
Lorsqu'on stipule une répétition un nombre indéfini de fois, il se peut qu'il existe plusieurs façons de filtrer l'entrée avec l'expression régulière. Que ce soit avec *, ou +, ou ?, l'algorithme va toujours essayer de trouver la séquence la plus longue, c'est pourquoi on qualifie l'approche de greedy - quelque chose comme glouton en français.
￼
# un fragment d'HTML 
line='<h1>Title</h1>'
# si on cherche un texte quelconque entre crochets
# c'est-à-dire l'expression régulière "<.*>"
re_greedy = '<.*>'
# on obtient ceci
# on rappelle que group(0) montre la partie du fragment
# HTML qui matche l'expression régulière
match = re.match(re_greedy, line)
match.group(0)
'<h1>Title</h1>'

Ça n'est pas forcément ce qu'on voulait faire, aussi on peut spécifier l'approche inverse, c'est-à-dire de trouver la plus-petite chaîne qui matche, dans une approche dite non-greedy, avec les opérateurs suivants :
*? : * mais non-greedy,
+? : + mais non-greedy,
?? : ? mais non-greedy,
￼
# ici on va remplacer * par *? pour rendre l'opérateur * non-greedy
re_non_greedy = re_greedy = '<.*?>'
# mais on continue à cherche un texte entre <> naturellement
# si bien que cette fois, on obtient
match = re.match(re_non_greedy, line)
match.group(0)
'<h1>'

-> S'agissant du traitement des fins de ligne
Il peut être utile, pour conclure cette présentation, de préciser un peu le comportement de la librairie vis-à-vis des fins de ligne.
Historiquement, les expressions régulières telles qu'on les trouve dans les librairies C, donc dans sed, grep et autre utilitaires Unix, sont associées au modèle mental où on filtre les entrées ligne par ligne.
Le module re en garde des traces, puisque :
# un exemple de traitement des 'newline' 
sample = """une entrée
sur
plusieurs
lignes
"""
match = re.compile("(.*)").match(sample)
match.groups()
('une entrée',)
Vous voyez donc que l'attrape-tout '.' en fait n'attrape pas le caractère de fin de ligne \n, puisque si c'était le cas et compte tenu du coté greedy de l'algorithme on devrait voir ici tout le contenu de sample. Il existe un flag re.DOTALL qui permet de faire de . un vrai attrape-tout qui capture aussi les newline
￼
match = re.compile("(.*)", flags=re.DOTALL).match(sample)
match.groups()
('une entrée\nsur\nplusieurs\nlignes\n',)
Cela dit, le caractère newline est par ailleurs considéré comme un caractère comme un autre, on peut le mentionner dans une regexp comme les autres. Voici quelques exemples pour illustrer tout ceci
￼
# sans mettre le flag unicode \w ne matche que l'ASCII
match = re.compile("([\w ]*)").match(sample)
match.groups()
('une entrée',)
￼
# sans mettre le flag unicode \w ne matche que l'ASCII
match = re.compile("([\w ]*)", flags=re.U).match(sample)
match.groups()
('une entrée',)
￼
# si on ajoute \n à la liste des caractères attendus 
# on obtient bien tout le contenu initial
# attention ici il ne FAUT PAS utiliser un raw string,
# car on veut vraiment écrire un newline dans la regexp
match = re.compile("([\w \n]*)", flags=re.UNICODE).match(sample)
match.groups()
('une entrée\nsur\nplusieurs\nlignes\n',)

Conclusion
La mise au point d'expressions régulières est certes un peu exigeante, et demande pas mal de pratique, mais permet d'écrire en quelques lignes des fonctionnalités très puissantes, c'est un investissement très rentable :)

testeur de regexp ex : https://pythex.org
on distingue en général l'analyse lexicale, qui découpe le texte en morceaux (qu'on appelle des tokens),
et l'analyse syntaxique qui décrit pour simplifier à l'extrême l'ordre dans lequel on peut trouver les tokens.
Avec les expression régulières, on adresse le niveau de l'analyse lexicale. 
Pour l'analyse syntaxique on peut se tourner vers ex : pyparsing, PLY (Python Lex-Yacc)


exemples :

pour trouver toutes les variables python sous forme de regexp : les chaines qui commencent par une lettre ou un _, suivi de lettres, chiffres ou _. . On peut ecrire : 
regexp_pythonid = r"\A([a-zA-Z]+|_+)+([a-zA-Z]+|[0-9]+|_+)*"

pour identifier tous les num de tel francais sans tenir compte du 0 et +33 avec un groupe :
regexp_phone = r"(0|\+33)(?P<number>([0-9]{9})+\Z)" 

On veut reconnaître dans un fichier toutes les lignes qui contiennent un nom et un prénom.
Plus précisément, on cherche les chaînes qui
commencent par une suite - possiblement vide - de caractères alphanumériques (vous pouvez utiliser \w) ou tiret haut (-) qui constitue le prénom,
contiennent ensuite comme séparateur le caractère 'deux-points' :
contiennent ensuite une suite - cette fois jamais vide - de caractères alphanumériques, qui consitue le nom,
et enfin contiennent un deuxième caractère : mais optionnellement seulement.
On vous demande de construire une expression régulière qui définit les deux groupes nom et prenom, et qui rejette les lignes qui ne satisfont pas ces critères.
￼
# il faudra la faire terminer par \Z
# regardez ce qui se passe si vous ne le faites pas
regexp_agenda = r"(?P<prenom>(\w+(-?\w+)*)*):(?P<nom>\w+(-?\w+)*):?\Z"

Exercice - niveau avancé

Vu comment sont conçus les exercices, vous ne pouvez pas passer à re.compile un flag comme re.IGNORECASE ou autre; sachez cependant que vous pouvez embarquer ces flags dans la regexp elle-même; par exemple pour rendre la regexp insensible à la casse de caractères, au lieu d'appeler re.compile avec le flag re.I, vous pouvez utiliser (?i) comme ceci:
￼
import re
￼
# on peut embarquer les flags comme IGNORECASE 
# directement dans la regexp
# c'est équivalent de faire ceci
re_obj = re.compile("abc", flags=re.IGNORECASE)
re_obj.match("ABC").group(0)
'ABC'
￼
# ou cela 
re.match("(?i)abc","ABC").group(0)
'ABC'
￼
# les flags comme (?i) doivent apparaître
# en premier dans la regexp
re.match("abc(?i)","ABC").group(0)
Pour plus de précisions sur ce trait, que nous avons laissé de coté dans le complément pour ne pas trop l'alourdir, voyez la documentation sur les expressions régulières et cherchez la première occurrence de iLmsux.


-> Décortiquer une URL
On vous demande d'écrire une expression régulière qui permette d'analyser des URLs.

Voici les conventions que nous avons adoptées pour l'exercice:
la chaîne contient les parties suivantes
<protocol>://<location>/<path>
l'url commence par le nom d'un protocole qui doit être parmi http, https, ftp, ssh
le nom du protocole peut contenir de manière indifférente des minuscules ou des majuscules,
ensuite doit venir la séquence ://
ensuite on va trouver une chaîne <location> qui contient:
potentiellement un nom d'utilisateur, et s'il est présent, potentiellement un mot de passe,
obligatoirement un nom de hostname,
potentiellement un numéro de port;
lorsque les 4 parties sont présentes dans <location>, cela se présente comme ceci:
<location> = <user>:<password>@<hostname>:<port>
si l'on note entre crochets les parties optionnelles, cela donne:
<location> = [<user>[:<password>]@]<hostname>[:<port>]
le champ <user> ne peut contenir que des caractères alphanumériques; si le @ est présent le champ <user> ne peut pas être vide
le champ <password> peut contenir tout sauf un : et de même, si le : est présent le champ <password> ne peut pas être vide
le champ <hostname> peut contenir un suite non-vide de caractères alphanumériques, underscores, ou .
le champ <port> ne contient que des chiffres, et il est non vide si le : est spécifié
le champ <path> peut être vide.
Enfin, vous devez définir les groupes proto, user, password, hostname, port et path qui sont utilisés pour vérifier votre résultat. Dans la case Résultat attendu, vous trouverez soit None si la regexp ne filtre pas l'intégralité de l'entrée, ou bien une liste ordonnée de tuples qui donnent la valeur de ces groupes; vous n'avez rien à faire pour construire ces tuples, c'est l'exercice qui s'en occupe.
￼
# pour charger l'exercice
from corrections.regexp_url import exo_url
￼
# exemples du résultat attendu
exo_url.example()
Arguments	Resultat Attendu
  'http://www.google.com/a/b'
[ ('proto', 'http'),
  ('user', None),
  ('password', None),
  ( 'hostname',
    'www.google.com'),
  ('port', None),
  ('path', 'a/b')]
  'HttPS://www.google.com:8080/a/b'
[ ('proto', 'HttPS'),
  ('user', None),
  ('password', None),
  ( 'hostname',
    'www.google.com'),
  ('port', '8080'),
  ('path', 'a/b')]
  'http://user@www.google.com/a/b'
[ ('proto', 'http'),
  ('user', 'user'),
  ('password', None),
  ( 'hostname',
    'www.google.com'),
  ('port', None),
  ('path', 'a/b')]
  'FTP://username:hispass@www.google.com/'
[ ('proto', 'FTP'),
  ('user', 'username'),
  ('password', 'hispass'),
  ( 'hostname',
    'www.google.com'),
  ('port', None),
  ('path', '')]




