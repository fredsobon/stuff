=== notes trow.io : ===

trow est une registry kube légere en rust qui va permettre de deployer des images en cli.
trow utilise a l'heure actuelle kustomized à la place de helm

= setup :

trow utilise le tls pour permettre de securiser les connections avec la registry.
un certificat ssl sera don nécéssaire pour attaquer le point d'entrée de notre appli : ce certificat sera lié à notre ingress.
trow va utiliser du stockage statique

- pre-requi

-> on va devoir installer un ingress-controller pour gérer l'acces à notre appli 

helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
on le deploi dans un namespace dédié :
kctl create ns ingress-controller
helm install ingress-controller -n ingress-controller ingress-nginx/ingress-nginx

->on va pour gérer la partie tls installer cert-manager et pour notre exemple definir une ca privée

kubectl create ns cert-manager


helm repo add jetstack https://charts.jetstack.io\n
helm install cert-manager jetstack/cert-manager --namespace cert-manager --version v0.15.0 --set installCRDs=true

on cree notre ca et on déploy notre secret 

openssl genrsa -out rootCA.key 2048
openssl req -new -x509 -key rootCA.key -out rootCA.crt

kubectl create secret tls ca-priv --namespace cert-manager --key rootCA.key --cert rootCA.crt

on crée une ressource de type clusterissuer :

apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: ca-issuer
spec:
  ca:
    secretName: ca-priv

 kctl create -f ca-issuer.yaml

on test :
kubectl get clusterissuers.cert-manager.io
NAME        READY   AGE
ca-issuer   True    4h59m

notre ca est prete on peut créer une ressource qui va générer un csr qui sera signée et un  certificate sera  créée le tout automatiquement par cert-manager
on va renseigner le nom qui sera appellé et configuré dans l'ingress : notre point d'entrée dans le cluster depuis l'exterrieur pour atteindre notre appli.

le mode op d'install de trow nous fait partir depuis le repo du repertoire install :
on copie le rep overlays/example-overlay pour notre conf :
cp -r overlays/example-overlay overlays/paasregistry-lapin

On en touche pas aux manifests de base
tree base                            
base
├── kustomization.yaml
├── patch-trow-arg.yaml
├── patch-validator-domain.yaml
├── service.yaml
├── stateful-set.yaml
└── validate.yaml

on ne touche pas à overlay/cert-manager :
tree overlays/cert-manager-nginx        
overlays/cert-manager-nginx
├── ingress.yaml
├── kustomization.yaml
└── patch-ingress-host.yaml

on ne modifie que la conf relative a notre cluster : 


tree paas-sandbox                      
paas-sandbox
├── kustomization.yaml
├── patch-ingress-host.yaml
├── patch-trow-arg.yaml
├── patch-validator-domain.yaml
├── pv-data-trow.yaml
└── README.md

on va maintenant ajouter dans notre rep d'overlay dédié à notre cluster ajouter un volume que nous créons manuellement avec une strategie de hostpath : storage local sur les nodes 

cat pv-data-trow.yaml 
 apiVersion: v1
 kind: PersistentVolume
 metadata:
   name: trow-data-hostpath-pv
   labels:
     app: trow
 spec:
   accessModes:
   - ReadWriteOnce
   capacity:
     storage: 10Gi
   hostPath:
     path: /data

on va integrer notre volume  dans la conf kustomized pour qu'il soit pris en compte on l'ajoute dans une section resource :

cat kustomization.yaml                                        
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: trow-example

bases:
  - ../cert-manager-nginx

generatorOptions:
    disableNameSuffixHash: true

secretGenerator:
  - name: trow-pass
    literals:
    - pass=blabla
  - name: trow-cred
    type: docker-registry
    literals:
    - docker-server=example.registry.com
    - docker-username=example
    - docker-password=blabla

patchesJson6902:
  - path: patch-ingress-host.yaml
    target:
      kind: Ingress
      name: trow-ingress
      group: extensions
      version: v1beta1
  - path: patch-trow-arg.yaml
    target:
      kind: StatefulSet
      name: trow-set
      group: apps
      version: v1

resources:                 <<< on ajoute un bloc resources avec nos deux volumes 
  - pv-data-trow.yaml


on va maintenant modifier les fichiers qui vont contenir nos specs :


- patch-ingress-host.yaml : 
on ajoute des nouvelles annotations ( le path de cert-manager a changé  on ajoute donc le bon chemin pour la prise en compte par certmanager et la creation du certif ssl ( cert-manager.io/cluster-issuer: ) puis on ajoute les annotations deja presentes dans le manifest ingress mais qui sont ecrasée avec la fonction add de kustomized (     kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"

on renseigne l'entree ns de l'ingress qui va nous servir
cat patch-ingress-host.yaml                                                  [☸ |kubernetes-admin@sandbox:trow]
- op: add
  path: /metadata/annotations
  value:
    cert-manager.io/cluster-issuer: ca-issuer
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
- op: replace
  path: /spec/rules/0/host
  value: paasregistry.lapin.io
- op: replace
  path: /spec/tls/0/hosts/0
  value: paasregistry.lapin.io


- patch-trow-arg.yaml
on renseigne le domaine et le user défini dans le kustomized de notre cluster :  

cat patch-trow-arg.yaml
- op: replace #domain name
  path: /spec/template/spec/containers/0/args/2
  value: paasregistry.lapin.io
- op: replace #user name
  path: /spec/template/spec/containers/0/args/4
  value: trow-pass


on va maintenant appliquer le kustomized sur nos arbos respectives pour appliquer les confs :

kubectl apply -k base/
kctl apply -k overlays/cert-manager-nginx
kctl apply -k overlays/paas-lapin

on va maintenant modifier notre ingress-controller  pour changer le service en Loadbalancer et attribuer une  ip fixe pour atteindre notre point d'entrée depuis l'exterrieur de notre cluster : les requettes externes passeront par l'ingress controller et son ip externe et le dispatch sera fait ensuite vers les ressources ingress qui enverront vers les services et enfin les pods 

et on va donc finalement définir notre fichier kustomized.yaml qui va contenir les informations nécéssaire :

cat overlays/paas-sandbox/kustomization.yaml                                                 
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: trow

bases:
  - ../cert-manager-nginx
generatorOptions:
    disableNameSuffixHash: true

secretGenerator:
  - name: trow-pass
    literals:
    - pass=s3cr3tp@55
  - name: trow-cred
    type: docker-registry
    literals:
    - docker-server=example.registry.com
    - docker-username=example
    - docker-password=s3cr3tp@55
resources: 
  - pv-data-trow.yaml    <<<<< on ajoute ici notre fichier de volume comme nouvelle ressource.

patchesJson6902:                      <<<< on renseigne ici les deux fichiers patch qui serviront a modifier les manifests
  - path: patch-ingress-host.yaml           
    target:
      kind: Ingress
      name: trow-ingress
      group: extensions
      version: v1beta1
  - path: patch-trow-arg.yaml
    target:
      kind: StatefulSet
      name: trow-set
      group: apps
      version: v1


On va modifier la config de notre ingress controller pour definir une ip externe par laquelles les clients externes au cluster se connecteront : 
....
  type: LoadBalancer
  externalIPs:
  - 192.168.1.250
...

kctl get svc ingress-controller-ingress-nginx-controller -o yaml
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2020-05-26T13:21:03Z"
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-controller
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/version: 0.32.0
    helm.sh/chart: ingress-nginx-2.3.0
  name: ingress-controller-ingress-nginx-controller
  namespace: ingress-controller
  resourceVersion: "257557"
  selfLink: /api/v1/namespaces/ingress-controller/services/ingress-controller-ingress-nginx-controller
  uid: 4f42464c-69e7-4912-8ccf-9455304a9340
spec:
  clusterIP: 10.93.244.43
  externalIPs:
  - 192.168.1.250
  externalTrafficPolicy: Cluster
  ports:
  - name: http
    nodePort: 30677
    port: 80
    protocol: TCP
    targetPort: http
  - name: https
    nodePort: 30849
    port: 443
    protocol: TCP
    targetPort: https
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-controller
    app.kubernetes.io/name: ingress-nginx
  sessionAffinity: None
  type: LoadBalancer
status:
  loadBalancer: {}


 kctl get svc -n ingress-controller 
NAME                                                    TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                      AGE
ingress-controller-ingress-nginx-controller             LoadBalancer   10.93.244.43   192.168.1.250  80:30677/TCP,443:30849/TCP   19h
ingress-controller-ingress-nginx-controller-admission   ClusterIP      10.90.197.52   <none>           443/TCP                      19h

on a de plus de renseigner dans notre ressource ingress l'ip externe qu'on a défini dans notre ingress controller 
kctl get ing -o yaml                                       
apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: Ingress
  metadata:
    annotations:
      certmanager.k8s.io/cluster-issuer: ca-issuer
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"extensions/v1beta1","kind":"Ingress","metadata":{"annotations":{"certmanager.k8s.io/cluster-issuer":"ca-issuer","kubernetes.io/ingress.class":"nginx","nginx.ingress.kubernetes.io/proxy-body-size":"0","nginx.ingress.kubernetes.io/proxy-read-timeout":"600","nginx.ingress.kubernetes.io/proxy-send-timeout":"600"},"name":"trow-ingress","namespace":"trow"},"spec":{"rules":[{"host":"paasregistry.lapin.io","http":{"paths":[{"backend":{"serviceName":"trow-svc","servicePort":8000},"path":"/"}]}}],"tls":[{"hosts":["paasregistry.lapin.io"],"secretName":"trow-registry-tls"}]}}
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    creationTimestamp: "2020-05-26T16:45:17Z"
    generation: 1
    name: trow-ingress
    namespace: trow
    resourceVersion: "257565"
    selfLink: /apis/extensions/v1beta1/namespaces/trow/ingresses/trow-ingress
    uid: 3fa0ca29-49ae-43fa-af65-5aece3de44aa
  spec:
    rules:
    - host: paasregistry.lapin.io
      http:
        paths:
        - backend:
            serviceName: trow-svc
            servicePort: 8000
          path: /
    tls:
    - hosts:
      - paasregistry.lapin.io
      secretName: trow-registry-tls
  status:
    loadBalancer:
      ingress:
      - ip: 192.168.1.250
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""


kctl get ing         
NAME           HOSTS                           ADDRESS          PORTS     AGE
trow-ingress   paasregistry.lapin.io   10.121.253.211   80, 443   19h


on renseigne dans notre fichier hosts la conf 
 192.168.1.250 paasregistry.lapin.io 

et on peut maintenant de puis notre pc atteindre nos ressources trow : 

curl paasregistry.lapin.io
<html>
<head><title>308 Permanent Redirect</title></head>
<body>
<center><h1>308 Permanent Redirect</h1></center>
<hr><center>nginx/1.17.10</center>
</body>
</html>
 boogie@boogieland  ~/Documents/work/repos_work/trow/install/overlays/paas-sandbox   master ●  curl -k  https://paasregistry.lapin.io
<!DOCTYPE html><html><body>
<h1>Welcome to Trow, the cluster registry</h1>
</body></html>%

à la fin de notre install on va devoir changer les droits du rep /data avec le user 999 en proprio comme la doc l'indique ( c'est pour le user trow de l'appli) pour permettre d'avoir les bon acces pour notre pod 
chown -R 999:999 /data


/ attention cette proc à permi d'installer l'appli ..mais c'est bancal : pas de connaissance de kustomized pour assurer la propreté du travail \
De plus tous les nodes (meme  le master )  du cluster vont porter une ip 192.168.1.250 defini pour ingress : ceci est du à kube-proxy qui associe la conf ingress a chaque nodes.

== Test :

on peut utiliser docker ou podman par exemple pour manipuler les containers 
ici on test avec podman 
connection à la registry :

on ajoute la registry dans note conf :

cat /etc/containers/registries.conf 
[registries.search]
registries = ['docker.io', 'quay.io', 'paasregistry.lapin.io']

on s'authentifie 

podman login paasregistry.lapin.io
user: defini dans trow
paswd: defini dans trow

on test la registry :

on recupere une image :
podman pull python

on la tag avec l'id de notre registry :
podman tag python:latest paasregistry.lapin.io/python:latest

on pousse l'image : 
podman push paasregistry.lapin.io/python:latest

on delete tours les images locales pour être sur de bien pull :
podman rmi 659f826fabf4 659f826fabf4 -f                                 
Untagged: docker.io/library/python:latest
Untagged: paasregistry.lapin.io/python:latest
Deleted: 659f826fabf48f9d883895d7ad4bb6b49f79bc7c0ee8590b943e2ccd295df568
Error: unable to find a name and tag match for 659f826fabf4 in repotags: no such image

on pull l'image : 

podman pull paasregistry.lapin.io/python
Trying to pull paasregistry.lapin.io/python...
Getting image source signatures
Copying blob 2ddb75a88683 done
Copying blob e1ac3b88b787 done
Copying blob f47591e5c75d done
Copying blob 086c4de50f71 done
Copying blob c9841f4ef425 done
Copying blob 3b40d033f8dc done
Copying blob de0ef6ab1825 done
Copying blob 8b45a8f9a2cf done
Copying blob 5542568d0a21 done
Copying config 659f826fab done
Writing manifest to image destination
Storing signatures
659f826fabf48f9d883895d7ad4bb6b49f79bc7c0ee8590b943e2ccd295df568

podman images                                                                [☸ |kubernetes-admin@sandbox:trow]
REPOSITORY                             TAG      IMAGE ID       CREATED      SIZE
paasregistry.lapin.io/python   latest   659f826fabf4   7 days ago   957 MB



todo 

faire des tests avec docker
attention changement d'images passée en latest (pb sinon avec le https sur loaclhost port 51000)
attention changement des annotaions pour le patch de cert-manager : plus compatible du coup pas de certificat ssl généré : pas de trigger a certmanager suite modif de path

faire du node affinity/ antiaffinity et mettre un label sur les nodes pour faire du node selector.

faire un repo qui va inclure le repo trow en dependance 
