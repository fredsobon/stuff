=== notes ud_gitlab ci beguinner : ===

== notes install minikube : ===

minikube start --kubernetes-version=v1.20.0 --cpus 4  --disk-size 20g --memory 8192M
minikube addons enable ingress
http://127.0.0.1:46653/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/

utilisation d'une conf light pour tourner sur minikube :

curl --output values.yaml "https://gitlab.com/gitlab-org/charts/gitlab/raw/master/examples/values-minikube-minimum.yaml"

modification de l'ip du fichier par l'ip de notre minikube :
minikube node list           
minikube	192.168.39.69  <<<< ip qu'on renseigne dans le fichier de value

minikube ip
192.168.39.69

fichier d'install minimal pour minikube :
cat values-minikube.yaml                                                                                                                       [☸ |minikube:default]
# values-minikube.yaml
# This example intended as baseline to use Minikube for the deployment of GitLab
# - Services that are not compatible with how Minikube runs are disabled
# - Configured to use 192.168.99.100, and nip.io for the domain

# Minimal settings
global:
  ingress:
    configureCertmanager: false
    class: "nginx"
  hosts:
    domain: 192.168.39.69.nip.io
    externalIP: 192.168.39.69
  shell:
    # Configure the clone link in the UI to include the high-numbered NodePort
    # value from below (`gitlab.gitlab-shell.service.nodePort`)
    port: 32022
# Don't use certmanager, we'll self-sign
certmanager:
  install: false
# Use the `ingress` addon, not our Ingress (can't map 22/80/443)
nginx-ingress:
  enabled: false
# Map gitlab-shell to a high-numbered NodePort cloning over SSH since
# Minikube takes port 22.
gitlab:
  gitlab-shell:
    service:
      type: NodePort
      nodePort: 32022
# Provide gitlab-runner with secret object containing self-signed certificate chain
gitlab-runner:
  certsSecretName: gitlab-wildcard-tls-chain




on ajoute le repo gitlab 
helm repo add gitlab https://charts.gitlab.io
on lance le setup en passant en argument le fichier minimal dl et modifié auparavant :
helm install gitlab -f values-minikube.yaml gitlab/gitlab                                                                                     [☸ |minikube:default]

W0206 12:35:13.131654  130195 warnings.go:70] extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress
W0206 12:35:13.133515  130195 warnings.go:70] extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress
W0206 12:35:13.135040  130195 warnings.go:70] extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress
W0206 12:35:40.643249  130195 warnings.go:70] extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress
W0206 12:35:40.653756  130195 warnings.go:70] extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress
W0206 12:35:40.653795  130195 warnings.go:70] extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress
NAME: gitlab
LAST DEPLOYED: Sat Feb  6 12:35:10 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
NOTICE: The resource requests have increased for the Webservice and Sidekiq charts.
    For more information on Webservice resources, see https://docs.gitlab.com/charts/charts/gitlab/webservice/index.html#resources
    For more information on Sidekiq resources, see https://docs.gitlab.com/charts/charts/gitlab/sidekiq/index.html#resource
    Related merge request: https://gitlab.com/gitlab-org/charts/gitlab/-/merge_requests/1634

    To restore the original resource specifications:
    --set gitlab.sidekiq.resources.requests.cpu=50m
    --set gitlab.sidekiq.resources.requests.memory=650M
    --set gitlab.webservice.resources.requests.memory=1.5G

WARNING: Automatic TLS certificate generation with cert-manager is disabled and no TLS certificates were provided. Self-signed certificates were generated.

You may retrieve the CA root for these certificates from the `gitlab-wildcard-tls-ca` secret, via the following command. It can then be imported to a web browser or system store.

    kubectl get secret gitlab-wildcard-tls-ca -ojsonpath='{.data.cfssl_ca}' | base64 --decode > gitlab.192.168.39.69.nip.io.ca.pem

If you do not wish to use self-signed certificates, please set the following properties:
  - global.ingress.tls.secretName
  OR
  - global.ingress.tls.enabled (set to `true`)
  - gitlab.webservice.ingress.tls.secretName
  - registry.ingress.tls.secretName
  - minio.ingress.tls.secretName


Help us improve the install experience, let us know how we did with a 1 minute survey:
https://gitlab.fra1.qualtrics.com/jfe/form/SV_6kVqZANThUQ1bZb?installation=helm&release=13-8

on renseigne dans notre fichier host le record 

192.168.39.69 gitlab.192.168.39.69.nip.io


on peut recup le certif auto signé et l'ajouter dans notre magasin de certifs du navigateur :

 kubectl get secret gitlab-wildcard-tls-ca -ojsonpath='{.data.cfssl_ca}' | base64 --decode > gitlab.192.168.39.69.nip.io.ca.pem

 on va ensuite recupérer les créentials générésà l'install pour se logger sur notre browser : 

kubectl get secret <name>-gitlab-initial-root-password -ojsonpath='{.data.password}' | base64 --decode ; echo
eDZIM3RZN0dpRjFPN212WUFUOFVjVElYQjcyYW55RkhOZFl1T1RSVzBIWklpYWtCazhWV0g4ZXlEa3ZPVTFVZQ==" |base64 -d                  [☸ |minikube:default]

x6H3tY7GiF1O7mvYAT8UcTIXB72anyFHNdYuOTRW0HZIiakBk8VWH8eyDkvOU1Ue%

on se logge ensuite avec le user root et le mdp recupéré sur l'url http://gitlab.192.168.39.69.nip.io

kubectl get secret <name>-gitlab-initial-root-password -ojsonpath='{.data.password}' | base64 --decode ; echo

root 



== fin de set up ==


== ud gitab ci beguinner ==


= architecture : 

gitlab server :

interface .Fourni tous les composants pour gérer notre project.
tout est stocké en db

des qu'on crée un pipeline : tout est géré par le gitlab server qui va déléguer le job a un gitlab runner qui va executer les taches et créer un artifact si besoin.
le gitlab serveur ne gére pas la charge de traitement mais manage le runner et s'assure qu'il a bien fait le job.
La solution est scalable ca on peut donc ajouter le nombre de gitlab runner qu'on veut pour assurer le job.

par exemple un runner lance un job :
> une image docker de ruby 2.5 est utilisée (img de base pour les runners) 
> le repo est cloné
> les steps sont fait
> un artifact est build
> le container est détruit à la fin du job
> on peut recup l'artifact et consulter les logs pour examiner le déroulement du job.

- runners :

on peur voir la maniere dont ils sont configurés :

projet > settings > ci /cd > on chercher runners > expand 
shared runners : 
ils sont dispos pour tous les users de gitlab
on peut dédié des runners pour nos tasks : tels projets, tel jobs seront dédiés.

= basic :

ci /cd 

> ci 
integration icontinue de code avec d'autres dev
chaque fois qu'on met du code à jour ce code va être intégré et testé ( build , test ok ? )

code >| build > code quality > tests > package |
        les phases entre | sont un pipeline
             ci pipeline

les erreurs sont détectées rapidement
le temps d'intégration est réduit
le dev se fait plus vite.

> cd 
apres avoir créer un package ( fin de ci) on va tester , installer le code sur un serveur de test puis déployer (manuellement ou pas sur la production)

package > | test review > staging > production |
                cd pipeline

chaque changement est releasable grace aux tests
reduction des risques de déployement 
deployement plus rapide : mise en place plus rapide de feature

                
- creation d'un project 

clone de https://gitlab.com/gitlab-course-public/my-static-website-no-pipeline.git

nodejs :
javascript runtime sans l'obligation d'ouvrir un navigateur.
npm : node package manager

static website 

https://www.gatsbyjs.com/docs/quick-start/#install-the-gatsby-cli

npm init gatsby


on installe 2 plugins :
gatsby-plugin-offline, gatsby-plugin-mdx


npx gatsby buildon se deplace dans notre folder :

cd static-website                                                                            
 boogie@boogieland  ~/Documents/lab/gitlab/projet/my-static-website-no-pipeline/static-website   master  ls 
gatsby-config.js  node_modules  package.json  package-lock.json  README.md  src

Start the local development server with

  npm run develop

See all commands at

  https://www.gatsbyjs.com/docs/gatsby-cli/

on peut acceder sur notre browser à un server http :

http://localhost:8000/


on va créer dans gitlab un nouveau projet :

static-website : on va cloner le repo sur notre poste

on crée un fichier .gitignore qui va contenir les fichiers que l'on ne veut pas synchro sur notre repo : node_modules package-lock.json

-  gatsby : étapes de build 

> construction de html et js 
> css et js sont compressés pour réduire la taille  'minified'
> gatsby build : on compile 



on peut prefixer les commandes avec npx :
https://github.com/gatsbyjs/gatsby/issues/15276
https://www.freecodecamp.org/news/npm-vs-npx-whats-the-difference/


npx gatsby build
...
....

info Generated public/sw.js, which will precache 6 files, totaling 283328 bytes.
The following pages will be precached:
/offline-plugin-app-shell-fallback/index.html
success onPostBuild - 0.078s
info Done building in 11.535389074 sec


la compilation a crée des fichiers dans le rep public : c'est ici qu'on va avoir nos fichiers que l'on pourra pousser en production.
ceci constitue donc notre artifact que l'on va déployer.
on va donc avec gitlab-ci automatiser cette phase de compilation

- docker :

docker va nous permettre de construire une image 
en packagant une application et ses dependances.


on va pull en local l'image docker node et executer dans le container les commandes ok pour le build (pb de dépendances versions js )
> on abouti à une liste de commande qui vont nous servir pour notre ci :

    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build


- creation de pipeline :

on va créer dans notre repo un fichier .gitlab-ci.yaml qui va contenir les etapes de notre build :
cat .gitlab-ci.yml                                                                   [☸ |sandbox:e2e]
# first pipeline with first build instructions
build website:
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build

le premier run tombe ko > 

"npm command not found"

en regardant on voit que le container utilisé est : Using Docker executor with image ruby:2.5 ..

il n'y a pas npm d'installé..

on va donc changer notre build en intégrant une image nodejs (on peut examiner sur dockerhub) 

# first pipeline with first build instructions
build website:
  image: node
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build

on va maintenant que notre build est ok recupérer notre artifact pour examiner le contenu du site qui sera publié.

on va donc rajouter la section artifact suivie du path dans lequel on va trouver notre artifact : on va préfixer par./ pour assurer la présence à partir de notre répertoire courant.

build website:
  image: node
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
  artifacts:
    paths:
      - ./public


on va avoir la sortie de notre build comme telle :
...
info Done building in 19.65983832 sec
Uploading artifacts for successful job
Uploading artifacts...
./public: found 30 matching files and directories  
Uploading artifacts as "archive" to coordinator... ok  id=1020136188 responseStatus=201 Created token=zied3oyS
Cleaning up file based variables
00:01
Job succeeded

on a la possibilité de recupérer l'artifact directement ou en cliquant sur browse : on voit le rep public qui contient notre artifact : le contenu de notre site pour la production.

- ajout d'un pipeline de test :

comment s'assurer que notre build est ok.
La convention veut que tout les stages qui finissent par 0 sont ok sinon un fail a eu lieu
on se base donc sur les codes retours 
0 > ok
1-255 > fail

ici on va vouloir tester que dans notre index.html on a un pattern précis "Gatsby"

 boogie@boogieland  ~/Documents/lab/gitlab/projet/my-static-website-no-pipeline/static-website   master  grep -q "Gatsby" public/index.html                                          
 boogie@boogieland  ~/Documents/lab/gitlab/projet/my-static-website-no-pipeline/static-website   master  echo $?                                                                    
0
 boogie@boogieland  ~/Documents/lab/gitlab/projet/my-static-website-no-pipeline/static-website   master  grep -q "lapin" public/index.html                                         
 ✘ boogie@boogieland  ~/Documents/lab/gitlab/projet/my-static-website-no-pipeline/static-website   master  echo $?                                                                
1

on va donc rajouter un stage pour notre test.

on va pouvoir nommer notre stage comme on veut : on va devoir définir une section qui comprend les stages de notre build :
on ajoute deux tests : un qui fini en ok et l'autre qui failed volontairement.



Attention : gitlab execute toujours les stages dans l'ordre de leur définition dans le fichier .gitlab.ci 

stages:
  - build
  - test

build website:
  stage: build
  image: node
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
  artifacts:
    paths:
      - ./public

test artifact:
  stage: test
  script:
     - grep "Gatsby" ./public/index.html
     - grep "lapin"  ./public/index.html


on voit deux stages dans notre pipeline


le resultat du test nous donne donc :
Running with gitlab-runner 13.8.0 (775dd39d)
  on docker-auto-scale ed2dce3a
Preparing the "docker+machine" executor
Using Docker executor with image ruby:2.5 ...
Pulling docker image ruby:2.5 ...
Using docker image sha256:67b2b6cb06d9e429852b3db87ca3427648b229685c52cc9474f4c7b2a832ec5e for ruby:2.5 with digest ruby@sha256:d99439def9ef2349c327ae76665be0d18376f7d9cc4d3a8ddfeb8f970271fdae ...
Preparing environment
00:03
Running on runner-ed2dce3a-project-24244335-concurrent-0 via runner-ed2dce3a-srm-1612947335-34fdf2d8...
Getting source from Git repository
00:01
$ eval "$CI_PRE_CLONE_SCRIPT"
Fetching changes with git depth set to 50...
Initialized empty Git repository in /builds/frederic.sobon/static-website/.git/
Created fresh repository.
Checking out b2c9f669 as master...
Skipping Git submodules setup
Downloading artifacts
00:01
Downloading artifacts for build website (1020178687)...
Downloading artifacts from coordinator... ok        id=1020178687 responseStatus=200 OK token=ndEvFxVg
Executing "step_script" stage of the job script
00:01
$ grep "Gatsby" ./public/index.html
...
...

$ grep "lapin"  ./public/index.html
Cleaning up file based variables
00:01
ERROR: Job failed: exit code 1



- build de job en parallele :

on va modifier notre build 

pour le test on va utiliser une image alpine > plus light 

on ajoute un test qui va tester notre site  gatsby en lancant le serveur et en faisant un curl sur une ressourcei.
on ajoute un & apres gatsby serve pour lancer notre commande en background et nous permettre ensuite de lancer les commandes suivantes sinon on ne peut continuer le process ..qui reste sur le check

stages:
  - build
  - test

build website:
  stage: build
  image: node
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  image: node
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve &
    - sleep 3
    - curl http://localhost:9000 | grep -q "Gatsby"



dans gitlab on voit qu'on a trois etapes dont deux en parrallele : les deux tests s'executent en parallele car on a spécifier le même stage dans nos deux confs :

 build website       test artifact
                     test website


dans un job on peut executer egalement plusieurs test en parallele pour s'assurer de l'integrité du test avec le keyword parralel
parallel: x

ex :

test artifact:
  image: alpine
  stage: test
  parallel: 5               <<<<< on va lancer le job 5 fois pour nous assurer du test 
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  image: node
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve &
    - sleep 3
    - curl http://localhost:9000 | grep -q "Gatsby"


ici dans notre cas il est possible de lancer en parrale les tests cela depend evidemment de nos contextes ( le build est un prérequi pour nos tests ..on ne peut pas tester le contenu si le build n'est pas fait.)
dans notre cas on ne gagne pas en performance car le test website install gatsby ..on a toujours le temps d'install des dependance ..mais dans certains ca on peut hériter d'un job précéder ce qui nous fait ganger un temps précieux.

sortie de deuxieme test :
...
....
$ gatsby serve &
$ sleep 3
warning Error: ENOENT: no such file or directory, open '/builds/frederic.sobon/static-website/.cache/match-paths.json'
warning Could not read match-paths.json from the .cache directory
warning Client-side routing will not work correctly. Maybe you need to re-run gatsby build?
⠀
You can now view static-website in the browser.
⠀
  http://localhost:9000/
$ curl http://localhost:9000 | grep -q "Gatsby"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5751  100  5751    0     0   101k      0 --:--:-- --:--:-- --:--:--  102k
Cleaning up file based variables
00:01
Job succeeded


on peut avoir des erreurs de sortie de curl qui va avoir une sortie "Failed write body" : dans ce cas curl ferme la connexion avant d'avoir ecrit toute la page web . on peut rajouter une double commande tac pour fixer le pépin. 

stages:
  - build
  - test

build website:
  stage: build
  image: node
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  image: node
  script: 
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli     
    - gatsby serve &
    - sleep 3
    - curl http://localhost:9000 |tac |tac | grep -q "Gatsby" 


- Deployment du site web :

surge cloud platform pour serverless platform > deployment sans se soucier de la plateforme
simple moyen de déployer un site web static 

on install surge : 
sudo npm install --global surge                                                     
sudo: unable to resolve host boogieland: Name or service not known
[sudo] password for boogie:
npm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142
npm WARN deprecated har-validator@5.1.5: this library is no longer supported
/usr/local/bin/surge -> /usr/local/lib/node_modules/surge/lib/cli.js
+ surge@0.21.7
added 112 packages from 96 contributors in 4.333s


on va se placer dans le repo public contenant notre site 
on lance surge > on remplit adresse mail + mdp + on check que la racine de notre arbo est bien celle du site . surge synchro ensuite le code quelque part dans le cloud et nous donne le nom de domaine 

 boogie@boogieland  ~/Documents/lab/gitlab/projet/my-static-website-no-pipeline/static-website   master  cd public                                                                            [☸ |N/A:default]
 boogie@boogieland  ~/Documents/lab/gitlab/projet/my-static-website-no-pipeline/static-website/public   master  surge                                                                         [☸ |N/A:default]

   Running as jazz77777@gmail.com (Student)

        project: /home/boogie/Documents/lab/gitlab/projet/my-static-website-no-pipeline/static-website/public/
         domain: petite-ducks.surge.sh
         upload: [====================] 100% eta: 0.0s (23 files, 1080748 bytes)
            CDN: [====================] 100%
     encryption: *.surge.sh, surge.sh (70 days)
             IP: 138.197.235.123

   Success! - Published to petite-ducks.surge.sh


quelques secondes suffisent à avoir notre site static up dans le cloud.

= gestion des mdp /secrets dans notre code via variables d'environment :

biensur on ne commit rien contenant des password.
on va pouvoir renseigner des secret dans gitlab sans qu'ils ne soient visible dans le code.

pour notre exemple on va vouloir déployer dans le cloud avec surge sans saisir le mdp .
On va générer un token via surge et le renseigner dans gitlab 

surge token                                                                   [☸ |N/A:default]

   sqdqdqsdqsdqd181b5f04dsdsdsdqdqsdqsdqdqsdqdqdqdqdqedfcsdc

 gitlab > notre projet > barre laterale gauche > ci/cd > environment variables :

 les variables seront accessible par notre runner

 on va créer deux variables :

 une pour le compte mail et une pour le token 

 SURGE_LOGIN
 SURGE_TOKEN 

/!\ le nom des variables est important : il faut qu'elles soient reconnues et identifiées par l'appli : dans notre cas surge attend ces variables 

on va donc maintenant deployer le site en utilisant gitlab-ci 

on ajoute le stage deploy 

on voit qu'on a plusieurs stage qui utilise l'image node : on peut la définir par defaut ce qui factorise le code 
dans notre stage on installe surge en precisant le path du contenu de notre site et un nom de domaine surge non pri ex : boogie.surge.sh

on ne specifie pas les token car gitlab met a dispo dans le runner

cat .gitlab-ci.yml                                                                 [☸ |N/A:default]
image: node

stages:
  - build
  - test
  - deploy

build website:
  stage: build
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve &
    - sleep 3
    - curl "http://localhost:9000" |grep -q "Gatsby"

deploy to surge:
  stage: deploy
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie.surge.sh

on a donc trois stages dans notre deployment

$ surge --project ./public --domain boogie.surge.sh
34   Running as xxxxx (Student)
35        project: ./public
36         domain: boogie.surge.sh
37     encryption: *.surge.sh, surge.sh (70 days)
38             IP: 138.197.235.123
39   Success! - Published to boogie.surge.sh
41
Cleaning up file based variables
00:01
43Job succeeded


notre site est en ligne 


on ajoute un test de post deploy qui fait un simple curl de notre domain pour nous assurer que le domain existe et qu'il renvoi du contenu
on utilise une image alpine plus light et on install curl avant de l'utiliser dans le stage.
cat .gitlab-ci.yml  
image: node

stages:
  - build
  - test
  - deploy
  - deploy test

build website:
  stage: build
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve &
    - sleep 3
    - curl "http://localhost:9000" |grep -q "Gatsby"

deploy to surge:
  stage: deploy
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie.surge.sh

post deploy test:
  stage: deploy test
  image: alpine
  script:
    - apk --no-cache add curl 
    - curl -q http://boogie.surge.sh

== gitlab ci : fundamentals. ==


= predefined variables : =

sur notre site on a pas forcement l'information de la version déployée ni du commit qui a servi a déployer.
gitlab embarque beaucoup de variables prédéfinies 

https://docs.gitlab.com/ee/ci/variables/predefined_variables.html

on va pouvoir utiliser la var CI_COMMIT_SHORT_SHA pour identifier le commit déployé

dans un premier temps on va juste vouloir lire la valeur de cette variable  : on rajoute un echo CI_COMMIT_SHORT_SHA dans le job de build :

..
build website:
  stage: build
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
  artifacts:
    paths:
      - ./public
..

dans notre index.js source on va ajouter un marqueur pour la version ceci va rajouter une section version dans la page index.html générée au build

ex : cat src/pages/index.js
...
.....
      />
     <div>Version: %%VERSION%%</div>      
    </main>
  )
}


dans le run du build on peut voir :
$ echo $CI_COMMIT_SHORT_SHA
754fecec


on va utiliser sed pour remplacer la version a chaque itération 

apres notre deployment on voit sur notre home :
en faisant un F5 
Version: 3b5fec95
Version: %%VERSION%% 

le js est executé coté client et la version du tag n'est pas visible tout le temps 
on ajoute test avec curl qui n'executant pas de js nous permet de voir dynamiquement la version recupérée dans notre test ci 

sur la page de notre site boogie.surge.sh
on voit la section :

Version: %%VERSION%%

cat .gitlab-ci.yml                                                                   [☸ |N/A:default]
image: node

stages:
  - build
  - test
  - deploy
  - deploy test

build website:
  stage: build
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/"  ./public/index.html
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve &
    - sleep 3
    - curl "http://localhost:9000" |grep -q "Gatsby"

deploy to surge:
  stage: deploy
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie.surge.sh

post deploy test:
  stage: deploy test
  image: alpine
  script:
    - apk --no-cache add curl
    - curl -q http://boogie.surge.sh
    - curl http://boogie.surge.sh |grep -q "$CI_COMMIT_SHORT_SHA"



= pipeline triggers and retried failed jobs :

si on a un job qui failed ( ce qui peut arriver ) 

> on peut relancer avec un retried 

pareil pour le pipeline complet 
> on peut relancer avec un retried 

on peut lancer un pipeline complet avec des selections manuelles

ci/cd > run pipeline

choisir une branche 


on peut créer un cron / schedule qui va nous permettre de lancer la pipeline automatiquement quand on veut 

ci/cd 
> schedule

on defini l'horaire qu'on veut et on enregistre
on peut forcer le ci manuellement si on veut 

= optimisation des build avec le cache : =

Certaines etapes peuvent prendre du temps : notamment les phases de build (il faut download les dependances et autres ...) a chaque fois puisque qu'on part d'un env clean a chaque itération 
contrairement a jenkins qui ne supprime pas les elements d'environment.

on va pouvoir definir des resources qui sont nécéssaires ( dependances ..) qui ne font pas partie du projet git

on peut dire a gitlab de ne pas delete les fichiers a chaque fois : de les conserver afin de les reutiliser pour rendre nos executions plus rapides.

dans notre exemple le repertoire node_modules est exactement ce qu'on veut conserver.


on va donc rajouter une section dans notre build pour garder les infos de build 

build website:
  stage: build
  cache:                         <<<< section cache 
    key: ${CI_COMMIT_REF_SLUG}   <<<   clé qui va permettre d'identifier quand utiliser le cache : une bonen pratique est d'associer le cache à une branche : la variable interne de gitlab CI_COMMIT_REF_SLUG permet  de la faire
    paths:                       <<<<  on va definir le path de se qu'on veut mettre en cache.
      - node_modules/
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/"  ./public/index.html
  artifacts:
    paths:
      - ./public

on peut definir le cache spécifiquement pour un job ou alors on peut le définir globalement pour notre pipeline : ce qui peut etre interressant pour permettre a d'autre job d'utiliser ce cache : dans notre cas c'est utile puisqu'on a un second job qui fait une install node 

on sort donc la section et on la place en global

image: node

stages:
  - build
  - test
  - deploy   
  - deploy test  

cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - node_modules/

build website:
  stage: build
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/"  ./public/index.html
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  script: 
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli     
    - gatsby serve &
    - sleep 3
    - curl "http://localhost:9000" |grep -q "Gatsby" 

deploy to surge:
  stage: deploy
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie.surge.sh

post deploy test:
  stage: deploy test
  image: alpine
  script:
    - apk --no-cache add curl 
    - curl -q http://boogie.surge.sh
    - curl http://boogie.surge.sh |grep -q "$CI_COMMIT_SHORT_SHA"



au premier run on voit des le debut une erreur : gitlab n'a pas de cache :

Restoring cache
00:01
18Checking cache for master...
19FATAL: file does not exist

une fois builde la premiere fois le cache est crée et sauvegardé par gitlab :
..
Creating cache master...
node_modules/: found 51198 matching files and directories
Uploading cache.zip to https://storage.googleapis.com/gitlab-com-runners-cache/project/24244335/master
Created cache
....


dans le second job de test qui build on voit qu'un check de cache est fait au début sur la branche master 
le cache est trouvé et utilisé 
Restoring cache
00:10
Checking cache for master...
Downloading cache.zip from https://storage.googleapis.com/gitlab-com-runners-cache/project/24244335/master 
Successfully extracted cache

à la fin le cache est de nouveau uploadé :
Creating cache master...
node_modules/: found 51198 matching files and directories
Uploading cache.zip to https://storage.googleapis.com/gitlab-com-runners-cache/project/24244335/master
Created cache


on gagne donc pas mal de temps.

il peut arriver que le cache pour une raiso, ou une autre fasse mal le job. On peut clear le cache 
ci/cd > pipeline > clear runner caches.

= cache vs artifact : =


- artifact :
on va pouvoir ajouter des données dans l'artifact job apres job

un premier job crée un artifact, qui sera recupérer par un autre job qui alimentera aussi cet artifact qui sera recup et alimenter par un autre job etc etc ..

l'artifact est souvent le resultat de notre build
dans gitlabci l'artifact sert a sauvegarder la géneration de notre build
les artifacts peuvent être utiliser pour passer des data entre les jobs


De base si on ne precise rien l'artifact est passé au job de test ( si on ne déclarer pas de stage car le workflow natif de gitlab est : build > test > deploy )


Il peut nous arriver de vouloir que certains artifacts ne soient pas récupérer automatiquement pour tous les jobs 
dans ce cas on va indiquer dans le job destination la dependance au job dont on veut récupérer l'artifact précis 

ex : on va specifiquement indiquer dans un test qu'on veut recup l'artifact de notre build ( dans notre cas c'a ne sert à rien mais c'est pour l'exemple ) 

build website:
  stage: build
  only:
    - master
    - merge_requests
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/"  ./public/index.html
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  dependencies                      <<<<< on set le keyword dependencies 
    - build website
..



- cache :

uniquement utiliser pour stocker temporairement les dependances de build pas stocker notre build


https://docs.gitlab.com/ee/ci/caching/#cache-vs-artifacts


= environment : =

jusqu'a present on a créer notre build, packagé et deployé directement en production.
  code > build > codequality >test > package >  production

On va biensur vouloir ajouter des stages afin de nous assurer de la viabilité de notre code.
L'idee est d'avoir un pipeline de ce type : 
  code > build > codequality >test > package > review test > staging > production

on va dans notre cas ajouter un stage :

  code > build > codequality >test > package > staging > production

on change nos stages :
...
stages:
  - build
  - test
  - deploy staging   <<< on ajoute le deployment en staging
  - deploy production <<<< le deployment en production est specifiquement défini
  - production tests  <<<  les tests post deploy se font en prod ( pas de plateforme de staging)
..

on renomme les jobs aussi et on ajoute notre job de déployment en staging.
on fait pointer notre job de déployment de staging sur une entrée dns pointant sur un env de staging / preproduction dédié.

ces etapes sont cruciales pour tester en amont de production les fonctionnalitées completes des sites ( ex: appels à des external api , ....) 



image: node

stages:
  - build
  - test
  - deploy staging
  - deploy production
  - production tests

cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - node_modules/

build website:
  stage: build
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/"  ./public/index.html
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve &
    - sleep 3
    - curl "http://localhost:9000" |grep -q "Gatsby"

deploy staging:
  stage: deploy staging
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie-staging.surge.sh   <<<<< ici on pointe sur un domaine de staging  qu'on aura defini au prealable.
deploy production:
  stage: deploy production
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie.surge.sh

production tests:
  stage: production tests
  image: alpine
  script:
    - apk --no-cache add curl
    - curl -q http://boogie.surge.sh
    - curl http://boogie.surge.sh |grep -q "$CI_COMMIT_SHORT_SHA"

Gitlab peut nous permettre d'utiliser la notion d'environment :
> permet de controller les phases de build et deployment
> tracker les deployments
> connaitre précisemement ce qu'il y a de deployé par environment


on va ajouter le keyword environment dans notre pipeline, lui donner un nom et associer l'url dédiée pour chacun des envs :
...
deploy staging:
  stage: deploy staging
  environment:
    name: staging
    url: boogie-staging.surge.sh
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie-staging.surge.sh
deploy production:
  stage: deploy production
  environment:
    name: production
    url: boogie.surge.sh
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie.surge.sh
...

quand on pousse dans gitlab on voit maintenant apparaitre dans la section operation > environment nos deux stages

on remarque les commits associés à nos déployments.

= variables : ==

ajout de variable personalisée

une des pratiques fondamentales est de ne jamais répliquer des informations mais d'utiliser des variables pour cela.
on va donc définir une variable pour les url d'env

on peut le faire via la gui
settings > ci/cd > variables comme on a fait pour le user surge et le token d'api surge

on peut aussi le faire directement dans le code.

comme la variables est utilisée à plusieurs reprises on va la définir en global et remplacer chaque occurence de domain via la variable appropriée :


Dans gitlab on peut créer des variables qui seront liées à notre repo git mais aussi des variables de group qui seront héritées par tous les projets inclus dans le group principale 

   main group >ci> variables   : ces variables seront accessibles dans les jobs des repos enfants du projet.
                 repo1
                 repo2
                 repox

on peut lancer un job manuellement et overrider la variables definies pour ce job en remplissant les champs dédies ( ci/cd > pipeline) 

image: node
stages:
  - build
  - test
  - deploy staging  
  - deploy production
  - production tests  

cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - node_modules/

variables:
  STAGING_DOMAIN: boogie-testing.surge.sh
  PRODUCTION_DOMAIN: boogie.surge.sh

      
build website:
  stage: build
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/"  ./public/index.html
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html
test website:
  stage: test
  script: 
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli     
    - gatsby serve &
    - sleep 3
    - curl "http://localhost:9000" |grep -q "Gatsby" 

deploy staging:
  stage: deploy staging
  environment:
    name: staging
    url: ${STAGING_DOMAIN}
  script:
    - npm install --global surge
    - surge --project ./public --domain ${STAGING_DOMAIN}
deploy production:
  stage: deploy production
  environment:
    name: production
    url: ${PRODUCTION_DOMAIN}
  script:
    - npm install --global surge
    - surge --project ./public --domain ${PRODUCTION_DOMAIN}

production tests:
  stage: production tests
  image: alpine
  script:
    - apk --no-cache add curl 
    - curl -q http://${PRODUCTION_DOMAIN}
    - curl http://${PRODUCTION_DOMAIN} |grep -q "$CI_COMMIT_SHORT_SHA"

= Deployment manuel =

comment déclencher l'execution de job manuellement uniquement.

on sait que jusqu'au déployment en staging on peut tout faire automatiquement.

on va vouloir s'assurer d'un deployment manuel pour la production : 

code > build > codequality >test > package > staging ><validation user << production

on va ajouter une directive dans notre job de deployment qui va déclencher le build uniquement manuellement 
..
deploy production:
  stage: deploy production
  environment:
    name: production
    url: http://${PRODUCTION_DOMAIN}
  when: manual                        <<<< ajout de la condition manual
  script:
    - npm install --global surge
    - surge --project ./public --domain ${PRODUCTION_DOMAIN}
..

https://docs.gitlab.com/ee/ci/yaml/#whenmanual

quand on examine notre pipeline on voit que le job de deployment to production est grisé : pour déployer nous n'avons qu'a cliquer sur le bouton 

on voir egalement que le test de production est ko (le num de commit de notre test de prod n'est forcement pas bon car le test c'est fait avant le déployment manuel de notre de job de production.
on peut relancer le test manuellement pas de pb.

On voudrait s'assurer qu'apres le job manuel les jobs suivants ne soient pas exécutés ( ce qui n'est pas le fonctionnement naturel de gitlab.). 
On va donc appliquer une modif à notre job.
La lecture n'est pas intuitive mais fait le job :

..
deploy production:
  stage: deploy production
  environment:
    name: production
    url: http://${PRODUCTION_DOMAIN}
  allow_failure: false    <<<< ici on defini que 
  when: manual
  script:
    - npm install --global surge
    - surge --project ./public --domain ${PRODUCTION_DOMAIN}
..

https://docs.gitlab.com/ee/ci/yaml/#allow_failure

"Use allow_failure when you want to let a job fail without impacting the rest of the CI suite. The default value is false, EXCEPT for manual jobs that use the when: manual syntax.
In jobs that use rules:, all jobs default to allow_failure: false, including when: manual jobs.
When allow_failure is set to true and the job fails, the job shows an orange warning in the UI. 
However, the logical flow of the pipeline considers the job a success/passed, and is not blocked.
Assuming all other jobs are successful, the job’s stage and its pipeline show the same orange warning. However, the associated commit is marked as “passed”, without warnings."

on voit maintenant que notre test est en status bloqué et que le deploymenten prod attend une intervention manuelle.


= Merge requests : securisation du déployment  =

amelioration du workflow de notre ci avec les merge requests et branches.

On va eviter de travailler sur la branche master dont un probleme pourrait bloquer tout le developpement.
Chaque dev va donc coder sur une brancher et faire une merge request pour pousser sur master.

dans notre cas on va pouvoir garder des steps pour notre branche mais certainement pas les parties de deployment ( staging,production et test production )
on va donc simplement pour ces jobs rajouter une directive qui permettra l'execution uniquement sur master.

on va pouvoir déclarer que personne ne peut pousser sur "master"
on va pouvoir faire des settings pour nos merge requests : 
dans notre repos > settings > repository > protected branches > on peut selectionner "no one" dans la section push : sur la branche master personne ne peut pousser en mode auto.

on peut egalement modifier la conf de nos merge requests :
general > merge request > merge method > selectionner fast forward pour garder un historique clean du repo git.


dans general > merge request > Merge checks "These checks must pass before merge requests can be merged"
on peut cliquer sur 'pipeline must succeeded' et 'all discussions must be resolved'

- merge request - tuto :

> on cree une nouvelle branche 
dans cette branche on ajoute un titre a notre src/index.js 
> on cree une merge request > on valide : trois jobs se lancent : 
build test artifact 
      test website 

les autres jobs se lancent uniquement sur la branche master

des que les jobs sont ok > le merge sur master se fait et cette fois on a tout nos jobs qui s"executent.

on peut rajouter pour reproduire ce comportement "mege_requests" dans la def de nos jobs "séurisés" :

..
deploy production:
  stage: deploy production
  environment:
    name: production
    url: http://${PRODUCTION_DOMAIN}
  only:
    - master
    - merge_requests
  allow_failure: false
  when: manual
  script:
    - npm install --global surge
    - surge --project ./public --domain ${PRODUCTION_DOMAIN}
..

= environments dynamiques : =

les environments de staging et production sont pour la branche master

on va vouloir a chaque branche crées pouvoir disposer d'un environment de review.
on va pouvoir utiliser les environment dynamiques à chaque mr crée et faire des tests spécifiques en plus si besoin.
les changements vont pouvoir être examiner par des personnes moins spécialisées dans le code ( product owner etc...)

on va créer un nouveau stage :

stages:
  - build
  - test
  - deploy review
  - deploy staging
  - deploy production
  - production tests
..


on cree le job associé : 
cette fois on a la création d'un environment dynamic qui se fait avec le nom de notre branche et fait a chaque merge request :
on adapte notree url de test en conséquence :
deploy review:
  stage: deploy review
  environment:
    name: review/$CI_COMMIT_REV_NAME
    url:  http://boogie-$CI_COMMIT_REV_NAME.surge.sh
  only:
    - merge_requests
  script:
    - npm install --global surge
    - surge --project ./public --domain http://boogie-$CI_COMMIT_REV_NAME.surge.sh


on a donc par exemple un env :
review/featureMr


notre fichier complet devient donc :

image: node

stages:
  - build
  - test
  - deploy review
  - deploy staging
  - deploy production
  - production tests

cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - node_modules/

variables:
  STAGING_DOMAIN: boogie-testing.surge.sh
  PRODUCTION_DOMAIN: boogie.surge.sh

build website:
  stage: build
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/"  ./public/index.html
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  script:
     - grep -q "Gatsby" ./public/index.html

test website:
  stage: test
  script:
    - npm install -g npm@7.5.3
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve &
    - sleep 3
    - curl "http://localhost:9000" |grep -q "Gatsby"

deploy review:
  stage: deploy review
  environment:
    name: review/$CI_COMMIT_REF_NAME
    url:  http://boogie-$CI_ENVIRONMENT_SLUG.surge.sh
  only:
    - merge_requests
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie-$CI_ENVIRONMENT_SLUG.surge.sh

deploy staging:
  stage: deploy staging
  environment:
    name: staging
    url:  http://${STAGING_DOMAIN}
  only:
    - master
  script:
    - npm install --global surge
    - surge --project ./public --domain ${STAGING_DOMAIN}

deploy production:
  stage: deploy production
  environment:
    name: production
    url: http://${PRODUCTION_DOMAIN}
  only:
    - master
  allow_failure: false
  when: manual
  script:
    - npm install --global surge
    - surge --project ./public --domain ${PRODUCTION_DOMAIN}

production tests:
  stage: production tests
  image: alpine
  only:
    - master
  script:
    - apk --no-cache add curl
    - curl -q http://${PRODUCTION_DOMAIN}
    - curl http://${PRODUCTION_DOMAIN} |grep -q "$CI_COMMIT_SHORT_SHA"



= environment et deployment dans kube : =

les environments decrivent l'endroit ou le code va être déployé
gitlab permet de fournir un url pour le monitoring 
un environment peut être linké à un cluster kube

ex :
on déclare un env production et on le restreint uniquement à la branche master

..
deploy:
  stage: deploy
  variables:
    APP_NAME: production-todo
    APP_LABEL: production
    DEPLOY_HOST: todo.k8s.anvard.org
  environment:
    name: production
    url: http://todo.k8s.anvard.org:32445/
  image: roffe/kubectl:v1.13.0
  script:
    - kubectl delete --ignore-not-found=true secret gitlab-auth
    - kubectl create secret docker-registry gitlab-auth --docker-server=$CI_REGISTRY --docker-username=$KUBE_PULL_USER --docker-password=$KUBE_PULL_PASS
    - cat k8s.yaml | envsubst | kubectl apply -f -
  only:
    - master

- kubernetes applications resources :

> deployment 
> service 
> pvc
> ingress


on voit dans le job de deployment qu'un fichier de ressources kube (k8s.yaml) va etre affiché et qu'ensuite via la commande envsubst on va remplacer les variables du fichiers par leurs valeurs définies dans gitlabci puis appliquer les fichiers dans notre cluster kube avec un kubectl apply -f 

on peut ici voir le fichier k8s.yaml et voir les variables qui seront remplacées par les valeurs définies dans gitlab 

cat k8s.yaml       
kind: Service
apiVersion: v1
metadata:
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "5000"
  name: ${APP_NAME}
spec:
  selector:
    app: ${APP_LABEL}
  type: NodePort
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000
---
kind: Deployment
apiVersion: apps/v1beta1
metadata:
  name: ${APP_NAME}
  labels:
    app: ${APP_LABEL}
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ${APP_LABEL}
  template:
    metadata:
      labels:
        app: ${APP_LABEL}
    spec:
      imagePullSecrets:
      - name: gitlab-auth
      containers:
      - name: ${APP_NAME}
        image: "${DOCKER_IMAGE_TAG}"
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          value: "postgres://${DBUSER}:${DBPASS}@${APP_NAME}-db/todo"
        ports:
        - containerPort: 5000
---
kind: Service
apiVersion: v1
metadata:
  name: ${APP_NAME}-db
spec:
  selector:
    app: ${APP_LABEL}-db
  ports:
  - protocol: TCP
    port: 5432
---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: ${APP_NAME}-db
  labels:
    app: ${APP_LABEL}-db
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ${APP_LABEL}-db
  template:
    metadata:
      labels:
        app: ${APP_LABEL}-db
    spec:
      containers:
      - name: ${APP_NAME}-db
        image: postgres:10.4
        env:
        - name: POSTGRES_USER
          value: "${DBUSER}"
        - name: POSTGRES_PASSWORD
          value: "${DBPASS}"
        - name: PGDATA
          value: "/data/pgdata"
        volumeMounts:
        - mountPath: /data
          name: todo-data
      volumes:
        - name: todo-data
          persistentVolumeClaim:
           claimName: ${APP_NAME}-data
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: ${APP_NAME}-data
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: ${APP_NAME}-ingress
spec:
  rules:
    - host: ${DEPLOY_HOST}
      http:
        paths:
          - backend:
              serviceName: ${APP_NAME}
              servicePort: 80




= Suppression des environments apres la merge requests : =

une fois que notre environment dynamique a été crée et la mr passée il n'y a plus de raison de conserver l'environement de review qui de part sa nature qui depend du nom de la branche est éphémère.
surge permet de delete un projet :
https://surge.sh/help/tearing-down-a-project

on va donc ajouter un second job dans le stage review de notre code.
on veut delete le projet quand la branche a été mergée et potentiellement deleted
on defini une variable propre a ce job qui indique que la branche ne doit pas être clonée
on va indiquer une action stop dans ce job
on va etablir un lien entre le job deploy review et stop review : on va ajouter dans l'environment du job deploy review la directive on_stop: stop review (qui correspond au nom de nootre job stop review)

https://docs.gitlab.com/ee/ci/environments/

"Stopping an environment
Executes an on_stop action, if defined.
This is often used when multiple developers are working on a project at the same time, each of them pushing to their own branches, causing many dynamic environments to be created.
dynamic environments stop automatically when their associated branch is deleted.
Environments can be stopped automatically using special configuration.
If you can’t use Pipelines for merge requests, setting the GIT_STRATEGY to none is necessary in the stop_review job so that the runner doesn’t try to check out the code after the branch is deleted.
When you have an environment that has a stop action defined (typically when the environment describes a Review App), GitLab automatically triggers a stop action when the associated branch is deleted. The stop_review job must be in the same stage as the deploy_review job in order for the environment to automatically stop."

deploy review 
  stage: deploy review
  environment:
    name: review/$CI_COMMIT_REF_NAME
    url:  http://boogie-$CI_ENVIRONMENT_SLUG.surge.sh
    on_stop: stop review                    <<<<<< on declare 
  only:
    - merge_requests
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie-$CI_ENVIRONMENT_SLUG.surge.sh

stop review:
  stage: deploy review
  variables:
    GIT_STRATEGY: none         <<<<< on specifie que ce job ne doit pas cloner la branche qui potentiellement n'existe plus.
  only:
    - merge_requests           <<<<  le job ne s'execute que pour les merge requests 
  script:
    - npm install --global surge <<<<  on installe surge pour le job 
    - surge teardown boogie-$CI_ENVIRONMENT_SLUG.surge.sh <<< on delete l'env surge dont la valeur de la variable correspond au nom de la branche deployée 
  when: manual                <<<< ne se fait qu'une fois l'action de merge sur master est faite manuellement sur gitlab
  environment:
    name: review/$CI_COMMIT_REF_NAME
    action: stop              <<<< l'environement est stoppé.


== before and after script :==

on peut configurer en global ou au niveau du job 

https://docs.gitlab.com/ee/ci/yaml/#before_script-and-after_script


- before script : 
on peut voir cette section comme une phase pour préparer le job, set up de dépendances etc ...

"Use before_script to define an array of commands that should run before each job, but after artifacts are restored.
Scripts specified in before_script are concatenated with any scripts specified in the main script, and executed together in a single shell.
It’s possible to overwrite a globally defined before_script if you define it in a job:

default:
  before_script:
    - echo "Execute this script in all jobs that don't already have a before_script section."

job1:
  script:
    - echo "This script executes after the global before_script."

job:
  before_script:
    - echo "Execute this script instead of the global before_script."
  script:
    - echo "This script executes after the job's `before_script`"
￼
You can use YAML anchors with before_script.

- after_script : 

Use after_script to define an array of commands that run after each job, including failed jobs.
If a job times out or is cancelled, the after_script commands are not executed. Support for executing after_script commands for timed-out or cancelled jobs is planned.
Scripts specified in after_script are executed in a new shell, separate from any before_script or script scripts. As a result, they:
Have a current working directory set back to the default.
Have no access to changes done by scripts defined in before_script or script, including:
Command aliases and variables exported in script scripts.
Changes outside of the working tree (depending on the runner executor), like software installed by a before_script or script script.
Have a separate timeout, which is hard coded to 5 minutes. See the related issue for details.
Don’t affect the job’s exit code. If the script section succeeds and the after_script times out or fails, the job exits with code 0 (Job Succeeded).

default:
  after_script:
    - echo "Execute this script in all jobs that don't already have an after_script section."

job1:
  script:
    - echo "This script executes first. When it completes, the global after_script executes."

job:
  script:
    - echo "This script executes first. When it completes, the job's `after_script` executes."
  after_script:
    - echo "Execute this script instead of the global after_script."

You can use YAML anchors with after_script."

= YAML : =

language pour gitlab-ci
key value pair
on peut stocker des stings, integers, list, multiples items
l'indentation est fondamentale
le yaml accepte les commentaires commenant par "#" ( pas le json )
on peut convertir du yaml en json

name: "John"
age: 29
isMale: true
stuff:
  - laptop
  - car
pour les list on peut ecrire de cette manière aussi :  
stuff: [ "laptop", "car" ]

person:
  name: "John"
  age: 29
  isMale: true
  stuff:
    - laptop
    - car
  friends: 
    - name: Jane
      age: 25
    - name: Mike
      age: 30

= disable job : =

on peut facilement désactiver un job dans notre pipeline : il suffit d'ajouter un "." devant le nom du job.
Il ne sera pas éxécuté.

ex: 
.deploy review:
  stage: deploy review
  only:
    - merge_requests
  environment:
    name: review/$CI_COMMIT_REF_NAME
    url:  http://boogie-$CI_ENVIRONMENT_SLUG.surge.sh
    on_stop: stop review
  script:
    - npm install --global surge
    - surge --project ./public --domain boogie-$CI_ENVIRONMENT_SLUG.surge.sh

= ancres / anchors : =

on va pouvoir relier un objet a un autre 

person:
  name: "John"
  age: 29
  isMale: true
  stuff:
    - laptop
    - car
  friends:
    - name: Jane
      age: 25
    - name: Mike
      age: 30
  self: "John"

exemple on va definir l'objet self qui devra prendre la valeur de l'objet name : quelque soit cette valeur.

on defini une ancre dans le nom et on appelle cette ancre dans l'objet self

person:
  name: &name "John"
  age: 29
  isMale: true
  stuff:
    - laptop
    - car
  friends:
    - name: Jane
      age: 25
    - name: Mike
      age: 30
  self: *name


on peut merger plusieurs properties dans un objet :
en déclarant une ancre avec "& nom d'ancre" et en l'integrant dans l'object avec "<<: * nom d'ancre" 

base_person: &base 
  city: nyc
  country: usa

person:
  <<: *base
  name: &name "John"
  age: 29
  isMale: true
  stuff:
    - laptop
    - car
  friends:
    - name: Jane
      age: 25
    - name: Mike
      age: 30
  self: *name

on va pouvoir s'en servir pour eviter de dupliquer du code dans nos pipelines gitlab.
on va donc pouvoir s'en servir pour créer des templates de code dans notre pipeline gitlab et factoriser du code.

en examinant notre pipeline on voit que les jobs de déployment sont à peut pres les mêmes on va pouvoir simplifier.
review / staging /production

on va essayer de trouver les infos similaires pour les isoler et factoriser.

on va isoler les blocs communs et ajuster si besoin : ici on rajoute dans chacun des jobs une variable domain pour factoriser notre code :

.deploy_template: &deploy
  only:
    - master
  script:
    - npm install --global surge
    - surge --project ./public --domain $DOMAIN
  environment:
    url: http://$DOMAIN

deploy staging:
  <<: *deploy
  stage: deploy staging
  variables:
    DOMAIN: $STAGING_DOMAIN
  environment:
    name: staging
  
deploy production:
  <<: *deploy
  stage: deploy production
  variables:
    DOMAIN: $PRODUCTION_DOMAIN
  environment:
    name: production

on a donc comme ci finale :

image: node:10

stages:
  - build
  - test
  - deploy review
  - deploy staging
  - deploy production
  - production tests

cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - node_modules/

variables:
  STAGING_DOMAIN: instazone-staging.surge.sh
  PRODUCTION_DOMAIN: instazone.surge.sh

build website:
  stage: build
  only:
    - master
    - merge_requests
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/" ./public/index.html
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine
  stage: test
  only:
    - master
    - merge_requests
  script:
    - grep -q "Gatsby" ./public/index.html

test website:
  stage: test
  only:
    - master
    - merge_requests
  script:
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve &
    - sleep 3
    - curl "http://localhost:9000" | tac | tac | grep -q "Gatsby"

deploy review:
  stage: deploy review
  only:
    - merge_requests
  environment:
      name: review/$CI_COMMIT_REF_NAME
      url: https://instazone-$CI_ENVIRONMENT_SLUG.surge.sh
      on_stop: stop review
  script:
    - npm install --global surge
    - surge --project ./public --domain instazone-$CI_ENVIRONMENT_SLUG.surge.sh

stop review:
  stage: deploy review
  only:
    - merge_requests
  variables:
    GIT_STRATEGY: none
  script:
    - npm install --global surge
    - surge teardown instazone-$CI_ENVIRONMENT_SLUG.surge.sh
  when: manual
  environment:
    name: review/$CI_COMMIT_REF_NAME
    action: stop

deploy_template: &deploy
  only:
    - master
  script:
    - npm install --global surge
    - surge --project ./public --domain $DOMAIN
  environment:
    url: http://$DOMAIN

deploy staging:
  <<: *deploy
  stage: deploy staging
  variables:
    DOMAIN: $STAGING_DOMAIN
  environment:
    name: staging
  
deploy production:
  <<: *deploy
  stage: deploy production
  variables:
    DOMAIN: $PRODUCTION_DOMAIN
  environment:
    name: production

production tests:
  image: alpine
  stage: production tests
  only:
    - master  
  script:
    - apk add --no-cache curl
    - curl -s "https://$PRODUCTION_DOMAIN" | grep -q "Hi people"
    - curl -s "https://$PRODUCTION_DOMAIN" | grep -q "$CI_COMMIT_SHORT_SHA"
