==== notes genarales sur kafka : === 

Le bus d'événement est un système orienté message :
les messages sont centralisés dans un seul système, facilitant l'intégration de nouveaux systèmes destinataires.

Celui utilise un système de communication où les émetteurs/recepteurs ne doivent pas forcement être au courant les uns des autres : 
L'émetteur (producer) ne connait que le bus et le nom de la file de message sur lequel envoyer l'événement. 
Le souscripteur (consumer) s'inscrit à la file de message, ne recevant que ce qu'il n'a pas déjà recu.


- Publish / Subscribe Messaging : 

est donc une méthode caractérisée par le publisher d'une donnée (message) mais sans l'envoyer directement au receiver.
A la place le publisher classifie les message d'une certaine manière et le receiver souscrit (subscribe) pour recevoir certain type de message en fonction de ses besoins. 
Ce systeme pub/sub utilise souvent un broker : un point central ou les messages sont publiés.

Kafka est un system de publication /souscription de message souvent désigné comme un "log de commit distribué"
Un commit de log distribué de systeme ou bdd est fait pour être potentiellement rejoué. Dela même manière les données dans kafka sont stockées durablement. 

- Message : 

L'unité de base dans kafka est le message (l'analogie avec une bdd serait un enregistrement / record) qui est un tableau de bytes mais il n'y a pas de format particulier mais on peut avoir un parametre additionnel une clé qui est elle même un tableau de bytes sans format particulier.
Les clés sont utilisées quand les messages doivent être écrit sur différentes partitions.

Pour plus d'efficacité les messages sont rassemblés en batchs : qui sont donc des collections de messages et tout ces batchs sont produits pour le même topic et la même partition.
Plus les batchs sont grands plus ils peuvent contenir de message mais sont donc plus long à être transférés : les batchs sontcompressés pour réduire la latence de transport.
 
Les messages kafka sont opaques; ils faut cependant imposer une structure au contenu du message afin de le rendre clairement lisible : on peut utiliser json /xml voir un format dédié hadoop : Avro .

- Topics :  

Les messages sont catégorisés dans kafka en topics (l'analogie avec une db serait une table..)
Les topics sont également splittés en différentes partie : les partitions (à voir comme un log de commit distribué)
Les messages sont ecrit à la suite et lu dans un ordre partant du début à la fin.
Un topic a donc très souvent plusieurs partitions.
Les partitions permettent aussi la redondance et la scalabilité: chaque partition peut être définie sur un server dédié.


- Producers and consumers :

Les clients kafka sont les users systèmes et sont de deux types : producers et consumers.

> producers : ils créent des messages (ce sont les publishers /editeurs). Un message va être crée pour un topic donné.
Par défaut le producer ne se souci pas de la partition sur laquelle le message va être écrit.
Il existe cependant certains cas ou on va vouloir ecrire notre message sur une partition donnée grâce à l'utilisation de clés et de hash et / ou d'outils partitionners.

> consummers : ils lisent les messages (subscribers / readers). Le consumer s'abonne à un ou des topics et lis les mesages dans leur ordre de leur production.
Le consumer garde la trace des message lus grâce à l'offset des messages qui est une metadata ( un entier incrémenté) que kafka ajoute à chaque messsage .
Chaque message sur chaque partition a un offset donné.En gardant la trace de l'offset du message : un consummer peut être redémarrer et donc reprendre la lecture à l'endroit précis ou il le faut.
Les consumers fonctionnent en groupes de consummers qui travaillent ensemble pour la conso d'un topic.Le group de consumer s'assure que chaque topic est bien consummé par un consummer par partition.
Le mapping d'un consumer sur une partition est appellé le owner de la partition.
On a donc une scalabilité possible pour les consummer et en cas de défaillance d'un consummer : une rebalance est faite entre les consummers du group epour continuer les services sur les partitions.

- Brokers et clusters :

un node seul kafka est un broker : il recoit les messages des produceurs , assigne des offsets et commit les messages sur disk.
Il va aussi servir les consummers  en leur designant les partitions pour lire les messages et récupérer les messages des disques. En fonction des specs techniques un broker peut gérer des milliers de partitions et des millions de messages par secondes.
Les brokers sont ammenés à travailler en cluster : dans un ensemble de broker un broker aura la fonction de cluster controller et se role se fera via une "election" . Il est responsable des opérations d'administration (assignation de partition,monitoring des pannes de broker)
Une partition appartient a un seul broker dans un cluster et ce broker est appellé le leader de la partition.
Une partition peut être assignée à plusieurs brokers : qui est le resultat de la répartition de partition.
Cependant les consummers et producers ne se connectent qu'au leader du cluster.





Typiquement un système de type publication-souscription.

Le bus permet les consumers au fil de l'eau et en mode batché.

Composants
Dropwizard-kafka-http
Dropwizard-kafka-http est une interface REST pour kafka.
L'intérêt de cette brique est de permettre la production de messages dans Kafka via HTTP. (les libs kafka pour php n'étant pas satisfaisante).
Ce composant est interne à Meetic, Dropwizard étant un framework pour créer des rest-api.
L'application écoute sur le port 8080 et présente une interface web de status/statistiques sur le port 8081.
Son accès se fait par load-balancer en round robin (sans session).

Apache Kafka :

Apache Kafka est un système orienté message de type publication-souscription, créé par LinkedIn, et en java, pour collecter et distribuer de grosses volumétrie de message avec une faible latence.
Kafka fournit un service de messaging un peu particulier. Il emploie des files de messages appelées topics pour mettre à disposition les données. Ces topics sont des sequences ordonnées de messages. Chaque message se voit attribuer un identifiant sequentiel (offset).
Kafka conserve tous les messages publiés, qu'ils aient été consommés ou pas, jusqu'à une durée de rétention définie (7 jours par défaut dans notre cas). Lors de la consommation d'un message, les consommateurs changent uniquement leurs positions (qui n'est d'une metadata : offset) dans la topic, aucune donnée n'est déplacé, ni dupliquée. Ce mécanisme simple permet à Kafka de n'être que très peu impactés par l'ajout de consommateurs.
De plus, les consommateurs peuvent appartenir à un groupe de consommateur. Un sein d'un même groupe, le message ne sera consomme qu'une seule fois, par un seul membre du groupe.

Kafka est dit distribué, les files de message pouvant être reparties sur plusieurs serveurs (brokers). Un message donné ne pourra être produit et consommé que sur le broker kafka leader de la topic.

Un topic kakfa peut être partitionnée, c'est-à dire les données d'un topic seront reparties sur des sortes de sous files de messages identifiés par la topic et un numéro de partitions. Ces partitions sont indépendantes entre elles. Elles peuvent être gérées par des brokers différents, permettant la scalabilité de la solution.

La version 0.8 de kafka a introduit la réplication intra-cluster : chaque partition peut se voir synchroniser ses données sur plusieurs brokers dit followers. La bascule d'un broker leader vers un broker réplicant se fait automatiquement si le leader est déclaré hors service.


Exemple de production et consommation sur un topic :  exemple d'un topic

Dans cet exemple, on peut voir l'utilisation d'un topic, partitionnées en 3. Il est consommé par 2 groupes de consommateurs :
le seul membre du groupe X consommera la totalité des événements de ce topic.
les membres du groupe Y traiteront uniquement 1/3 des messages du même topic.

L'accès au service kafka se fait en contactant au moins un des brokers kafka, qui donnera au client la topologie du cluster.
Le service kafka est accessible via un protocole binaire sur le port 9092. Et son interface de métrologie jmx est disponible sur le port 9999.

Apache Zookeeper
Apache Zookeeper est un service de coordination pour les applications distribuées, en java. Il est utilisé par Kafka :
pour élir les leadership.
pour partage la topologie du cluster Kafka : (liste des brokers dans le cluster, leadership et réplicant des topics).
pour stocker les offset de chaque consommateur (ou groupe).
Dans notre cas, les noeuds Zookeeper forment un seul ensemble (cluster) Zookeeper, réparti sur les 2 datacenters. Or dans le cas de coupure d'interconnexion datacenter, le cluster, avec 2 ensembles isolés de même nombre de serveurs (sans quorum), sera en situation de partitionnement sans pour pouvoir décider quel broker peut passer leader. Nous avons choisi, afin de moins se soucier du nombre pair ou impairs dans le cluster, de mettre un poids plus important sur un ou plusieurs serveurs d'un des datacenters.
Par exemple: avec 3 serveurs sur chaque site, on pourra mettre un poids de 2 sur le 1er serveur du site de Bessieres. Le cluster Zookeeper aura alors un nombre de votants impair, 7, le serveur 1 comptant pour 2. Alors en cas de coupure d'interco, le site maitre sera Bessieres, avec ses 4 voix, les serveur des Ulis se mettront en maintenance. Si l'on souhaite basculer sur le site des Ulis, la configuration sera manuelle et une relance des services nécessaire (cf proc d'exploitation).

Ce service ouvre le port :
2181 pour son service
2182 pour la réplication
2183 pour l'élection de leader
9998 pour son interface de métrologie jmx


Monitoring :

sitescope / imon4 / eventbus
Check Service Dropwizard-Kafka-Http : controle l'état du service Dropwizard-Kafka-Http sur chaque serveur, en utilisant l'interface de status, le status doit etre "OK" ni avoir de lock.
Check Service Zookeeper : controle l'état du service de chaque serveur, en utilisant la commande ruok de zookeeper
Check Service Kafka : controle l'état du service kafka
Check Partition Balancing - Kafka : controle que le leader de chaque topic soit bien le noeud déclaré "préféré" (1er replica)
Check Under Replicated Partitions - Kafka : controle chaque topic ait le nombre de réplica (copie) demandé.

Dropwizard-kafka-http :
Localisation : Munin / dw-kafka-http
indicateurs jvm (memory, threads)
nombre de requetes par seconde
nombre de requetes par code HTTP par seconde
temps pris pour faire une requete (max, moyenne , 99th)


Kafka
Localisation : Munin / kafka
indicateurs jvm complets
nombre de requetes par type de client (consumer, follower)
nombre de requetes en échec par type de client (consumer, follower)
temps des requetes par type de client (consumer, follower) (max, moyenne, 99th)
débit entrant/sortant
indicateurs sur la topologie du cluster (nombre de leader, partitions sous repliquées et nombre de partitions)


Documentation & Liens

kafka.apache.org : https://kafka.apache.org/
wiki : https://cwiki.apache.org/confluence/display/KAFKA/Index
zookeeper.apache.org  : https://zookeeper.apache.org/

