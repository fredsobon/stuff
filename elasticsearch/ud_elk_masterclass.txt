==== notes sur ud complete masterclass elsasticsearch with kibana and logstash : ====


https://www.elastic.co/guide/en/elasticsearch/reference/6.1/_basic_concepts.html


=== ch1 Elasticsearch  - intro setup : ===


1- set up Elasticsearch ET kibana pour utiliser la console et requetter le moteur elasticsearch 

- prerequi : avoir java installé : 
  ~/Documents/learn/elasticstack/ud_elk_complete  java -version                                                        [☸ kube-infra:monitoring]
java version "1.8.0_201"
Java(TM) SE Runtime Environment (build 1.8.0_201-b09)
Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)

- download elasticsearch et kibana depuis le site elastic :

extraire les archives.

- elastic :

lancer le binaire dans une fenetre : /bin/elasticsearch 
dans une autre fenêtre : curl http://localhost:9200 
 boogie@lab  ~/Documents/work/repos_work/udemy-dl  master  curl http://localhost:9200                                            [☸ kube-infra:monitoring]
{
  "name" : "lab",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "sAzQv9-bT5-IswPq2ExmSg",
  "version" : {
    "number" : "7.2.1",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "fe6cb20",
    "build_date" : "2019-07-24T17:58:29.979462Z",
    "build_snapshot" : false,
    "lucene_version" : "8.0.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}


-kibana :

editer le fichier : config/kibana.yaml
decommenter ou renseigner la ligne :
# The URLs of the Elasticsearch instances to use for all your queries.
elasticsearch.hosts: ["http://localhost:9200"]

cela permet de configurer kibana pour pointer sur notre elasticsearch.

on lance kibana :
/bin/kibana 
à la fin de l'execution on voit l'adresse sur laquelle on peut utiliser kibana : 
  log   [18:13:41.215] [info][listening] Server running at http://localhost:5601

- devtools : on selectionne ce menu dans le pannel d'icones de la barre laterale gauche 
on va essentiellement utiliser la section devtools dans kibana pour interroger notre server elasticsearch 
on selectionne console : puis on peut saisir des requettes et en cliquat sur le petit triangle ou entrée dans la pannel de gauche , on voit le resultat de notre requette à droite.


- monitoring : on selectionne idem que devtools dans la barre laterale gauche :
-> on active le monitoring : "turn on monitoring"

on voit l'etat de nos applis :

Biensur pour nos tests on va lancer /stopper elasticsearch /kibana -> a chaque instance 

- Elasticsearch concepts :

document oriented :  insert /delete/retrieve/analyse/search 
mais c'est essentiellement un moteur de recherche qui va utiliser les termes de la recherche pour retrouver le document.
comme analogie on peut prendre l'index d'un livre.
Basé sur le moteur de recherche lucene , il utilise un index inversé "inverted index" (cf doc elasticsearch :
https://www.elastic.co/guide/en/elasticsearch/reference/current/documents-indices.html )
"An inverted index lists every unique word that appears in any document and identifies all of the documents each word occurs in."
Pour créer un index inversé : tous les mots /champs  du documents vont être isolés et associés à un term ou token ensuite une liste de tous les documents dans lesquels ces mots apparaissent est créée :

doc1 : le lapin nain joue
doc2: jouer avec le lapin 

terms    doc1  doc2
le        X     X
lapin     X     X
nain      X
jouer           X
avec            X

si on cherche le texte lapin nain dans quel document on a le plus de chance de le trouver ?
-> dans le document 1 : elasticsearch utilise un algorithme de score pour ses recherches : le doc 1 a deux entrées sur le mot lapin, le doc 1 a une seule entrée sur le mot nain ...

Elasticsearch est orienté document . Un document est l'unité de base qui sera indexée et présenté sous le format json.
https://www.elastic.co/guide/en/elasticsearch/reference/6.1/_basic_concepts.html



== ch2 Elastic basics : ==

Dans un mode sgbd on stocke les données dans des tables, ligne et colonne.
Dans elastic :
-> les données sont stockées dans un index
-> l'equivalent des lignes est un document dans elastic 
-> l'equivalent d'une colonne est un champ dans elastic
on peut donc avoir une equivalence  de type : 
SGBD       ELASTIC
table      index
raw        document
column     field 
Attention cette comparaison est imagée et on a pas vraiment une correspondance stricte entre sgbd classic et elastic.

/!\ Attention depuis la version 6 : les types disparaissent progressivement  d'elastic pour etre retirés en version 7 

Quand on insere des données dans elastic on dis qu'on index.


- Ajout de données :

PUT /{index}/{type}/{id}      <<< attention en v7 on utilise plus le type 
  {
   "field1": "value1",
   "field2": "value2",
  }

on aura un equivalent du type suivant pour la v7

PUT /{index}/_doc/{id}
{
   "field1": "value1",
   "field2": "value2",

}

ex: 
PUT /vehicles/_doc/123
{
  "brand": "honda",
  "color": "red"
}


Un type est une sous division d'index. 
A partir de la version 6 on ne peut plus avoir plusieurs type d'index :
ex :  avant la v6 : on pouvait avoir : 
/vehicles/moto/121
/vehicles/car/123
/vehicles/truck/333
    
maintenant on aura qu'un seul type en v6 ..pour disparaitre en v7

Il peut être conseillé de definir nous même un id au document que l'on va inserer : cela sera plus simple a retrouver sinon elastic en génére automatiquement un. 


on va pouvoir utiliser la console de dev elastic dans kibana :

- on cree un index avec un doc et une version (v7) 

PUT /vehicles/_doc/123
{
  "make": "honda",
  "milage": "12000",
  "color": "red"

}


on clic sur play et on a le resultat en json :

{
  "_index" : "vehicles",
  "_type" : "_doc",
  "_id" : "123",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 4,
  "_primary_term" : 1
}

si on modifie un champ ou on reclic sur play on a une modif : "updated" apparait et le num de version est incrémenté.

{
  "_index" : "vehicles",
  "_type" : "_doc",
  "_id" : "123",
  "_version" : 2,
  "result" : "updated",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 4,
  "_primary_term" : 1
}

Toutes les données qui commencent par "_" sont gérées par elastic. ce sont des "meta field" ajoutés et managés par elastic.
on voit aussi la section shard (que l'on etudiera plus tard)

- GET :
on va pouvoir recupérer nos données via la commandes :

GET /vehicles/_doc/123
{
  "make": "honda",
  "milage": "12000",
  "color": "red"
  
}
--> 
{
  "_index" : "vehicles",
  "_type" : "_doc",
  "_id" : "123",
  "_version" : 7,
  "result" : "updated",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 6,
  "_primary_term" : 2
}

Si on cherche un "type" qui n'existe pas dans notre index pas de surprise elasic ne le retournera pas : 

on va pouvoir recuperer jusqu'en version 6 le contenu de notre document sans les metadata : en suffixant notre requette avec _source 

- HEAD : 
on peut recupérer le header de la requete comme en http classique :

HEAD /vehicles/_doc/123  -> 200 - ok

si on cherche une reference qui n'existe pas : 
HEAD /vehicles/_doc/128   -> 404 - Not Found

si on modifie un champ dans notre document : tout le document se trouve update et pas uniquement le champ concerné.
le document est l'unité granulaire d'elastic.

Les documents dans elastic sont "immutables"  (hash / tuple ..) 
en changeant un champ dans le doc : on aura le num de version du doc incrémenté.

Une API pour l'update existe on utilisera donc une syntaxe particuliere :


Attention v7 only : 
POST /vehicles/_update/123
{
  "doc": {
  "color": "yellow"
  }
}

--> 
{
  "_index" : "vehicles",
  "_type" : "_doc",
  "_id" : "123",
  "_version" : 9,
  "result" : "noop",
  "_shards" : {
    "total" : 0,
    "successful" : 0,
    "failed" : 0
  }
}
L'update fait pareil que le put.

- DELETE : pour supprimer un doc :

DELETE /vehicles/_doc/123
--> 
{
  "_index" : "vehicles",
  "_type" : "_doc",
  "_id" : "123",
  "_version" : 10,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 9,
  "_primary_term" : 2
}

Quand un doc est supprimé : elastic le mark comme deleted et une tache de fond interne va le supprimer effectivement completement via un mecanisme interne à elastic.
L'espace disque n'est donc pas immédiatement récupéré : il attendre un peu avant de voir le volume occupé diminuer

Quand on fait un GET sur un index , on recupere juste la structure de cet index.

GET /vehicles
--> 

{
  "vehicles" : {
    "aliases" : { },
    "mappings" : {
      "properties" : {
        "brand" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "color" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "make" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "milage" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        }
      }
    },
    "settings" : {
      "index" : {
        "creation_date" : "1566288372063",
        "number_of_shards" : "1",
        "number_of_replicas" : "1",
        "uuid" : "6Etn6PwXS1qNCAaE0XMnnQ",
        "version" : {
          "created" : "7020199"
        },
        "provided_name" : "vehicles"
      }
    }
  }
}

on voit qu'elastic a defini comme type text des infos qu'on a posté dans notre doc : ex text

on peut biensur delete un index :

DELETE /vehicles
-->

{
  "acknowledged" : true
}

un get sur l'index supprimé retournera forcement une erreur : 
GET /vehicles
-->
{
  "error" : {
    "root_cause" : [
      {
        "type" : "index_not_found_exception",
        "reason" : "no such index [vehicles]",
        "resource.type" : "index_or_alias",
        "resource.id" : "vehicles",
        "index_uuid" : "_na_",
        "index" : "vehicles"
      }
    ],
    "type" : "index_not_found_exception",
    "reason" : "no such index [vehicles]",
    "resource.type" : "index_or_alias",
    "resource.id" : "vehicles",
    "index_uuid" : "_na_",
    "index" : "vehicles"
  },
  "status" : 404
}

= Analyse de text : =

quand el index : il va recuperer les data et construire un index inversé puis injecter les data dans des shards.
L'analyse de text est vraiement au coeur du process d'indexation 

On va avoir des methode pour être le plus efficace possible :

->on va supprimer de l'indexation les "stop words" : nom communb vraiment utilisés au maximum dans la langue : ex en anglais / us : the, and ...
->on ne va pas tenir compte de la casse : on passe en mode casse insensitive
->on va indexer les racines des mots : ex dans un text on a swimming, swimmers: on va indexer la racine swim
->on va indexer les synonymes (ex: thin, skinny)

ces actions sont associées / appellées "filtres".
ces actions vont  permettre de réduire l'espace occupé par nos data, améliorer le temps de recherche
on a donc deux phases dans l'indexation :
tokenisation -> on isole les mots à indexer ( on supprime les espaces ..)
filtre -> on va appliquer les differents filtres vu precedement

pour resumer :

indexation :    ->            analyser:           ->            inverted index
 text                        1/ tokenisation                            
                             2 filtering

ces etapes se passent egalement pour la recherche 

si on recherche dans le text "the Thin"   on aura de trouvé dans notre index inversé : "thin" (tokenisation puis filtres suppression des stops words et case insensitive)

elastic embarque des prebuild analysers et filters qu'on peut utiliser.
Tous les documents indexés / en cours d'indexation dans elastic passent par ces process.
On peut appliquer un analyser sur des champ specifique de notre document :

{ 
 "name": "steve bob",
 "date": "12/12/15",
 "tweeted": "the last swimmer is in the pool"
}

on pourra par exemple appliquer un analyser a un champ particulier ex "tweeted" ..
Cet analyser pourra être appliquer pour la phase d'indexation mais egalement pour la phase de recherche.

Il va être important de définir une structure de notre index avant d'injecter des data dedans.
on va ainsi pouvoir placer des analysers sur les champs qui nous interessent et ainsi gagner en performance.

on aura une partie de design qui embarquera :

les settings et mappings.


== ch3 - Elasticsearch : index settings - mappings ==

La plupart du temps on va travailler avec les index dans elasticsearch 
Si on crée notre index manuellement on va essayer de structurer correctement : c'est important pour la gestion en production

ex: customer_index 
quand on crée un index : deux sections interviennent settings et mapping 

ex :  PUT /CUSTOMERS
       {
        "settings": {
           "number_of_shards": 2,                   <<<<< de base el si on ne precise pas va créer 5 shards.
           "number_of_replicas": 1,

           }
        "mappings":                                 <<<<< attention n'existe plus (comme les types en version 7 d'el) 
       }
        


Si on execute notre requette c'est ok on peut faire un GET et on a les détails.

on va definir notre mapping ( on le fait dasn une seconde requette : attention en el6 on ne peut definir qu'un seul nom a notre mapping 

      PUT /CUSTOMERS
      {

        "mappings":   {
             "online": {
               "properties": 
             }

            }
      }



ch3 lecture8 min6 







ch3 - lecture8 - min :



